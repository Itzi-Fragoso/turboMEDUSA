	if (length(phy$tip.label) == length(richness[,1])) check <- TRUE
check
length(phy$tip.label)
length(richness[,1])
(length(phy$tip.label) == length(richness[,1]))
	if (length(phy$tip.label) == length(richness[,1])) check <- TRUE
check
# Rename exemplar taxa with taxon name in richness file#
	if (!is.null(richness$exemplar))#
	{#
# Change relevant tip.labels in phy; individual 'exemplar' may be NA, use original tip.label.#
# Ordering in richness file should NOT be assumed to match order of tip.labels#
		i.na <- is.na(richness$exemplar)#
		phy$tip.label[match(richness$exemplar[!i.na], phy$tip.label)] <- as.character(richness$taxon[!i.na])#
	}#
	#
# make sure things are in the correct order and of correct format#
	if (length(richness[1,]) == 2)#
	{#
		if (colnames(richness)[1] != "taxon" || colnames(richness)[2] != "n.taxa")#
		{#
			if (class(richness[,1]) == "factor" & class(richness[,2]) == "integer")#
			{#
				colnames(richness) = c("taxon", "n.taxa")#
			} else if (class(richness[,1]) == "integer" & class(richness[,2]) == "factor")#
			{#
				colnames(richness) = c("n.taxa", "taxon")#
			} else {#
				cat("turboMEDUSA thinks your richness data is in an incorrect format. See ?runTurboMEDUSA.\n")#
				stop#
			}#
		}#
	}#
	#
	check <- FALSE#
# checking for typo; if same size, nothing should be dropped#
	if (length(phy$tip.label) == length(richness[,1])) check <- TRUE#
#
# Prune tree down to lineages with assigned richnesses#
	temp <- richness[, "n.taxa"]#
	names(temp) <- richness[, "taxon"]#
	pruned <- treedata(phy, temp, warnings=verbose)  # geiger function calling ape (namecheck)#
	if (check) {#
		if (length(phy$tip.label) != length(pruned$phy$tip.label)) {#
			cat("turboMEDUSA thinks there is a typo in either the tree or richness files.\n")#
			stop#
		}#
	}
	phy <- pruned$phy
phy
ls()
class(whale.tree)
(class(whale.tree)) == "nexus"
foo <- ("SuperBird2.tre")
foo
foo <- read("SuperBird2.tre")
?read file
?readfile
?read.file
?read
??read
read.nexus("SuperBird2.tre")
read.nexus("SuperBird2.tre") -> foo
foo
class(foo)
class(foo) <- "nexus"
foo
class(foo)
foo <- as.phylo(foo)
??as.phylo
foo <- as.phylo(foo)
foo <- runTurboMEDUSA(phy, richness)
require(turboMEDUSA)
load("/Users/josephwb/Projects/R_working/Fossil_MEDUSA/Whale.Rdata")
ls()
foo <- runTurboMEDUSA(whale.tree, whale.ext.richness)
setwd("/Users/josephwb/Idaho/NCEAS_Workshop/MEDUSA_Code")
require(turboMEDUSA)#
#
carnivore.extant.richness <- read.csv("carnivore.extant.richness.csv")#
carnivora.tree <- read.tree("carnivora.phy")
plot(carnivora.tree, label.offset=0.5, cex=0.75); axisPhylo()
# run turboMEDUSA using extant species information only#
foo <- runTurboMEDUSA(phy=carnivore.tree, richness=carnivore.extant.richness)
foo <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
summarize.turboMEDUSA(results=foo, label.offset=0.5)
summarize.turboMEDUSA(results=foo, label.offset=0.5, plotSurface=T)
bd <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
yule <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness, model="yule")
mixed <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness, model="mixed")
summarize.turboMEDUSA(bd)
summarize.turboMEDUSA(yule)
summarize.turboMEDUSA(mixed)
carnivore.extant.richness <- read.csv("carnivore.extant.richness.csv")#
carnivora.tree <- read.tree("carnivora.phy")#
#
plot(carnivora.tree, label.offset=0.5, cex=0.75); axisPhylo()#
#
# run turboMEDUSA using extant species information only#
carny.res <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)#
#
# summarize#
summarize.turboMEDUSA(results=carny.res)#
summarize.turboMEDUSA(results=carny.res, label.offset=0.5)#
summarize.turboMEDUSA(results=carny.res, label.offset=0.5, plotSurface=T)
carny.res
?runTurboMEDUSA
carny.res$threshold
carny.res$models
carny.res$models[1]
carny.res$models[[1]]
carny.res$models[[7]]
carny.res$phy
carny.res$z
?runTurboMEDUSA
carny.res$model.summary
summarize.turboMEDUSA(carny.res)
summarize.turboMEDUSA(carny.res, criterion="aic")
load("/Users/josephwb/Projects/R_working/Fossil_MEDUSA/Whale.Rdata")
ls()
whale.richness
require(fossilMEDUSA)
data(whales)
ls()
require(fossilMEDUSA)
ls()
data(whales)
ls()
plot(whale.tree)
plot(whale.tree, cex=0.5)
plot(whale.tree, cex=0.5, label.offset=0.5, no.margin=T)
?fossilMEDUSA
??fossilMEDUSA
require(auteur)
data(urodela)
ls()
urodela
class(urodela)
ls()
whales
whales <- list()
whales$whale.tree <- whale.tree
whales$whale.richness <- whale.richness
whales$whale.ext.richness <- whale.ext.richness
whales$whale.fossil.richness <- whale.fossil.richness
whale.fossil.richness
whales$whale.pruned.tree <- whale.pruned.tree
length(whales)
save(whales, file="wahles.RData")
rm(list=ls)
rm(list=ls())
load("whales.RData")
ls()
whales
data(urodela)
ls()
urodela
require(fossilMEDUSA)
?fossilMEDUSA
whales.richness
data(whales)
whales.richness
whales$whale.richness
require(fossilMEDUSA)
?fossilMEDUSA
require(turboMEDUSA)
?turboMEDUSA
require(fossilMEDUSA)
?fossilMEDUSA
require(fossilMEDUSA)
?fossilMEDUSA
require(turboMEDUSA)
?turboMEDUSA
require(fossilMEDUSA)
data(whales)
require(fossilMEDUSA)#
data(whales)#
#
# typical MEDUSA#
phy <- whales$whale.tree
whales
richness <- whales$$whale.ext.richness
richness <- whales$whale.ext.richness
richness
phy
foo <- runFossilMEDUSA(phy, richness)
require(turboMEDUSA)
foo.t <- runTurboMEDUSA(phy, richness)
foo.f <- runFossilMEDUSA(phy, richness)
summaryFossilMEDUSA(foo.f)
summarizeFossilMEDUSA(foo.f)
foo.f
summarizeFossilMEDUSA
summarizeTurboMEDUSA(foo.f)
require(turboMEDUSA)#
foo.t <- runTurboMEDUSA(phy, richness)#
summarizeTurboMEDUSA(foo.f)
require(turboMEDUSA)
data(whales)
phy <- whales$whale.tree
richness <- whales$whale.ext.richness
foo.t <- runTurboMEDUSA(phy, richness)
require(turboMEDUSA)
data(whales)
phy <- whales$whale.tree
richness <- whales$whale.ext.richness
data(whales)#
#
phy <- whales$whale.tree#
richness <- whales$whale.ext.richness#
#
foo.t <- runTurboMEDUSA(phy, richness)
summarizeTurboMEDUSA(foo.f)
summarizeTurboMEDUSA(foo.t)
carnivore.extant.richness <- read.csv("carnivore.extant.richness.csv")
carnivora.tree <- read.tree("carnivora.phy")
plot(carnivora.tree, label.offset=0.5, cex=0.75); axisPhylo()
ls()
carnivora <- list
carnivora <- list()
carnivora$tree <- carnivora.tree
carnivora$tree
carnivora$ext.richness <- carnivore.extant.richness
save(carnivora, file="carnivora.RData")
require(turboMEDUSA)
carnivore.extant.richness <- read.csv("carnivore.extant.richness.csv")
carnivora.tree <- read.tree("carnivora.phy")
plot(carnivora.tree, label.offset=0.5, cex=0.75); axisPhylo()
carny.res <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
carny.res
summarizeTurboMEDUSA(results=carny.res)
summarizeTurboMEDUSA(results=carny.res, label.offset=0.5)
? summarizeTurboMEDUSA
summarizeTurboMEDUSA(results=carny.res, label.offset=0.5, plotSurface=T)
carny.bd <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
carny.yule <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness, model="yule")
carny.mixed <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness, model="mixed")
require(fossilMEDUSA)
carny.res <- runFossilMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
summarizeFossilMEDUSA(results=carny.res)
summarizeTurboMEDUSA(results=carny.res, label.offset=0.5, plotSurface=T)
carny.res <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
summarizeTurboMEDUSA(results=carny.res, label.offset=0.5, plotSurface=T)
require(fossilMEDUSA)
carnivore.extant.richness <- read.csv("carnivore.extant.richness.csv")
carnivora.tree <- read.tree("carnivora.phy")
carny.res <- runFossilMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
summarizeFossilMEDUSA(results=carny.res)
 carny.res
summarizeFossilMEDUSA(results=carny.res)
summarizeFossilMEDUSA
summarizeFossilMEDUSA(results=carny.res)
threshold <- 0
-threshold
		else {cat("\nSelecting model based on corrected threshold (decrease in information theoretic score of ", -threshold, " units).\n", sep="")}
cutoff="threshold"
if (cutoff != "threshold") {threshold <- cutoff}#
		else {cat("\nSelecting model based on corrected threshold (decrease in information theoretic score of ", -threshold, " units).\n", sep="")}
if (cutoff != "threshold") {threshold <- cutoff} else {#
			cat("\nSelecting model based on corrected threshold (decrease in information theoretic score of ", -threshold, " units).\n", sep="")}
library(ape)#
library(multicore)#
library(geiger)#
#
## fossilMEDUSA #
## Written by Joseph W. Brown, Richard G. FitzJohn, Luke J. Harmon, and Michael E. Alfaro#
## Problems/bugs/questions/request: josephwb@uidaho.edu#
#
## runFossilMEDUSA:#
##  Takes in phylogeny 'phy' and (optional) 'richness' (containing extant and potentially fossil#
##  counts); 'fossil.richness' optionally passed in separately. #
## 	The species richness information (if supplied) must minimally have columns 'taxon' and 'n.taxa'; #
## 	'taxon' must match with a tip.label in the phylogeny 'phy'. May also include 'exemplar' column,#
## 	used for incompletely-sampled clades which requiring pruning. If no richness information#
##  is provided then it is assumed tips represent single species with comprehensive#
##  sampling. Returns a list of models with 0, 1, 2, ..., 'model.limit' partitions.#
##  'model.limit' can be supplied by user, but is overruled if large enough (relative#
##  to tree size) that AIC correction factor becomes undefined (different for pure birth vs.#
##  birth-death models). 'phy' is assumed to be ultrametric; this is not checked. #
## #
## Returned list has elements:#
##  $models, which contains:#
##     $par: i x 2 matrix (for birth-death parameters); the jth row contains #
##       the speciation and extinction rate for the jth rate class#
##     $lnLik.part: vector of length i; the jth element is the partial log#
##       likelihood value due to the jth rate class#
##     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
##     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
##  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
##  $z: a matrix listing branch times and richnesses; for summarizing results#
##  $anc: a list of all ancestors; for summarizing results#
##  $modelSummary: data.frame listing considered models, likelihoods, AIC, etc.#
#
## Features (to be) added: specify epsilon (for every piecewise model), estimate r.#
## An argument 'epsilon.value' is passed; if NULL, normal MEDUSA is performed.#
#
## TO-DO:#
 # 0. fossil counts in pendant edges - DONE (but slow when fossil.minimum==T)#
 # 1. option for no extinction (i.e. pure birth) (lower priority)#
 # 2. set epsilon to some value (for all piecewise models), estimate r (num.par = 2*num.models - 1)#
 # 3. implement cutAtStem=FALSE (very low priority) # abandon?!?#
 # calculate fossil likelihoods using C++ - WORKING#
#
#
## Function to prune tree using 'richness' information, assumed to have minimally two columns, "taxon" and "n.taxa"#
##   Perhaps relax on these column names, may cause too many problems#
## May also include 'exemplar' column; in that case, rename relevant tip.label before pruning.#
## In addition, may have columns 'n.fossils' and 'f.time'; must match names exactly or ambiguous error generated.#
##   Taxa without fossil counts should have NA in n.fossil and f.time columns.#
## If 'fossil.richness' passed in separately, merge with 'richness'#
pruneTreeMergeData <- function(phy, richness, fossil.richness=NULL, fossil.minimum=FALSE, verbose=T)#
{#
# Sort for downstream functions#
	if (is.null(richness$n.fossils))#
	{#
		richness <- richness[order(richness $taxon),]#
	} else {#
		richness <- richness[order(richness $taxon, -richness$f.time),]#
	}#
	rownames(richness) <- NULL#
# Rename exemplar taxa with taxon name in richness file#
	if (!is.null(richness$exemplar))#
	{#
# Change relevant tip.labels in phy; individual 'exemplar' may be NA, use original tip.label.#
# Ordering in richness file should NOT be assumed to match order of tip.labels#
		i.na <- is.na(richness$exemplar)#
		phy$tip.label[match(richness$exemplar[!i.na], phy$tip.label)] <- as.character(richness$taxon[!i.na])#
	}#
	#
# Check names against 'richness' (already fixed above). May use 'exemplar', but *must* use 'taxon'#
# Update 'n.fossils' and 'f.time' accordingly#
# Again, assume ordering is random, but that taxa are consistent across richness files#
# Annoying number of possible combinations of file format. Don't be so nice! Force them into one or few.#
	if (!is.null(fossil.richness)) # Merge 'fossil.richness' with 'richness'#
	{#
		if (!is.null(fossil.richness$exemplar) && !is.null(richness$exemplar))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$exemplar)#
		} else if (!is.null(fossil.richness$exemplar) && !is.null(richness$taxon))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$taxon)#
# This would be odd, but allow for it; need to change tip labels to 'exemplar' from 'fossil.richness'#
	# VERY low priority#
		} else {#
			i.fossil <- match(fossil.richness$taxon, richness$taxon)#
		}#
		#
		if (length(i.fossil) != length(fossil.richness[,1])) {stop("Problem matching extant and fossil taxon information.")}#
		#
		for (i in 1:length(fossil.richness[,1]))#
		{#
			richness[i.fossil[i],"n.fossils"] <- fossil.richness[i,"n.fossils"]#
			richness[i.fossil[i],"f.time"] <- fossil.richness[i,"f.time"]#
		}#
	}#
# Just for consistency with downstream functions:#
	if (is.null(richness$n.fossils)) {richness <- cbind(richness, n.fossils=NA, f.time=NA)}#
	#
# Check if fossil.minimum==T and if any n.fossil==1; delete and warn#
	if (fossil.minimum == TRUE)#
	{#
		if (!is.na(any(richness$n.fossils == 1)))  # is it possible to be uglier?!? make pretty later.#
		{#
			if(any(richness$n.fossils == 1))#
			{#
				drop.fossil <-  (richness$n.fossils == 1)#
				drop.fossil.taxa <- as.character(richness$taxon[drop.fossil])#
				#
				richness$n.fossils[drop.fossil] <- NA#
				richness$f.time[drop.fossil] <- NA#
				#
				cat("Warning: dropped fossil observations since cannot use fossil counts == 1 as minimums:\n")#
				print(drop.fossil.taxa)#
				cat("\n")#
			}#
		}#
	}#
	#
	if (length(phy$tip.label) != length(richness[,1]))#
	{#
# Prune tree down to lineages with assigned richnesses#
		temp <- richness[, "n.taxa"]#
		names(temp) <- richness[, "taxon"]#
		pruned <- treedata(phy, temp, warnings=verbose)  # geiger function calling ape (namecheck)#
		prunedTree <- pruned$phy#
# Check the tree#
	#	plotNN(prunedTree)					# Node numbers (ape-style) plotted#
		phy <- prunedTree#
	}#
	return(list(phy=phy, richness=richness))#
}#
#
#
#
## Original default was to fit 20 models (or less if the tree was small).#
## Changing to a stop-criterion e.g. when k = n-1 (i.e. when denominator of aicc correction is undefined).#
## k <- (3*i-1) # when BOTH birth and death are estimated#
  ## This occurs when i = n/3#
  ## if est.extinction=FALSE, k <- (2*i-1); max i = n/2#
## n <- (2*num.taxa - 1) == (2*length(richness[,1]) - 1) # i.e. total number of nodes in tree (internal + pendant)#
  ## if present, consider each fossil count as one data point; i.e. n <- num.nodes + num.fossils#
## Eventually use aicc itself as a stopping criterion (not urgent, as it is very fast).#
getMaxModelLimit <- function(richness, model.limit, est.extinction, stop, verbose)#
{#
	samp.size <- sum(!is.na(richness[,"n.fossils"])) + (2*length(richness[,1]) - 1)#
	max.model.limit <- numeric()#
	#
	if (est.extinction == TRUE)#
	{#
		max.model.limit <- as.integer(samp.size/3) - ((!samp.size %% 3) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	} else {#
		max.model.limit <- as.integer(samp.size/2) - ((!samp.size %% 2) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	}#
	#
	if (stop == "model.limit")#
	{#
		if (verbose) {cat("\nLimiting consideration to ", model.limit, " piecewise diversification models\n\n", sep="")}#
	} else if (stop == "threshold") {#
		model.limit <- max.model.limit#
		if (verbose) {cat("\nConsidering a maximum of ", model.limit, " piecewise diversification models (or until threshold is not satisfied)\n\n", sep="")}#
	}#
	return(model.limit)#
}#
#
#
#
## Fitted curve from random b-d simulations#
## Value corresponds to 95th percentile of AICc(split) - AICc(no-split) for no-split simulations#
getThreshold <- function (x)#
{#
	a = -3.5941052380332650E+01#
	b =  6.7372587299747000E+00#
	c = -1.0061508340754866E-01#
	Offset =  2.7516678664333408E+01#
	y <- a * (x-b)^c + Offset#
	if (y < 0) y <- 0#
	return(y)#
}#
#
#
#
## The make.cache.medusa function is like the first half of the original splitEdgeMatrix().#
## It works through and reorders the edges, then works out start and end times of these#
## based on the phylogeny's branching times.#
###
## In addition, every node's ancestors are also calculated.  The element 'anc' is a list.#
## $anc[i] contains the indices within $edge, $t.start, etc., of all ancestors of node 'i'#
## (in ape node numbering format).#
## #
## If multiple fossil observances present for a lineage, tie all to same ancestor#
make.cache.medusa <- function(phy, richness, mc, num.cores)#
{#
	if (is.null(richness)) {stop("This should not be possible.")}#
	#
# Fix for condition where there are only two branches (i.e. no internal)#
	#
	n.tips <- length(phy$tip.label)#
	n.int <- nrow(phy$edge) - n.tips#
	bt <- branching.times(phy)#
	#
# Broken up to more easily parse fossil information; consider only internal edges first#
	if (n.int > 1)#
	{#
		i.int <- seq_len(n.int)#
		interior <- phy$edge[,2] %in% phy$edge[,1]#
		#
		edges.int <- phy$edge[interior,]#
		colnames(edges.int) <- c("anc", "dec")#
		#
		t.0 <- bt[match(edges.int[,1], (n.tips+1):max(edges.int))]#
		t.1 <- c(t.0[i.int] - phy$edge.length[interior])#
		#
		z.internal <- cbind(edges.int, t.0, t.1, t.len=t.0 - t.1,#
			n.0=rep(1, n.int), n.t=rep(NA, n.int))#
	}#
	#
# Now, pendant edges; #
# Assume that if multiple fossils per taxon, use same 'taxon' and [optionally] 'exemplar'#
	edges.pendant <- phy$edge[match(seq_len(n.tips), phy$edge[,2]),]#
	colnames(edges.pendant) <- c("anc", "dec")#
	#
	t.0 <- bt[match(edges.pendant[,1], (n.tips+1):max(edges.pendant))]#
	#
	z.pendant <- data.frame() # Put each (sub)edge on a separate row#
	#
	#
# *** Is there a way to do this without the for loop?#
#
	# if (length(phy$tip.label) == length(richness[,1])) # if no fossils, can disregard a lot of matching#
	# {#
		#
	# } else {#
		# for (i in 1:n.tips) # *** This is the slow bit; only used for fossils.#
		# {#
			# i.taxon <- which(richness$taxon == phy$tip.label[i])#
			# tmp  <- data.frame()#
			# anc=edges.pendant[i,"anc"]#
			# dec=edges.pendant[i,"dec"]#
			# cur.r0 <- 1#
			# cur.t0 <- t.0[i]#
			#
			# tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
			# z.pendant <- rbind(z.pendant, tmp)#
		# }#
	# }#
#
#
	for (i in 1:n.tips)#
	{#
		i.taxon <- which(richness$taxon == phy$tip.label[i]) # May have multiple entties due to mutliple fossil observances#
		tmp  <- data.frame()#
		anc=edges.pendant[i,"anc"]#
		dec=edges.pendant[i,"dec"]#
		cur.r0 <- 1#
		cur.r1 <- richness$n.fossils[i.taxon[1]]#
		cur.t0 <- t.0[i]#
		cur.t1 <- richness$f.time[i.taxon[1]]#
		#
		if (is.na(cur.r1)) # no fossils#
		{#
			tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0,#
				t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
		} else { # n fossils; split into n+1 rows#
			for (j in 1:length(i.taxon))#
			{#
				foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
					t.1=cur.t1, t.len=cur.t0-cur.t1, n.0=cur.r0, n.t=cur.r1)#
				tmp <- rbind (tmp, foo)#
				#
				cur.r0 <- cur.r1#
				cur.t0 <- cur.t1#
				if (j != length(i.taxon))#
				{#
					cur.r1 <- richness$n.fossils[i.taxon[j+1]]#
					cur.t1 <- richness$f.time[i.taxon[j+1]]#
				}#
			}#
			foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
				t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon[1]])#
			tmp <- rbind (tmp, foo)#
		}#
		z.pendant <- rbind(z.pendant, tmp)#
	}#
	#
	if (n.int > 1) {z <- rbind(z.internal, z.pendant)#
	} else {z <- z.pendant}#
	z <- cbind(z,partition=rep(1, length(z[,1]))) # Stores piecewise model structure#
	rownames(z) <- NULL#
	#
# Used for identifying ancestral nodes below i.e. tracking breakpoints#
	all.edges <- as.matrix(z[,c("anc","dec")])#
	#
	if (mc)#
	{#
		list(z=z, anc=mclapply(seq_len(max(all.edges)), ancestors.idx, all.edges), mc.cores=num.cores)#
	} else {#
		list(z=z, anc=lapply(seq_len(max(all.edges)), ancestors.idx, all.edges))#
	} # And, we're good to go...#
}#
#
#
#
## This generates the indices of all ancestors of a node, using ape's edge matrix.#
## Deals with row numbers of the edge matrix rather than node numbers of the tree#
ancestors <- function(node, all.edges)#
{#
	ans <- node#
	repeat#
	{#
		node <- all.edges[all.edges[,1] %in% node,2]#
		if (length(node) > 0) {ans <- c(ans, node)} else {break}#
	}#
	unlist(ans)#
}#
#
## The function 'ancestors' returns the indices of all ancestors within the edge matrix.#
ancestors.idx <- function(node.list, all.edges)#
{#
	which(all.edges[,1] == node.list | all.edges[,2] %in% ancestors(node.list, all.edges))#
}#
#
#
## Needed for determining whether nodes are virgin nodes#
getNumTips <- function(node, phy)#
{#
	n <- length(node.leaves(phy,node))#
	return(n)#
}#
#
#
#
## Only used for base model#
medusa.ml.initial <- function(z, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
#	rootnode <- min(z[is.na(z[,"n.t"]),1]) # doesn't work if only two branches (i.e. no NA)#
	#
	rootnode <- min(z[,"anc"])#
	obj <- medusa.ml.fit.partition(1, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	modelFit <- calculateModelFit(fit=obj, z, est.extinction, epsilon.value)#
	#
	if (est.extinction)#
	{#
		list(par=matrix(obj$par, nrow=1, dimnames=list(NULL,c("r", "epsilon"))), lnLik.part=obj$lnLik, #
		   lnLik=obj$lnLik, split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	} else {#
		list(par=matrix(obj$par, nrow=1,dimnames=list(NULL,"r")), lnLik.part=obj$lnLik, lnLik=obj$lnLik,#
		   split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	}#
}#
#
#
## Pre-fit values for pendant edges; DON'T recalculate later; should account for ~25% of all calculations#
medusa.ml.prefit <- function(node, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
# Partition '2' represents the pendant edge#
	fitted <- medusa.ml.fit.partition(2, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	return(fitted)#
}#
#
#
#
## 'fit' contains parameter value(s) from previous model, used to initialize subsequent model#
## Pass in pre-fitted values for pendant edges; DON'T recalculate #
medusa.ml.update <- function(node, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
	aff <- obj$affected#
	#
	op <- fit$par#
	sp <- op[aff[1],] # Use previously fit parameter values from clade that is currently being split#
	#
	fit1 <- medusa.ml.fit.partition(aff[1], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	fit2 <- 0#
	#
## Check if pendant; calculations already done#
	if (node < root.node)#
	{#
		fit2 <- tips[[node]]#
## Check if virgin node; save more time!#
	} else if (length(unique(z[(z[,"partition"] == aff[2] & z[,"dec"] < root.node),"dec"])) == num.tips[[node]])#
	{#
		fit2 <- virgin.nodes[[node - root.node]]#
## Novel arrangement; need to calculate#
	} else {#
		fit2 <- medusa.ml.fit.partition(aff[2], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	}#
	#
	op[aff[1],] <- fit1$par # Replace parameters with new values for diminished clade#
	fit$par <- rbind(op, fit2$par)#
	fit$lnLik.part[aff] <- c(fit1$lnLik, fit2$lnLik) # Replace parameters with new values for diminished clade#
	fit$split.at <- c(fit$split.at, node)#
	fit$lnLik <- sum(fit$lnLik.part)#
	#
	modelFit <- calculateModelFit(fit, z, est.extinction, epsilon.value)#
	#
	fit$aic <- modelFit[1]#
	fit$aicc <- modelFit[2]#
	fit$num.par <- modelFit[3]#
	#
	return(fit)#
}#
#
#
#
## Split the edge matrix 'z' by adding a partition rooted at node 'node'.#
##   Note: in original MEDUSA parlance, this is cutAtStem=T.#
## The list 'anc' is a list of ancestors (see make.cache.medusa, above).#
## Returns a list with elements:#
##   z: new medusa matrix, with the new partition added#
##   affected: indices of the partitions affected by the split (n == 2).#
# Add cutAtStem = F option. Allow both within a single analysis?!?#
medusa.split <- function(node, z, anc)#
{#
	part <- z[,"partition"]#
	base <- min(part[z[,1] == node | z[,2] == node])#
	tag <- max(part) + 1#
#
	i <- anc[[node]]#
	idx <- i[part[i] == base]#
	z[idx,"partition"] <- tag#
	#
	z[which(z["dec"] == node),"partition"] <- tag # Possible to have several edges to consider#
#
	list(z=z, affected=c(unique(part[idx]), tag))#
}#
#
#
#
## sp = initializing values for r & epsilon#
## Default values should never be used (except for first model), as the values from the previous model are passed in.#
medusa.ml.fit.partition <- function(partition, z, est.extinction, epsilon.value, sp=c(0.1, 0.05), fossil.minimum)#
{#
# Construct likelihood function:#
	lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
	#
	if (est.extinction) # Possibly give a range of initializing values to "navigate the banana"#
	{#
		fit <- optim(fn=lik, par=sp, method="N", control=list(fnscale=-1))#
		list(par=fit$par, lnLik=fit$value)#
	} else {#
		fit <- optimize(fn=lik, interval=c(0, 1))  # check on a valid range#
		list(par=fit$minimum, lnLik=fit$objective)#
	}#
}#
#
#
#
## make.lik.medusa.part: generate a likelihood function for a single partition.#
###
## In the pendant calculations, the variables 'A' and 'B' are the A and B terms#
## in Foote et al. Science: 283 1310-1314, p. 1313, defined as:#
## #
##   A: probability of extinction of one lineage over time 't'#
##   B: A * lambda / mu OR A / epsilon#
###
## Where there is a single lineage at time 0 (a==1), the calculation is#
##   log(1 - A) + log(1 - B) + (n-1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1-A) on a log scale) which cancels to give:#
##   log(1 - B) + (n-1)*log(B)#
## when pendant richness==1 the calculation is even simpler:#
##   log(1 - B)#
###
## When a > 1 (more than one starting species; will only happen coming off of a fossil observation),#
## the calculations follow Foote et al. 1999, put into the function 'foote.fossil.pendant'.#
## 'est.extinction' determines whether yule model is assumed#
## 'epsilon.value', if != NULL, fixes epsilon for all partitions, estimates r; not yet implemented#
## 'fossil.minimum', if == FALSE, treat fossils as exact counts#
## Only one 'partition' is passed in at a time from a proposed split.#
make.lik.medusa.part <- function(partition, est.extinction=TRUE, epsilon.value=NULL, fossil.minimum=T)#
{#
#
# Handle internal, fossil, and pendant edges separately#
	is.int <- is.na(partition[,"n.t"])#
	is.fossil <- (partition[,"n.0"] > 1) | (partition[,"t.1"] > 0 & !is.int)#
	is.pend <- !is.int == !is.fossil # pendant edges *without* fossils#
	#
	n.int <- sum(is.int)#
	n.fossil <- sum(is.fossil)#
	n.pend <- sum(is.pend)#
	#
	if (n.int + n.fossil + n.pend != length(partition[,1])) stop("You messed up, yo.")#
	#
## Internal and pendant calculations differ; split'em up#
	int  <- partition[is.int,,drop=FALSE]#
	foss <- partition[is.fossil,,drop=FALSE]#
	pend <- partition[is.pend,,drop=FALSE]#
	#
	sum.int.t.len <- sum(int[,"t.len"])  # Simply sum all internal edges#
	int.t.0 <- int[,"t.0"]#
	#
# 'n.0' = Foote's 'a', initial diversity; 'n.t' = Foote's 'n', final diversity#
	pend.n.0 <- pend[,"n.0"] # Foote's 'a': initial diversity#
	pend.n.t <- pend[,"n.t"] # Foote's 'n': final diversity#
	pend.t.len <- pend[,"t.len"]#
	#
# Don't need much of this shit anymore#
	foss.n.0 <- foss[,"n.0"]   # Not necessarily equal 1 anymore#
	foss.n.t <- foss[,"n.t"]#
	foss.t.len <- foss[,"t.0"] - foss[,"t.1"]#
	#
# User may pass in epsilon; don't change it, just estimate r#
	f <- function(pars)#
	{#
		if (est.extinction == TRUE)#
		{#
			r <- pars[1]#
			epsilon <- pars[2]#
	#		bd <- get.b.d(r, epsilon)   # Not necessary#
	#		b <- bd$b#
	#		d <- bd$d#
			#
# Previous version where b & d were estimated:#
	#		b <- pars[1]#
	#		d <- pars[2]#
	#		r <- abs(b - d)#
	#		epsilon <- d / b#
			#
			if (r < 0 | epsilon <= 0 | epsilon >= 1) {return(-Inf)}#
		} else {#
## Implement pure birth; not currently working (for some reason). Not immediately urgent, as won't work with fossils anyway#
			r <- pars[1]#
			d <- 0#
			b <- r#
			epsilon <- 0#
			#
			if (r < 0) {return(-Inf)}#
		}#
		#
		if (n.int == 0) {l.int <- 0} else {#
## Likelihood of internal edges from Rabosky et al. (2007) equation (2.3):#
			l.int <- n.int * log(r) - r * sum.int.t.len - sum(log(1 - (epsilon * exp(-r * int.t.0))))#
# Under Yule, should be: l.int <- n.int * log(r) - r * sum.int.t.len#
#
		}#
		#
		if (n.pend == 0) {l.pend <- 0} else {#
## Calculations are from the following:#
## Rabosky et al. 2007. Proc. Roy. Soc. 274: 2915-2923.#
## Foote et al. 1999. Science. 283: 1310-1314#
## Raup. 1985. Paleobiology 11: 42-52 [Foote et al. correct the equation [A18] where a > 1]#
## Bailey. 1964. The Elements Of Stochastic Processes, With Applications To The Natural Sciences#
## Kendall. 1948. Ann. Math. Stat. 19: 1–15.#
###
## A = probability of extinction of one lineage over time 't'#
## B = A * (lambda/mu)#
###
## When there is a single lineage at time 0 (a = 1), the calculation is#
##   log(1 - A) + log(1 - B) + (n - 1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1 - A) on a log scale) which cancels to give:#
##   log(1 - B) + (n - 1)*log(B)#
##      - for n.t == 1, reduces further to log(1-B)#
###
## A = mu*(exp((lambda - mu)*t) - 1)) / (lambda*exp((lambda - mu)*t) - mu)#
##  let r = (lambda - mu); ert = exp((lambda - mu)*t)#
## A = mu*(ert - 1)/(lambda*ert - mu)#
###
## B = A * (lambda/mu)#
##   = [mu*(ert - 1)/(lambda*ert - mu)] * (lambda/mu)#
##   = (lambda*(ert - 1))/(lambda*ert - mu)#
##   = (lambda*(ert - 1))/(lambda(ert - mu/lambda))#
##   = (ert - 1) / (ert - epsilon)#
#
## All pendant nodes begin with richness '1'; calculations simple.#
#			i.pend.n.t.1 <- which(pend.n.t == 1)   # calculations even simpler: log(1-B)#
#			i.pend.n.t.n1 <- which(pend.n.t != 1)#
			#
			ert <- exp(r * pend.t.len)#
			B <- (ert - 1) / (ert - epsilon) # Equivalently: B <- (bert - b) / (bert - d)#
			#
	# Under Yule should be: B <- (ert - 1) / ert#
			#
	# separate out calculations; likely not any faster (slower?)#
#			l.pend.1 <- sum(log(1 - B[i.pend.n.t.1]))#
#			l.pend.n1 <- sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
#			l.pend <- l.pend.1 + l.pend.n1#
			#
#			l.pend <- sum(log(1 - B[i.pend.n.t.1])) + #
#			   sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
			#
			l.pend <- sum(log(1 - B) + (pend.n.t - 1)*log(B)) # equivalent single formula version#
		}#
		#
# Fossils!#
		if (n.fossil == 0) {l.fossil <- 0} else {#
#
# What is desired: P(n,t,N,T) = P(n,t,1)*P(N,T-t,n)#
# - each term (internal node to fossil, and fossil to pendant node) is conditioned on survival (dividing by [1-(P(0,t,a)]^a)]#
#
			if (fossil.minimum) # loop counts from 1 -> n-1 fossils; *** NEED TO SPEED THIS SHIT UP! ***#
			{#
## First consider path from internal node to fossil, conditioning on survival (i.e. divide by (1-A)^a, although 'a' is always 1 here):#
##  sum(over x from 1 to n-1) [(1-B)*B^(x-1)]#
				#
	### *** BROKEN!!! *** ####
	#
# *** UPDATE TO NEW FORMAT ***#
				#
				ert <- exp(r * foss.t.len)#
				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
			# Under Yule should be: B <- (ert - 1) / ert#
				#
				sum.prob.int.fossil <- numeric(length(foss.n.t))#
				for (i in 1:n.fossil)#
				{#
					tmp <- 0#
					for (j in 1:foss.n.t[i])#
					{#
						tmp <- sum((B.1[i]^(j-1)), tmp)#
					}#
					sum.prob.int.fossil[i] <- (1 - B.1[i]) * tmp # (1-B) brought outside sum, as it is present in every term#
				}#
				#
# Now consider path from fossil to pendant node; looping bits in 'foote.fossil.pendant.minimum'#
				ert <- exp(r * foss.t.len)#
				A <- (ert - 1) / ((ert/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.2 <- A / epsilon                   # Equivalently: B.2 <- A * (b/d)#
				#
			# Using raw probabilities:#
				sum.prob.fossil.pend <- foote.fossil.pendant.minimum(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(log(1 - (sum.prob.int.fossil * sum.prob.fossil.pend)))#
				#
			# Using log-scale values:#
#				sum.prob.fossil.pend <- foote.fossil.pendant.combined(foss.n.t, foss.n.t, A, B.2, fossil.minimum)#
#				l.fossil <- sum(log(1 - (sum.prob.int.fossil * exp(sum.prob.fossil.pend))))#
				#
			} else { # No looping; pretty fast#
# Two scenarios:#
# 1. coming off internal node (i.e. n.0 = 1); same calculation as above#
	# log(1 - B) + (n - 1)*log(B)#
# 2. coming off fossil (i.e. n.0 > 1); need Foote equations#
				off.node <- which(foss[,"n.0"] == 1)#
				off.fossil <- which(foss[,"n.0"] != 1)#
				#
	# First, off node; n.0 = 1#
				ert.off.node <- exp(r * foss[off.node,"t.len"]) # internal node to fossil#
				B.off.node <- (ert.off.node - 1) / (ert.off.node - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
				l.off.node <- sum(log(1 - B.off.node) + (foss[off.node,"n.t"] - 1)*log(B.off.node))#
				#
#				ert <- exp(r * foss.t.len) #
#				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
		# Under Yule should be: B <- (ert - 1) / ert#
				#
				ert.off.fossil <- exp(r * foss[off.fossil,"t.len"])        # fossil to pendant node or next fossil#
				A <- (ert.off.fossil - 1) / ((ert.off.fossil/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.off.fossil <- A / epsilon                                         # Equivalently: B.2 <- A * (b/d)#
				l.off.fossil <- foote.fossil.pendant.exact(foss[off.fossil,"n.0"], foss[off.fossil,"n.t"], A, B.off.fossil)#
				#
#				l.fossil <- sum(log(1 - B.1) + (foss.n.t - 1)*log(B.1)) + #
#				   foote.fossil.pendant.exact(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(l.off.node, l.off.fossil)#
			}#
		}#
		l.int + l.pend + l.fossil#
	}#
#	l.int + l.pend + l.fossil#
}#
#
#
## Calculates the probability of having *exactly* 'a' fossils and ending with *exactly* 'n' extant species.#
## Use only when 'a', starting richness, > 1 (i.e. if coming off a fossil count).#
## For 'off-fossil' calculations, richness may increase or decrease.#
foote.fossil.pendant.exact <- function(a, n, A, B)#
{#
	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
	lB <- log(B)#
	l1mA <- log(1 - A)#
	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
	l1mB <- log(1 - B)#
	l1mA1mB <- l1mA + l1mB#
	#
#	min.a.n <- pmin(a, n) # *Insanely* slow!#
	min.a.n <- pmin.int(a, n)#
	#
	l.exact.fossil <- numeric(length(min.a.n))#
	#
	for (i in 1:length(a))#
	{#
		ji <- seq_len(min.a.n[i])#
		ai <- a[i]#
		ni <- n[i]#
		#
#		tmp <- lchoose(ai, ji) + lchoose(ni - 1, ji - 1) + (ai - ji)*lA[i] + ji*l1mA1mB[i] + (ni - ji)*lB[i]#
		#
# Non-logspace version much faster#
		foo <- choose(ai, ji) * choose(ni - 1, ji - 1) * A[i]^(ai - ji) * ((1-A[i])*(1-B[i]))^ji * B[i]^(ni - ji)#
		tmp <- sum(foo)#
		#
## Conditioning on survival factors out of the sum:#
		l.exact.fossil[i] <- sum(tmp)/(r1mA.exp.a[i])#
		#
#		l.exact.fossil[i] <- logspace_sum(tmp) - l1mA.exp.a[i] # logspace_sum: calculate log(x+y) from log(x) and log(y)#
	#	l.exact.fossil[i] <- logspace_sum(tmp) - l1mA[i]  # old conditioning; not appropriate for a > 1#
	}#
#
#	sum(l.exact.fossil)#
	return(sum(log(l.exact.fossil)))#
}#
#
#
## Calculates the probability of having *at least* 'a' fossils and ending with exactly 'n' extant species.#
## Richness may increase or decrease.#
## Should this be computed on a log-scale?#
# *** THIS IS BROKEN ***#
foote.fossil.pendant.minimum <- function(a, n, A, B)#
{#
#	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
#	lB <- log(B)#
#	l1mA <- log(1 - A)#
#	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
#	l1mB <- log(1 - B)#
#	l1mA1mB <- l1mA + l1mB#
	#
	sum.prob.fossil.pend <- numeric(length(a))#
	#
	for (i in 1:length(a)) # Loop over fossils#
	{#
		tmp <- numeric(a[i]-1)#
		for (k in 1:(a[i]-1)) # For fossil i loop over from 1 to n[i]-1#
		{#
			ai <- k#
			ni <- n[i]#
			min.a.n <- pmin.int(ai, ni)#
#			min.a.n <- pmin(ai, ni) # *Insanely* slow! pmin.int saves 70s on a 107s job! WTF?!?#
	   		j <- seq_len(min.a.n)#
			#
	# *** Should this be put on a log scale to preserve precision? ***#
	  # Tests with reasonable data yield the same answer either way#
			foo <- choose(ai, j) * choose(ni - 1, j - 1) * A[i]^(ai - j) * ((1-A[i])*(1-B[i]))^j * B[i]^(ni - j)#
			tmp[k] <- sum(foo)#
	# Alternate log form:#
	  # foo <- lchoose(ai, j) + lchoose(ni - 1, j - 1) + (ai - j)*lA[i] + j*l1mA1mB[i] + (ni - j)*lB[i]#
	    }#
	#  	tmp[i] <- sum(tmp)/(1-A[i])  # old conditioning; not appropriate for a > 1#
			#
# Conditioning on survival factors out of the sum:#
		sum.prob.fossil.pend[i] <- sum(tmp)/(r1mA.exp.a[i])#
	# Alternate log form:#
	  #	foo <- (logspace_sum(tmp))#
	  #	sum.prob.fossil.pend[i] <- foo - l1mA.exp.a[i]#
	}#
#
	return(sum.prob.fossil.pend)#
}#
#
#
## 'fit' contains '$par' and '$lnlik'#
calculateModelFit <- function(fit, z, est.extinction, epsilon.value)#
{#
## Sample size taken (for now) as the total num.nodes in the tree (internal + pendant) plus num.fossil observations#
  # num.nodes = (2*length(phy$tip.label) - 1) == (2*length(richness[,1]) - 1) == length(z[,1]) + 1#
#	n <- (length(z[,1]) + 1) + sum(!is.na(z[,"n.f"]))#
	#
# Changed structure of data; no longer have z[,"n.f"]#
# Instead, each row of z constitutes an edge#
# Since each edge defines either a node or a fossil (i.e. an 'observation'), need only add root node as final obervation#
	n <- (length(z[,1]) + 1)#
	#
## Number of parameters estimated depends on values of est.extinction and epsilon.value#
  # Includes both formal parameters AND number of breaks. Note: first model does not involve a break.#
## Models where all parameters are estimated:#
  # 2 parameters for base model (no breakpoint) + 3 parameters (r, eps, breakpoint) for each subsequent model#
## Models where only one parameter is estimated:#
  # 1 parameter for base model (no breakpoint) + 2 parameters (r, breakpoint) for each subsequent model#
	#
	if (length(fit$par) < 3) # i.e. base model#
	{#
		num.models <- 1#
	} else {#
		num.models <- length(fit$par[,1])#
	}#
	#
	if (est.extinction == FALSE || !is.null(epsilon.value)) # only one parameter estimated (plus breakpoint)#
	{#
		k <- 1 + (2 * (num.models - 1))#
	} else {#
		k <- 2 + (3 * (num.models - 1))#
	}#
	#
	lnLik <- fit$lnLik#
	#
	aic <- (-2 * lnLik) + (2*k)#
	aicc <- aic + 2*k*(k+1)/(n-k-1)#
	#
	modelFit <- c(aic, aicc, k)#
	return(modelFit)#
}#
#
#
## Prints out a table of likelihoods, parameters, aic scores, and aic weights (delta-aics are also available, if desired)#
calculateModelFitSummary <- function (models, phy, plotFig, fig.title=NULL, ...)#
{#
	tmp <- matrix(nrow=(length(models)), ncol=6)#
	colnames(tmp) <- c("N.Models", "Break.Node", "Ln.Lik", "N.Param", "aic", "aicc")#
	#
	w.aic <- numeric(length(models))#
	w.aicc <- numeric(length(models))#
	#
	for (i in 1:length(tmp[,1]))#
	{#
		tmp[i,] <- c(i, as.integer(models[[i]]$split.at[i]), models[[i]]$lnLik, models[[i]]$num.par, models[[i]]$aic, models[[i]]$aicc)#
	}#
	#
	all.res <- as.data.frame(tmp)#
	all.res[1,2] <- NA # root node for base model#
	#
	w.aic <- calculateModelWeights(all.res$aic)#
	w.aicc <- calculateModelWeights(all.res$aicc)#
	#
	all.res <- cbind(all.res[,c(1:5)], w.aic=w.aic$w, aicc=all.res$aicc, w.aicc=w.aicc$w)#
	#
	if (plotFig)#
	{#
		dev.new()#
		plotModelFit(all.res)#
		if (!is.null(fig.title)) {title(main=fig.title, cex.main=0.75)}#
	}#
	return(all.res)#
}#
#
calculateModelWeights <- function (fit)#
{#
	best <- min(fit)#
	delta <- fit-best#
	sumDelta <- sum(exp(-0.5 * delta))#
	w <- (exp(-0.5 * delta)/sumDelta)#
	#
	results <- data.frame(fit=fit,delta=delta,w=w)#
	#
	return(results)#
}#
#
plotModelFit <- function (all.res)#
{#
	ylim <- c(min(all.res[,"aic"],all.res[,"aicc"]), max(all.res[,"aic"],all.res[,"aicc"]))#
	plot(all.res[,"N.Models"],all.res[,"aicc"], xlab="Number of Piecewise Models", ylab="Model Fit", ylim=ylim, type="l", col="blue")#
	points(all.res[,"N.Models"],all.res[,"aicc"], col="blue", pch=21, bg="white")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", type="l")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", pch=21, bg="white")#
	#
	legend("topleft", c("aicc","aic"), pch=21, pt.bg="white", lty=1, col=c("blue", "black"), inset = .05, cex=0.75, bty="n") # 'bottomright' also works#
}#
#
logspace_sum <- function(logx)#
{#
	r <- logx[1]#
	if (length(logx)>1)#
	{#
		for (i in 2:length(logx)) {r <- logspace_add(r, logx[i])}#
	}#
	return(r)	#
}#
#
# Calculate log(x+y) from log(x) and log(y)#
logspace_add <- function(logx, logy)#
{#
	if (logx == -Inf)#
	{#
		return(logy)#
	} else {#
		max(logx, logy) + log1p(exp (-abs (logx - logy)))#
	}#
}#
#
#
# Print out results from a given piecewise model. May be:#
#   1. optimal model under aicc: the default#
#   2. optimal model under aic: through setting "aic=T"#
#   3. aicc model using threshold improvement (like original MEDUSA): through setting "threshold" to some value#
#   4. aic model using threshold improvement (like original MEDUSA): through setting "aic=T" and "threshold" to some value#
#   5. user-selected model: through setting "model" to some integer value (from summary table)#
# In any case, also print out base model for comparison#
# Need to parse 'results' (list of lists). Contains elements:#
#  $models, which contains:#
#     $par: i x 2 matrix (for birth-death; i x 1 for pure-birth); the jth row contains #
#       the speciation and (optional) extinction rate for the jth rate class#
#     $lnLik.part: vector of length i; the jth element is the partial log#
#       likelihood value due to the jth rate class#
#     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
#     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
#  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
#  $z: a matrix listing branch times and richnesses; for summarizing results#
#  $anc: a list of all ancestors; for summarizing results#
#  $modelSummary: data.frame listing considered models, likelihoods, number of paramters, aicc, aicc, Akaike weights.#
#
#threshold=0; aic=F; plotTree=F; time=T; cex=0.5; plotSurface=T; est.extinction=T; fossil.minimum=F; n.points=100; node.labels=T;#
#r.interval=c(0.0000001,0.9999999); e.interval=r.interval; model=NULL;#
#
summarizeFossilMEDUSA <- function(results, model=NULL, cutoff="threshold", criterion="aicc", plotTree=TRUE, time=TRUE,#
	node.labels=TRUE, cex=0.5, plotSurface=FALSE, est.extinction=TRUE, fossil.minimum=FALSE, r.interval=c(1e-10,1.0),#
	e.interval=r.interval, n.points=100, ...)#
{#
# Desirables:#
#  1. table listing parameter values of selected model#
#  2. list parameters of base model#
#  3. tree printed with colour-coded edges, node labels to indicate split position(s)#
#  4. plot likelihood surface#
	#
# Extract constituent components from results#
	fit <- results$models#
	phy <- results$phy#
	z <- results$z#
	anc <- results$anc#
	modelSummary <- results$modelSummary#
	threshold <- results$threshold#
	#
# First, determine which model is desired#
	model.id <- 0#
	if (!is.null(model))#
	{#
		model.id <- model#
	} else {   # Find best model using threshold criterion#
		if (cutoff != "threshold") {threshold <- cutoff} else {#
			cat("\nSelecting model based on corrected threshold (decrease in information theoretic score of ", -threshold, " units).\n", sep="")}#
		model.id <- 1#
		while (1)#
		{#
			if ((model.id + 1) > length(fit)) break;#
			if ((unlist(fit[[model.id]][criterion]) - unlist(fit[[model.id+1]][criterion])) > threshold) break;#
			model.id <- model.id + 1#
		}#
	}#
	#
	break.pts <- fit[[model.id]]$split.at#
	opt.model <- as.data.frame(cbind(Split.node=break.pts, fit[[model.id]]$par, LnLik.part=fit[[model.id]]$lnLik.part))#
	base.model <- as.data.frame(fit[[1]]$par)#
	#
	cat("\nEstimated parameter values for model #", model.id, ":\n\n", sep="")#
	print.data.frame(opt.model, digits=5)#
	opt.weight <- 0#
	optFit <- 0#
	base.weight <- 0#
	baseFit <- 0#
	if (criterion == "aicc")#
	{#
		opt.weight <- modelSummary$w.aicc[model.id]#
		optFit <- modelSummary$aicc[model.id]#
		base.weight <- modelSummary$w.aicc[1]#
		baseFit <- modelSummary$aicc[1]#
	} else { # aic used#
		opt.weight <- modelSummary$w.aic[model.id]#
		optFit <- modelSummary$aic[model.id]#
		base.weight <- modelSummary$w.aic[1]#
		baseFit <- modelSummary$aic[1]#
	}#
	cat("\nModel fit summary for model #", model.id, ":\n\n", sep="")#
	cat("\tLog-likelihood = ", as.numeric(results$models[[model.id]]["lnLik"]), "\n", sep="")#
	cat("\t", criterion, " = ", optFit, "\n", sep="")#
	cat("\t", criterion, " weight = ", opt.weight, "\n\n", sep="")#
	#
	if (model.id != 1)#
	{#
		cat("\nFor comparison, estimated values for the base model are:\n\n")#
		print.data.frame(base.model, digits=5, row.names=F)#
		cat("\nModel fit summary for base model:\n\n", sep="")#
		cat("\tLog-likelihood = ", as.numeric(results$models[[1]]["lnLik"]), "\n", sep="")#
		cat("\t", criterion, " = ", baseFit, "\n", sep="")#
		cat("\t", criterion, " weight = ", base.weight, "\n\n", sep="")#
	}#
	#
# Get desired tree-model conformation#
	if (length(break.pts) > 1)#
	{#
		for (i in 2:length(break.pts))#
		{#
			tmp <- medusa.split(break.pts[i], z, anc)#
			z <- tmp$z#
		}#
	}#
	#
	#
	#
	#
# Temporary workaround#
	epsilon.value <- NULL#
	#
	#
# Plot tree with purdy colours and labelled nodes (to better map between tree and table)#
	if (plotTree)#
	{#
		dev.new()#
		margin <- F#
		#
# This need to be changed to reflect new structure#
		mm <- match(phy$edge[,2], z[,"dec"])#
		if (time) {margin=T}#
#		plot(phy, edge.color=z[mm,10], no.margin=!margin, cex=cex, ...)#
		plot(phy, edge.color=z[mm,"partition"], no.margin=!margin, cex=cex, ...)#
		if (time)#
		{#
			axisPhylo(cex.axis=0.75)#
			mtext("Divergence Time (MYA)", at=(max(get("last_plot.phylo", envir = .PlotPhyloEnv)$xx)*0.5), side = 1, line = 2, cex=0.75)#
		}#
		if (node.labels)#
		{#
			for (i in  1:length(break.pts))#
			{#
				nodelabels(i, node= break.pts[i], frame = "c", font = 1, cex=0.5)#
			}#
		}#
	}#
	#
	if (plotSurface)#
	{#
		n.pieces <- length(opt.model[,1])#
		dev.new()#
		#
		if ((sqrt(n.pieces)) == round(sqrt(n.pieces)))  #make square plotting surface#
		{#
			op <- par(mfrow=c(sqrt(n.pieces),sqrt(n.pieces)))#
		} else {#
			layout(matrix(1:n.pieces))#
		}#
		#
#	min.r <- 0.000001#
#	max.r <- max(opt.model["r"]) * 2#
		#
		if (n.pieces > 1) {cat("Computing surfaces...\n")} else {cat("Computing surface...")}#
		for (k in 1: n.pieces)#
		{#
			partition <- k#
			#
			lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
			#
			lik.vals <- matrix(nrow=n.points, ncol=n.points)#
			r.vals <- seq(from=r.interval[1], to=r.interval[2], length.out=n.points)#
			eps.vals <- seq(from=e.interval[1], to=e.interval[2], length.out=n.points)#
			#
			for (i in 1:length(r.vals))#
			{#
				for (j in 1:(length(eps.vals))) {lik.vals[i,j] <- lik(pars=c(r.vals[i], eps.vals[j]))}#
			}#
			if (n.pieces > 1) {cat("Completed computing surface for piecewise model #", k, "\n", sep="")}#
			else {cat (" done.\n")}#
		#
# Perspective plot#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood", theta=-45, phi=45)#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood")#
#	points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
#	points(x=best.r, y=best.eps, pch=16, col="blue")#
#	points(modelSummary$Ln.Lik[model.id], x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
	#
	#
	#
	#
## *** Can check on distance between MLE and best point evaluated above; if large, advize evaluating further points#
# Perhaps determine the correct number of points this way automatically?#
	#
	#
	#
	#
# Contour plot#
			#
	# This shit is only good for determining the best number of points to evaluate#
			max.lik <- max(lik.vals,na.rm=T)#
			best.r <- numeric()#
			best.eps <- numeric()#
			#
# Need to figure out which parameter values lead to this likelihood...#
			i.best <- which(lik.vals==max.lik)#
			if (length(i.best) > 1) {i.best <- i.best[1]} # if more than one combination gives best value, just grab first#
			#
	# the following determines, from the r/eps sequences, where in the the likelihood matrix the MLE lies#
			if (i.best > n.points)#
			{#
				best.r <- r.vals[i.best%%n.points]#
				best.eps <- eps.vals[ceiling(i.best/n.points)]#
			} else {#
				best.r <- r.vals[i.best]#
				best.eps <- eps.vals[1]#
			}#
#			cat("Best likelihood found: ", max.lik, " for parameter combination #", i.best, "\n", sep="")#
			#
			#
			max.lik <- as.numeric(opt.model[partition,"LnLik.part"])  # MLE#
			lines <- c(max.lik-0.5, max.lik-1, max.lik-2, max.lik-3, max.lik-4, max.lik-5, max.lik-10, max.lik-50, max.lik-100)#
			contour(lik.vals, levels=lines, labels=c(0.5, 1, 2, 3, 4, 5, 10, 50, 100), axes=FALSE, xlab="r (b-d)", ylab="epsilon (d/b)")#
			tics<-floor(c(1, n.points/4, n.points/2, n.points*3/4, n.points))#
			axis(1, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(r.vals[tics], 3))#
			axis(2, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(eps.vals[tics], 3))#
			points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red") # inferred ML values#
#			points(x=best.r, y=best.eps, pch=16, col="blue") # best from surface samples#
#			legend("topright", c("ML","Best from sampled surface"), pch=16, col=c("red", "blue"), inset = .05, cex=0.75, bty="n")#
			legend("topright", "ML", pch=16, col="red", inset = .05, cex=0.75, bty="n")#
			if (n.pieces > 1) {title(main=paste("Piecewise model #", k, sep=""))}#
		}#
	}#
}#
#
#
#
#
#
#
#
#
# *** NOT used ***#
#
#
## Get b and d values from r (b-d) and epsilson (d/b)#
## Used in previous version of program; now in terms of r and epsilon#
## Possibly of use to users wishing to translate results#
get.b.d <- function(r, epsilon)#
{#
	b <- r/(1-epsilon)#
	d <- b-r   # Alternatively: d <- eps*r/(1-eps)#
	return(list(b=b, d=d))#
}#
#
## Print out tree with ape-style node-numbering#
## Possibly of interest for users to identify numbers of node(s) off interest#
 ## If this is the case, make sure to pass in pruned tree#
plotNN <- function (phy, time=TRUE, margin=TRUE, label.offset=0.5, cex=0.5, ...) #
{#
	phy$node.label <- (length(phy$tip.label) + 1):max(phy$edge)#
	plot.phylo(phy, show.node.label=TRUE, no.margin=!margin, label.offset=label.offset, cex=cex, ...)#
	if (time && !margin) cat("Cannot plot time axis without a margin.\n")#
	else if (time && margin) axisPhylo(cex.axis=0.75)#
}
summarizeFossilMEDUSA(results=carny.res)
library(ape)#
library(multicore)#
library(geiger)#
#
## fossilMEDUSA #
## Written by Joseph W. Brown, Richard G. FitzJohn, Luke J. Harmon, and Michael E. Alfaro#
## Problems/bugs/questions/request: josephwb@uidaho.edu#
#
## runFossilMEDUSA:#
##  Takes in phylogeny 'phy' and (optional) 'richness' (containing extant and potentially fossil#
##  counts); 'fossil.richness' optionally passed in separately. #
## 	The species richness information (if supplied) must minimally have columns 'taxon' and 'n.taxa'; #
## 	'taxon' must match with a tip.label in the phylogeny 'phy'. May also include 'exemplar' column,#
## 	used for incompletely-sampled clades which requiring pruning. If no richness information#
##  is provided then it is assumed tips represent single species with comprehensive#
##  sampling. Returns a list of models with 0, 1, 2, ..., 'model.limit' partitions.#
##  'model.limit' can be supplied by user, but is overruled if large enough (relative#
##  to tree size) that AIC correction factor becomes undefined (different for pure birth vs.#
##  birth-death models). 'phy' is assumed to be ultrametric; this is not checked. #
## #
## Returned list has elements:#
##  $models, which contains:#
##     $par: i x 2 matrix (for birth-death parameters); the jth row contains #
##       the speciation and extinction rate for the jth rate class#
##     $lnLik.part: vector of length i; the jth element is the partial log#
##       likelihood value due to the jth rate class#
##     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
##     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
##  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
##  $z: a matrix listing branch times and richnesses; for summarizing results#
##  $anc: a list of all ancestors; for summarizing results#
##  $modelSummary: data.frame listing considered models, likelihoods, AIC, etc.#
#
## Features (to be) added: specify epsilon (for every piecewise model), estimate r.#
## An argument 'epsilon.value' is passed; if NULL, normal MEDUSA is performed.#
#
## TO-DO:#
 # 0. fossil counts in pendant edges - DONE (but slow when fossil.minimum==T)#
 # 1. option for no extinction (i.e. pure birth) (lower priority)#
 # 2. set epsilon to some value (for all piecewise models), estimate r (num.par = 2*num.models - 1)#
 # 3. implement cutAtStem=FALSE (very low priority) # abandon?!?#
 # calculate fossil likelihoods using C++ - WORKING#
#
#
## Function to prune tree using 'richness' information, assumed to have minimally two columns, "taxon" and "n.taxa"#
##   Perhaps relax on these column names, may cause too many problems#
## May also include 'exemplar' column; in that case, rename relevant tip.label before pruning.#
## In addition, may have columns 'n.fossils' and 'f.time'; must match names exactly or ambiguous error generated.#
##   Taxa without fossil counts should have NA in n.fossil and f.time columns.#
## If 'fossil.richness' passed in separately, merge with 'richness'#
pruneTreeMergeData <- function(phy, richness, fossil.richness=NULL, fossil.minimum=FALSE, verbose=T)#
{#
# Sort for downstream functions#
	if (is.null(richness$n.fossils))#
	{#
		richness <- richness[order(richness $taxon),]#
	} else {#
		richness <- richness[order(richness $taxon, -richness$f.time),]#
	}#
	rownames(richness) <- NULL#
# Rename exemplar taxa with taxon name in richness file#
	if (!is.null(richness$exemplar))#
	{#
# Change relevant tip.labels in phy; individual 'exemplar' may be NA, use original tip.label.#
# Ordering in richness file should NOT be assumed to match order of tip.labels#
		i.na <- is.na(richness$exemplar)#
		phy$tip.label[match(richness$exemplar[!i.na], phy$tip.label)] <- as.character(richness$taxon[!i.na])#
	}#
	#
# Check names against 'richness' (already fixed above). May use 'exemplar', but *must* use 'taxon'#
# Update 'n.fossils' and 'f.time' accordingly#
# Again, assume ordering is random, but that taxa are consistent across richness files#
# Annoying number of possible combinations of file format. Don't be so nice! Force them into one or few.#
	if (!is.null(fossil.richness)) # Merge 'fossil.richness' with 'richness'#
	{#
		if (!is.null(fossil.richness$exemplar) && !is.null(richness$exemplar))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$exemplar)#
		} else if (!is.null(fossil.richness$exemplar) && !is.null(richness$taxon))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$taxon)#
# This would be odd, but allow for it; need to change tip labels to 'exemplar' from 'fossil.richness'#
	# VERY low priority#
		} else {#
			i.fossil <- match(fossil.richness$taxon, richness$taxon)#
		}#
		#
		if (length(i.fossil) != length(fossil.richness[,1])) {stop("Problem matching extant and fossil taxon information.")}#
		#
		for (i in 1:length(fossil.richness[,1]))#
		{#
			richness[i.fossil[i],"n.fossils"] <- fossil.richness[i,"n.fossils"]#
			richness[i.fossil[i],"f.time"] <- fossil.richness[i,"f.time"]#
		}#
	}#
# Just for consistency with downstream functions:#
	if (is.null(richness$n.fossils)) {richness <- cbind(richness, n.fossils=NA, f.time=NA)}#
	#
# Check if fossil.minimum==T and if any n.fossil==1; delete and warn#
	if (fossil.minimum == TRUE)#
	{#
		if (!is.na(any(richness$n.fossils == 1)))  # is it possible to be uglier?!? make pretty later.#
		{#
			if(any(richness$n.fossils == 1))#
			{#
				drop.fossil <-  (richness$n.fossils == 1)#
				drop.fossil.taxa <- as.character(richness$taxon[drop.fossil])#
				#
				richness$n.fossils[drop.fossil] <- NA#
				richness$f.time[drop.fossil] <- NA#
				#
				cat("Warning: dropped fossil observations since cannot use fossil counts == 1 as minimums:\n")#
				print(drop.fossil.taxa)#
				cat("\n")#
			}#
		}#
	}#
	#
	if (length(phy$tip.label) != length(richness[,1]))#
	{#
# Prune tree down to lineages with assigned richnesses#
		temp <- richness[, "n.taxa"]#
		names(temp) <- richness[, "taxon"]#
		pruned <- treedata(phy, temp, warnings=verbose)  # geiger function calling ape (namecheck)#
		prunedTree <- pruned$phy#
# Check the tree#
	#	plotNN(prunedTree)					# Node numbers (ape-style) plotted#
		phy <- prunedTree#
	}#
	return(list(phy=phy, richness=richness))#
}#
#
#
#
## Original default was to fit 20 models (or less if the tree was small).#
## Changing to a stop-criterion e.g. when k = n-1 (i.e. when denominator of aicc correction is undefined).#
## k <- (3*i-1) # when BOTH birth and death are estimated#
  ## This occurs when i = n/3#
  ## if est.extinction=FALSE, k <- (2*i-1); max i = n/2#
## n <- (2*num.taxa - 1) == (2*length(richness[,1]) - 1) # i.e. total number of nodes in tree (internal + pendant)#
  ## if present, consider each fossil count as one data point; i.e. n <- num.nodes + num.fossils#
## Eventually use aicc itself as a stopping criterion (not urgent, as it is very fast).#
getMaxModelLimit <- function(richness, model.limit, est.extinction, stop, verbose)#
{#
	samp.size <- sum(!is.na(richness[,"n.fossils"])) + (2*length(richness[,1]) - 1)#
	max.model.limit <- numeric()#
	#
	if (est.extinction == TRUE)#
	{#
		max.model.limit <- as.integer(samp.size/3) - ((!samp.size %% 3) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	} else {#
		max.model.limit <- as.integer(samp.size/2) - ((!samp.size %% 2) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	}#
	#
	if (stop == "model.limit")#
	{#
		if (verbose) {cat("\nLimiting consideration to ", model.limit, " piecewise diversification models\n\n", sep="")}#
	} else if (stop == "threshold") {#
		model.limit <- max.model.limit#
		if (verbose) {cat("\nConsidering a maximum of ", model.limit, " piecewise diversification models (or until threshold is not satisfied)\n\n", sep="")}#
	}#
	return(model.limit)#
}#
#
#
#
## Fitted curve from random b-d simulations#
## Value corresponds to 95th percentile of AICc(split) - AICc(no-split) for no-split simulations#
getThreshold <- function (x)#
{#
	a = -3.5941052380332650E+01#
	b =  6.7372587299747000E+00#
	c = -1.0061508340754866E-01#
	Offset =  2.7516678664333408E+01#
	y <- a * (x-b)^c + Offset#
	if (y < 0) y <- 0#
	return(y)#
}#
#
#
#
## The make.cache.medusa function is like the first half of the original splitEdgeMatrix().#
## It works through and reorders the edges, then works out start and end times of these#
## based on the phylogeny's branching times.#
###
## In addition, every node's ancestors are also calculated.  The element 'anc' is a list.#
## $anc[i] contains the indices within $edge, $t.start, etc., of all ancestors of node 'i'#
## (in ape node numbering format).#
## #
## If multiple fossil observances present for a lineage, tie all to same ancestor#
make.cache.medusa <- function(phy, richness, mc, num.cores)#
{#
	if (is.null(richness)) {stop("This should not be possible.")}#
	#
# Fix for condition where there are only two branches (i.e. no internal)#
	#
	n.tips <- length(phy$tip.label)#
	n.int <- nrow(phy$edge) - n.tips#
	bt <- branching.times(phy)#
	#
# Broken up to more easily parse fossil information; consider only internal edges first#
	if (n.int > 1)#
	{#
		i.int <- seq_len(n.int)#
		interior <- phy$edge[,2] %in% phy$edge[,1]#
		#
		edges.int <- phy$edge[interior,]#
		colnames(edges.int) <- c("anc", "dec")#
		#
		t.0 <- bt[match(edges.int[,1], (n.tips+1):max(edges.int))]#
		t.1 <- c(t.0[i.int] - phy$edge.length[interior])#
		#
		z.internal <- cbind(edges.int, t.0, t.1, t.len=t.0 - t.1,#
			n.0=rep(1, n.int), n.t=rep(NA, n.int))#
	}#
	#
# Now, pendant edges; #
# Assume that if multiple fossils per taxon, use same 'taxon' and [optionally] 'exemplar'#
	edges.pendant <- phy$edge[match(seq_len(n.tips), phy$edge[,2]),]#
	colnames(edges.pendant) <- c("anc", "dec")#
	#
	t.0 <- bt[match(edges.pendant[,1], (n.tips+1):max(edges.pendant))]#
	#
	z.pendant <- data.frame() # Put each (sub)edge on a separate row#
	#
	#
# *** Is there a way to do this without the for loop?#
#
	# if (length(phy$tip.label) == length(richness[,1])) # if no fossils, can disregard a lot of matching#
	# {#
		#
	# } else {#
		# for (i in 1:n.tips) # *** This is the slow bit; only used for fossils.#
		# {#
			# i.taxon <- which(richness$taxon == phy$tip.label[i])#
			# tmp  <- data.frame()#
			# anc=edges.pendant[i,"anc"]#
			# dec=edges.pendant[i,"dec"]#
			# cur.r0 <- 1#
			# cur.t0 <- t.0[i]#
			#
			# tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
			# z.pendant <- rbind(z.pendant, tmp)#
		# }#
	# }#
#
#
	for (i in 1:n.tips)#
	{#
		i.taxon <- which(richness$taxon == phy$tip.label[i]) # May have multiple entties due to mutliple fossil observances#
		tmp  <- data.frame()#
		anc=edges.pendant[i,"anc"]#
		dec=edges.pendant[i,"dec"]#
		cur.r0 <- 1#
		cur.r1 <- richness$n.fossils[i.taxon[1]]#
		cur.t0 <- t.0[i]#
		cur.t1 <- richness$f.time[i.taxon[1]]#
		#
		if (is.na(cur.r1)) # no fossils#
		{#
			tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0,#
				t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
		} else { # n fossils; split into n+1 rows#
			for (j in 1:length(i.taxon))#
			{#
				foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
					t.1=cur.t1, t.len=cur.t0-cur.t1, n.0=cur.r0, n.t=cur.r1)#
				tmp <- rbind (tmp, foo)#
				#
				cur.r0 <- cur.r1#
				cur.t0 <- cur.t1#
				if (j != length(i.taxon))#
				{#
					cur.r1 <- richness$n.fossils[i.taxon[j+1]]#
					cur.t1 <- richness$f.time[i.taxon[j+1]]#
				}#
			}#
			foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
				t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon[1]])#
			tmp <- rbind (tmp, foo)#
		}#
		z.pendant <- rbind(z.pendant, tmp)#
	}#
	#
	if (n.int > 1) {z <- rbind(z.internal, z.pendant)#
	} else {z <- z.pendant}#
	z <- cbind(z,partition=rep(1, length(z[,1]))) # Stores piecewise model structure#
	rownames(z) <- NULL#
	#
# Used for identifying ancestral nodes below i.e. tracking breakpoints#
	all.edges <- as.matrix(z[,c("anc","dec")])#
	#
	if (mc)#
	{#
		list(z=z, anc=mclapply(seq_len(max(all.edges)), ancestors.idx, all.edges), mc.cores=num.cores)#
	} else {#
		list(z=z, anc=lapply(seq_len(max(all.edges)), ancestors.idx, all.edges))#
	} # And, we're good to go...#
}#
#
#
#
## This generates the indices of all ancestors of a node, using ape's edge matrix.#
## Deals with row numbers of the edge matrix rather than node numbers of the tree#
ancestors <- function(node, all.edges)#
{#
	ans <- node#
	repeat#
	{#
		node <- all.edges[all.edges[,1] %in% node,2]#
		if (length(node) > 0) {ans <- c(ans, node)} else {break}#
	}#
	unlist(ans)#
}#
#
## The function 'ancestors' returns the indices of all ancestors within the edge matrix.#
ancestors.idx <- function(node.list, all.edges)#
{#
	which(all.edges[,1] == node.list | all.edges[,2] %in% ancestors(node.list, all.edges))#
}#
#
#
## Needed for determining whether nodes are virgin nodes#
getNumTips <- function(node, phy)#
{#
	n <- length(node.leaves(phy,node))#
	return(n)#
}#
#
#
#
## Only used for base model#
medusa.ml.initial <- function(z, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
#	rootnode <- min(z[is.na(z[,"n.t"]),1]) # doesn't work if only two branches (i.e. no NA)#
	#
	rootnode <- min(z[,"anc"])#
	obj <- medusa.ml.fit.partition(1, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	modelFit <- calculateModelFit(fit=obj, z, est.extinction, epsilon.value)#
	#
	if (est.extinction)#
	{#
		list(par=matrix(obj$par, nrow=1, dimnames=list(NULL,c("r", "epsilon"))), lnLik.part=obj$lnLik, #
		   lnLik=obj$lnLik, split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	} else {#
		list(par=matrix(obj$par, nrow=1,dimnames=list(NULL,"r")), lnLik.part=obj$lnLik, lnLik=obj$lnLik,#
		   split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	}#
}#
#
#
## Pre-fit values for pendant edges; DON'T recalculate later; should account for ~25% of all calculations#
medusa.ml.prefit <- function(node, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
# Partition '2' represents the pendant edge#
	fitted <- medusa.ml.fit.partition(2, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	return(fitted)#
}#
#
#
#
## 'fit' contains parameter value(s) from previous model, used to initialize subsequent model#
## Pass in pre-fitted values for pendant edges; DON'T recalculate #
medusa.ml.update <- function(node, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
	aff <- obj$affected#
	#
	op <- fit$par#
	sp <- op[aff[1],] # Use previously fit parameter values from clade that is currently being split#
	#
	fit1 <- medusa.ml.fit.partition(aff[1], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	fit2 <- 0#
	#
## Check if pendant; calculations already done#
	if (node < root.node)#
	{#
		fit2 <- tips[[node]]#
## Check if virgin node; save more time!#
	} else if (length(unique(z[(z[,"partition"] == aff[2] & z[,"dec"] < root.node),"dec"])) == num.tips[[node]])#
	{#
		fit2 <- virgin.nodes[[node - root.node]]#
## Novel arrangement; need to calculate#
	} else {#
		fit2 <- medusa.ml.fit.partition(aff[2], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	}#
	#
	op[aff[1],] <- fit1$par # Replace parameters with new values for diminished clade#
	fit$par <- rbind(op, fit2$par)#
	fit$lnLik.part[aff] <- c(fit1$lnLik, fit2$lnLik) # Replace parameters with new values for diminished clade#
	fit$split.at <- c(fit$split.at, node)#
	fit$lnLik <- sum(fit$lnLik.part)#
	#
	modelFit <- calculateModelFit(fit, z, est.extinction, epsilon.value)#
	#
	fit$aic <- modelFit[1]#
	fit$aicc <- modelFit[2]#
	fit$num.par <- modelFit[3]#
	#
	return(fit)#
}#
#
#
#
## Split the edge matrix 'z' by adding a partition rooted at node 'node'.#
##   Note: in original MEDUSA parlance, this is cutAtStem=T.#
## The list 'anc' is a list of ancestors (see make.cache.medusa, above).#
## Returns a list with elements:#
##   z: new medusa matrix, with the new partition added#
##   affected: indices of the partitions affected by the split (n == 2).#
# Add cutAtStem = F option. Allow both within a single analysis?!?#
medusa.split <- function(node, z, anc)#
{#
	part <- z[,"partition"]#
	base <- min(part[z[,1] == node | z[,2] == node])#
	tag <- max(part) + 1#
#
	i <- anc[[node]]#
	idx <- i[part[i] == base]#
	z[idx,"partition"] <- tag#
	#
	z[which(z["dec"] == node),"partition"] <- tag # Possible to have several edges to consider#
#
	list(z=z, affected=c(unique(part[idx]), tag))#
}#
#
#
#
## sp = initializing values for r & epsilon#
## Default values should never be used (except for first model), as the values from the previous model are passed in.#
medusa.ml.fit.partition <- function(partition, z, est.extinction, epsilon.value, sp=c(0.1, 0.05), fossil.minimum)#
{#
# Construct likelihood function:#
	lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
	#
	if (est.extinction) # Possibly give a range of initializing values to "navigate the banana"#
	{#
		fit <- optim(fn=lik, par=sp, method="N", control=list(fnscale=-1))#
		list(par=fit$par, lnLik=fit$value)#
	} else {#
		fit <- optimize(fn=lik, interval=c(0, 1))  # check on a valid range#
		list(par=fit$minimum, lnLik=fit$objective)#
	}#
}#
#
#
#
## make.lik.medusa.part: generate a likelihood function for a single partition.#
###
## In the pendant calculations, the variables 'A' and 'B' are the A and B terms#
## in Foote et al. Science: 283 1310-1314, p. 1313, defined as:#
## #
##   A: probability of extinction of one lineage over time 't'#
##   B: A * lambda / mu OR A / epsilon#
###
## Where there is a single lineage at time 0 (a==1), the calculation is#
##   log(1 - A) + log(1 - B) + (n-1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1-A) on a log scale) which cancels to give:#
##   log(1 - B) + (n-1)*log(B)#
## when pendant richness==1 the calculation is even simpler:#
##   log(1 - B)#
###
## When a > 1 (more than one starting species; will only happen coming off of a fossil observation),#
## the calculations follow Foote et al. 1999, put into the function 'foote.fossil.pendant'.#
## 'est.extinction' determines whether yule model is assumed#
## 'epsilon.value', if != NULL, fixes epsilon for all partitions, estimates r; not yet implemented#
## 'fossil.minimum', if == FALSE, treat fossils as exact counts#
## Only one 'partition' is passed in at a time from a proposed split.#
make.lik.medusa.part <- function(partition, est.extinction=TRUE, epsilon.value=NULL, fossil.minimum=T)#
{#
#
# Handle internal, fossil, and pendant edges separately#
	is.int <- is.na(partition[,"n.t"])#
	is.fossil <- (partition[,"n.0"] > 1) | (partition[,"t.1"] > 0 & !is.int)#
	is.pend <- !is.int == !is.fossil # pendant edges *without* fossils#
	#
	n.int <- sum(is.int)#
	n.fossil <- sum(is.fossil)#
	n.pend <- sum(is.pend)#
	#
	if (n.int + n.fossil + n.pend != length(partition[,1])) stop("You messed up, yo.")#
	#
## Internal and pendant calculations differ; split'em up#
	int  <- partition[is.int,,drop=FALSE]#
	foss <- partition[is.fossil,,drop=FALSE]#
	pend <- partition[is.pend,,drop=FALSE]#
	#
	sum.int.t.len <- sum(int[,"t.len"])  # Simply sum all internal edges#
	int.t.0 <- int[,"t.0"]#
	#
# 'n.0' = Foote's 'a', initial diversity; 'n.t' = Foote's 'n', final diversity#
	pend.n.0 <- pend[,"n.0"] # Foote's 'a': initial diversity#
	pend.n.t <- pend[,"n.t"] # Foote's 'n': final diversity#
	pend.t.len <- pend[,"t.len"]#
	#
# Don't need much of this shit anymore#
	foss.n.0 <- foss[,"n.0"]   # Not necessarily equal 1 anymore#
	foss.n.t <- foss[,"n.t"]#
	foss.t.len <- foss[,"t.0"] - foss[,"t.1"]#
	#
# User may pass in epsilon; don't change it, just estimate r#
	f <- function(pars)#
	{#
		if (est.extinction == TRUE)#
		{#
			r <- pars[1]#
			epsilon <- pars[2]#
	#		bd <- get.b.d(r, epsilon)   # Not necessary#
	#		b <- bd$b#
	#		d <- bd$d#
			#
# Previous version where b & d were estimated:#
	#		b <- pars[1]#
	#		d <- pars[2]#
	#		r <- abs(b - d)#
	#		epsilon <- d / b#
			#
			if (r < 0 | epsilon <= 0 | epsilon >= 1) {return(-Inf)}#
		} else {#
## Implement pure birth; not currently working (for some reason). Not immediately urgent, as won't work with fossils anyway#
			r <- pars[1]#
			d <- 0#
			b <- r#
			epsilon <- 0#
			#
			if (r < 0) {return(-Inf)}#
		}#
		#
		if (n.int == 0) {l.int <- 0} else {#
## Likelihood of internal edges from Rabosky et al. (2007) equation (2.3):#
			l.int <- n.int * log(r) - r * sum.int.t.len - sum(log(1 - (epsilon * exp(-r * int.t.0))))#
# Under Yule, should be: l.int <- n.int * log(r) - r * sum.int.t.len#
#
		}#
		#
		if (n.pend == 0) {l.pend <- 0} else {#
## Calculations are from the following:#
## Rabosky et al. 2007. Proc. Roy. Soc. 274: 2915-2923.#
## Foote et al. 1999. Science. 283: 1310-1314#
## Raup. 1985. Paleobiology 11: 42-52 [Foote et al. correct the equation [A18] where a > 1]#
## Bailey. 1964. The Elements Of Stochastic Processes, With Applications To The Natural Sciences#
## Kendall. 1948. Ann. Math. Stat. 19: 1–15.#
###
## A = probability of extinction of one lineage over time 't'#
## B = A * (lambda/mu)#
###
## When there is a single lineage at time 0 (a = 1), the calculation is#
##   log(1 - A) + log(1 - B) + (n - 1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1 - A) on a log scale) which cancels to give:#
##   log(1 - B) + (n - 1)*log(B)#
##      - for n.t == 1, reduces further to log(1-B)#
###
## A = mu*(exp((lambda - mu)*t) - 1)) / (lambda*exp((lambda - mu)*t) - mu)#
##  let r = (lambda - mu); ert = exp((lambda - mu)*t)#
## A = mu*(ert - 1)/(lambda*ert - mu)#
###
## B = A * (lambda/mu)#
##   = [mu*(ert - 1)/(lambda*ert - mu)] * (lambda/mu)#
##   = (lambda*(ert - 1))/(lambda*ert - mu)#
##   = (lambda*(ert - 1))/(lambda(ert - mu/lambda))#
##   = (ert - 1) / (ert - epsilon)#
#
## All pendant nodes begin with richness '1'; calculations simple.#
#			i.pend.n.t.1 <- which(pend.n.t == 1)   # calculations even simpler: log(1-B)#
#			i.pend.n.t.n1 <- which(pend.n.t != 1)#
			#
			ert <- exp(r * pend.t.len)#
			B <- (ert - 1) / (ert - epsilon) # Equivalently: B <- (bert - b) / (bert - d)#
			#
	# Under Yule should be: B <- (ert - 1) / ert#
			#
	# separate out calculations; likely not any faster (slower?)#
#			l.pend.1 <- sum(log(1 - B[i.pend.n.t.1]))#
#			l.pend.n1 <- sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
#			l.pend <- l.pend.1 + l.pend.n1#
			#
#			l.pend <- sum(log(1 - B[i.pend.n.t.1])) + #
#			   sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
			#
			l.pend <- sum(log(1 - B) + (pend.n.t - 1)*log(B)) # equivalent single formula version#
		}#
		#
# Fossils!#
		if (n.fossil == 0) {l.fossil <- 0} else {#
#
# What is desired: P(n,t,N,T) = P(n,t,1)*P(N,T-t,n)#
# - each term (internal node to fossil, and fossil to pendant node) is conditioned on survival (dividing by [1-(P(0,t,a)]^a)]#
#
			if (fossil.minimum) # loop counts from 1 -> n-1 fossils; *** NEED TO SPEED THIS SHIT UP! ***#
			{#
## First consider path from internal node to fossil, conditioning on survival (i.e. divide by (1-A)^a, although 'a' is always 1 here):#
##  sum(over x from 1 to n-1) [(1-B)*B^(x-1)]#
				#
	### *** BROKEN!!! *** ####
	#
# *** UPDATE TO NEW FORMAT ***#
				#
				ert <- exp(r * foss.t.len)#
				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
			# Under Yule should be: B <- (ert - 1) / ert#
				#
				sum.prob.int.fossil <- numeric(length(foss.n.t))#
				for (i in 1:n.fossil)#
				{#
					tmp <- 0#
					for (j in 1:foss.n.t[i])#
					{#
						tmp <- sum((B.1[i]^(j-1)), tmp)#
					}#
					sum.prob.int.fossil[i] <- (1 - B.1[i]) * tmp # (1-B) brought outside sum, as it is present in every term#
				}#
				#
# Now consider path from fossil to pendant node; looping bits in 'foote.fossil.pendant.minimum'#
				ert <- exp(r * foss.t.len)#
				A <- (ert - 1) / ((ert/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.2 <- A / epsilon                   # Equivalently: B.2 <- A * (b/d)#
				#
			# Using raw probabilities:#
				sum.prob.fossil.pend <- foote.fossil.pendant.minimum(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(log(1 - (sum.prob.int.fossil * sum.prob.fossil.pend)))#
				#
			# Using log-scale values:#
#				sum.prob.fossil.pend <- foote.fossil.pendant.combined(foss.n.t, foss.n.t, A, B.2, fossil.minimum)#
#				l.fossil <- sum(log(1 - (sum.prob.int.fossil * exp(sum.prob.fossil.pend))))#
				#
			} else { # No looping; pretty fast#
# Two scenarios:#
# 1. coming off internal node (i.e. n.0 = 1); same calculation as above#
	# log(1 - B) + (n - 1)*log(B)#
# 2. coming off fossil (i.e. n.0 > 1); need Foote equations#
				off.node <- which(foss[,"n.0"] == 1)#
				off.fossil <- which(foss[,"n.0"] != 1)#
				#
	# First, off node; n.0 = 1#
				ert.off.node <- exp(r * foss[off.node,"t.len"]) # internal node to fossil#
				B.off.node <- (ert.off.node - 1) / (ert.off.node - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
				l.off.node <- sum(log(1 - B.off.node) + (foss[off.node,"n.t"] - 1)*log(B.off.node))#
				#
#				ert <- exp(r * foss.t.len) #
#				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
		# Under Yule should be: B <- (ert - 1) / ert#
				#
				ert.off.fossil <- exp(r * foss[off.fossil,"t.len"])        # fossil to pendant node or next fossil#
				A <- (ert.off.fossil - 1) / ((ert.off.fossil/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.off.fossil <- A / epsilon                                         # Equivalently: B.2 <- A * (b/d)#
				l.off.fossil <- foote.fossil.pendant.exact(foss[off.fossil,"n.0"], foss[off.fossil,"n.t"], A, B.off.fossil)#
				#
#				l.fossil <- sum(log(1 - B.1) + (foss.n.t - 1)*log(B.1)) + #
#				   foote.fossil.pendant.exact(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(l.off.node, l.off.fossil)#
			}#
		}#
		l.int + l.pend + l.fossil#
	}#
#	l.int + l.pend + l.fossil#
}#
#
#
## Calculates the probability of having *exactly* 'a' fossils and ending with *exactly* 'n' extant species.#
## Use only when 'a', starting richness, > 1 (i.e. if coming off a fossil count).#
## For 'off-fossil' calculations, richness may increase or decrease.#
foote.fossil.pendant.exact <- function(a, n, A, B)#
{#
	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
	lB <- log(B)#
	l1mA <- log(1 - A)#
	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
	l1mB <- log(1 - B)#
	l1mA1mB <- l1mA + l1mB#
	#
#	min.a.n <- pmin(a, n) # *Insanely* slow!#
	min.a.n <- pmin.int(a, n)#
	#
	l.exact.fossil <- numeric(length(min.a.n))#
	#
	for (i in 1:length(a))#
	{#
		ji <- seq_len(min.a.n[i])#
		ai <- a[i]#
		ni <- n[i]#
		#
#		tmp <- lchoose(ai, ji) + lchoose(ni - 1, ji - 1) + (ai - ji)*lA[i] + ji*l1mA1mB[i] + (ni - ji)*lB[i]#
		#
# Non-logspace version much faster#
		foo <- choose(ai, ji) * choose(ni - 1, ji - 1) * A[i]^(ai - ji) * ((1-A[i])*(1-B[i]))^ji * B[i]^(ni - ji)#
		tmp <- sum(foo)#
		#
## Conditioning on survival factors out of the sum:#
		l.exact.fossil[i] <- sum(tmp)/(r1mA.exp.a[i])#
		#
#		l.exact.fossil[i] <- logspace_sum(tmp) - l1mA.exp.a[i] # logspace_sum: calculate log(x+y) from log(x) and log(y)#
	#	l.exact.fossil[i] <- logspace_sum(tmp) - l1mA[i]  # old conditioning; not appropriate for a > 1#
	}#
#
#	sum(l.exact.fossil)#
	return(sum(log(l.exact.fossil)))#
}#
#
#
## Calculates the probability of having *at least* 'a' fossils and ending with exactly 'n' extant species.#
## Richness may increase or decrease.#
## Should this be computed on a log-scale?#
# *** THIS IS BROKEN ***#
foote.fossil.pendant.minimum <- function(a, n, A, B)#
{#
#	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
#	lB <- log(B)#
#	l1mA <- log(1 - A)#
#	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
#	l1mB <- log(1 - B)#
#	l1mA1mB <- l1mA + l1mB#
	#
	sum.prob.fossil.pend <- numeric(length(a))#
	#
	for (i in 1:length(a)) # Loop over fossils#
	{#
		tmp <- numeric(a[i]-1)#
		for (k in 1:(a[i]-1)) # For fossil i loop over from 1 to n[i]-1#
		{#
			ai <- k#
			ni <- n[i]#
			min.a.n <- pmin.int(ai, ni)#
#			min.a.n <- pmin(ai, ni) # *Insanely* slow! pmin.int saves 70s on a 107s job! WTF?!?#
	   		j <- seq_len(min.a.n)#
			#
	# *** Should this be put on a log scale to preserve precision? ***#
	  # Tests with reasonable data yield the same answer either way#
			foo <- choose(ai, j) * choose(ni - 1, j - 1) * A[i]^(ai - j) * ((1-A[i])*(1-B[i]))^j * B[i]^(ni - j)#
			tmp[k] <- sum(foo)#
	# Alternate log form:#
	  # foo <- lchoose(ai, j) + lchoose(ni - 1, j - 1) + (ai - j)*lA[i] + j*l1mA1mB[i] + (ni - j)*lB[i]#
	    }#
	#  	tmp[i] <- sum(tmp)/(1-A[i])  # old conditioning; not appropriate for a > 1#
			#
# Conditioning on survival factors out of the sum:#
		sum.prob.fossil.pend[i] <- sum(tmp)/(r1mA.exp.a[i])#
	# Alternate log form:#
	  #	foo <- (logspace_sum(tmp))#
	  #	sum.prob.fossil.pend[i] <- foo - l1mA.exp.a[i]#
	}#
#
	return(sum.prob.fossil.pend)#
}#
#
#
## 'fit' contains '$par' and '$lnlik'#
calculateModelFit <- function(fit, z, est.extinction, epsilon.value)#
{#
## Sample size taken (for now) as the total num.nodes in the tree (internal + pendant) plus num.fossil observations#
  # num.nodes = (2*length(phy$tip.label) - 1) == (2*length(richness[,1]) - 1) == length(z[,1]) + 1#
#	n <- (length(z[,1]) + 1) + sum(!is.na(z[,"n.f"]))#
	#
# Changed structure of data; no longer have z[,"n.f"]#
# Instead, each row of z constitutes an edge#
# Since each edge defines either a node or a fossil (i.e. an 'observation'), need only add root node as final obervation#
	n <- (length(z[,1]) + 1)#
	#
## Number of parameters estimated depends on values of est.extinction and epsilon.value#
  # Includes both formal parameters AND number of breaks. Note: first model does not involve a break.#
## Models where all parameters are estimated:#
  # 2 parameters for base model (no breakpoint) + 3 parameters (r, eps, breakpoint) for each subsequent model#
## Models where only one parameter is estimated:#
  # 1 parameter for base model (no breakpoint) + 2 parameters (r, breakpoint) for each subsequent model#
	#
	if (length(fit$par) < 3) # i.e. base model#
	{#
		num.models <- 1#
	} else {#
		num.models <- length(fit$par[,1])#
	}#
	#
	if (est.extinction == FALSE || !is.null(epsilon.value)) # only one parameter estimated (plus breakpoint)#
	{#
		k <- 1 + (2 * (num.models - 1))#
	} else {#
		k <- 2 + (3 * (num.models - 1))#
	}#
	#
	lnLik <- fit$lnLik#
	#
	aic <- (-2 * lnLik) + (2*k)#
	aicc <- aic + 2*k*(k+1)/(n-k-1)#
	#
	modelFit <- c(aic, aicc, k)#
	return(modelFit)#
}#
#
#
## Prints out a table of likelihoods, parameters, aic scores, and aic weights (delta-aics are also available, if desired)#
calculateModelFitSummary <- function (models, phy, plotFig, fig.title=NULL, ...)#
{#
	tmp <- matrix(nrow=(length(models)), ncol=6)#
	colnames(tmp) <- c("N.Models", "Break.Node", "Ln.Lik", "N.Param", "aic", "aicc")#
	#
	w.aic <- numeric(length(models))#
	w.aicc <- numeric(length(models))#
	#
	for (i in 1:length(tmp[,1]))#
	{#
		tmp[i,] <- c(i, as.integer(models[[i]]$split.at[i]), models[[i]]$lnLik, models[[i]]$num.par, models[[i]]$aic, models[[i]]$aicc)#
	}#
	#
	all.res <- as.data.frame(tmp)#
	all.res[1,2] <- NA # root node for base model#
	#
	w.aic <- calculateModelWeights(all.res$aic)#
	w.aicc <- calculateModelWeights(all.res$aicc)#
	#
	all.res <- cbind(all.res[,c(1:5)], w.aic=w.aic$w, aicc=all.res$aicc, w.aicc=w.aicc$w)#
	#
	if (plotFig)#
	{#
		dev.new()#
		plotModelFit(all.res)#
		if (!is.null(fig.title)) {title(main=fig.title, cex.main=0.75)}#
	}#
	return(all.res)#
}#
#
calculateModelWeights <- function (fit)#
{#
	best <- min(fit)#
	delta <- fit-best#
	sumDelta <- sum(exp(-0.5 * delta))#
	w <- (exp(-0.5 * delta)/sumDelta)#
	#
	results <- data.frame(fit=fit,delta=delta,w=w)#
	#
	return(results)#
}#
#
plotModelFit <- function (all.res)#
{#
	ylim <- c(min(all.res[,"aic"],all.res[,"aicc"]), max(all.res[,"aic"],all.res[,"aicc"]))#
	plot(all.res[,"N.Models"],all.res[,"aicc"], xlab="Number of Piecewise Models", ylab="Model Fit", ylim=ylim, type="l", col="blue")#
	points(all.res[,"N.Models"],all.res[,"aicc"], col="blue", pch=21, bg="white")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", type="l")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", pch=21, bg="white")#
	#
	legend("topleft", c("aicc","aic"), pch=21, pt.bg="white", lty=1, col=c("blue", "black"), inset = .05, cex=0.75, bty="n") # 'bottomright' also works#
}#
#
logspace_sum <- function(logx)#
{#
	r <- logx[1]#
	if (length(logx)>1)#
	{#
		for (i in 2:length(logx)) {r <- logspace_add(r, logx[i])}#
	}#
	return(r)	#
}#
#
# Calculate log(x+y) from log(x) and log(y)#
logspace_add <- function(logx, logy)#
{#
	if (logx == -Inf)#
	{#
		return(logy)#
	} else {#
		max(logx, logy) + log1p(exp (-abs (logx - logy)))#
	}#
}#
#
#
# Print out results from a given piecewise model. May be:#
#   1. optimal model under aicc: the default#
#   2. optimal model under aic: through setting "aic=T"#
#   3. aicc model using threshold improvement (like original MEDUSA): through setting "threshold" to some value#
#   4. aic model using threshold improvement (like original MEDUSA): through setting "aic=T" and "threshold" to some value#
#   5. user-selected model: through setting "model" to some integer value (from summary table)#
# In any case, also print out base model for comparison#
# Need to parse 'results' (list of lists). Contains elements:#
#  $models, which contains:#
#     $par: i x 2 matrix (for birth-death; i x 1 for pure-birth); the jth row contains #
#       the speciation and (optional) extinction rate for the jth rate class#
#     $lnLik.part: vector of length i; the jth element is the partial log#
#       likelihood value due to the jth rate class#
#     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
#     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
#  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
#  $z: a matrix listing branch times and richnesses; for summarizing results#
#  $anc: a list of all ancestors; for summarizing results#
#  $modelSummary: data.frame listing considered models, likelihoods, number of paramters, aicc, aicc, Akaike weights.#
#
#threshold=0; aic=F; plotTree=F; time=T; cex=0.5; plotSurface=T; est.extinction=T; fossil.minimum=F; n.points=100; node.labels=T;#
#r.interval=c(0.0000001,0.9999999); e.interval=r.interval; model=NULL;#
#
summarizeFossilMEDUSA <- function(results, model=NULL, cutoff="threshold", criterion="aicc", plotTree=TRUE, time=TRUE,#
	node.labels=TRUE, cex=0.5, plotSurface=FALSE, est.extinction=TRUE, fossil.minimum=FALSE, r.interval=c(1e-10,1.0),#
	e.interval=r.interval, n.points=100, ...)#
{#
# Desirables:#
#  1. table listing parameter values of selected model#
#  2. list parameters of base model#
#  3. tree printed with colour-coded edges, node labels to indicate split position(s)#
#  4. plot likelihood surface#
	#
# Extract constituent components from results#
	fit <- results$models#
	phy <- results$phy#
	z <- results$z#
	anc <- results$anc#
	modelSummary <- results$modelSummary#
	threshold <- results$threshold#
	#
# First, determine which model is desired#
	model.id <- 0#
	if (!is.null(model))#
	{#
		model.id <- model#
	} else {   # Find best model using threshold criterion#
		if (cutoff != "threshold") {threshold <- cutoff} else {#
#			cat("\nSelecting model based on corrected threshold (decrease in information theoretic score of ", -threshold, " units).\n", sep="")}#
		model.id <- 1#
		while (1)#
		{#
			if ((model.id + 1) > length(fit)) break;#
			if ((unlist(fit[[model.id]][criterion]) - unlist(fit[[model.id+1]][criterion])) > threshold) break;#
			model.id <- model.id + 1#
		}#
	}#
	#
	break.pts <- fit[[model.id]]$split.at#
	opt.model <- as.data.frame(cbind(Split.node=break.pts, fit[[model.id]]$par, LnLik.part=fit[[model.id]]$lnLik.part))#
	base.model <- as.data.frame(fit[[1]]$par)#
	#
	cat("\nEstimated parameter values for model #", model.id, ":\n\n", sep="")#
	print.data.frame(opt.model, digits=5)#
	opt.weight <- 0#
	optFit <- 0#
	base.weight <- 0#
	baseFit <- 0#
	if (criterion == "aicc")#
	{#
		opt.weight <- modelSummary$w.aicc[model.id]#
		optFit <- modelSummary$aicc[model.id]#
		base.weight <- modelSummary$w.aicc[1]#
		baseFit <- modelSummary$aicc[1]#
	} else { # aic used#
		opt.weight <- modelSummary$w.aic[model.id]#
		optFit <- modelSummary$aic[model.id]#
		base.weight <- modelSummary$w.aic[1]#
		baseFit <- modelSummary$aic[1]#
	}#
	cat("\nModel fit summary for model #", model.id, ":\n\n", sep="")#
	cat("\tLog-likelihood = ", as.numeric(results$models[[model.id]]["lnLik"]), "\n", sep="")#
	cat("\t", criterion, " = ", optFit, "\n", sep="")#
	cat("\t", criterion, " weight = ", opt.weight, "\n\n", sep="")#
	#
	if (model.id != 1)#
	{#
		cat("\nFor comparison, estimated values for the base model are:\n\n")#
		print.data.frame(base.model, digits=5, row.names=F)#
		cat("\nModel fit summary for base model:\n\n", sep="")#
		cat("\tLog-likelihood = ", as.numeric(results$models[[1]]["lnLik"]), "\n", sep="")#
		cat("\t", criterion, " = ", baseFit, "\n", sep="")#
		cat("\t", criterion, " weight = ", base.weight, "\n\n", sep="")#
	}#
	#
# Get desired tree-model conformation#
	if (length(break.pts) > 1)#
	{#
		for (i in 2:length(break.pts))#
		{#
			tmp <- medusa.split(break.pts[i], z, anc)#
			z <- tmp$z#
		}#
	}#
	#
	#
	#
	#
# Temporary workaround#
	epsilon.value <- NULL#
	#
	#
# Plot tree with purdy colours and labelled nodes (to better map between tree and table)#
	if (plotTree)#
	{#
		dev.new()#
		margin <- F#
		#
# This need to be changed to reflect new structure#
		mm <- match(phy$edge[,2], z[,"dec"])#
		if (time) {margin=T}#
#		plot(phy, edge.color=z[mm,10], no.margin=!margin, cex=cex, ...)#
		plot(phy, edge.color=z[mm,"partition"], no.margin=!margin, cex=cex, ...)#
		if (time)#
		{#
			axisPhylo(cex.axis=0.75)#
			mtext("Divergence Time (MYA)", at=(max(get("last_plot.phylo", envir = .PlotPhyloEnv)$xx)*0.5), side = 1, line = 2, cex=0.75)#
		}#
		if (node.labels)#
		{#
			for (i in  1:length(break.pts))#
			{#
				nodelabels(i, node= break.pts[i], frame = "c", font = 1, cex=0.5)#
			}#
		}#
	}#
	#
	if (plotSurface)#
	{#
		n.pieces <- length(opt.model[,1])#
		dev.new()#
		#
		if ((sqrt(n.pieces)) == round(sqrt(n.pieces)))  #make square plotting surface#
		{#
			op <- par(mfrow=c(sqrt(n.pieces),sqrt(n.pieces)))#
		} else {#
			layout(matrix(1:n.pieces))#
		}#
		#
#	min.r <- 0.000001#
#	max.r <- max(opt.model["r"]) * 2#
		#
		if (n.pieces > 1) {cat("Computing surfaces...\n")} else {cat("Computing surface...")}#
		for (k in 1: n.pieces)#
		{#
			partition <- k#
			#
			lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
			#
			lik.vals <- matrix(nrow=n.points, ncol=n.points)#
			r.vals <- seq(from=r.interval[1], to=r.interval[2], length.out=n.points)#
			eps.vals <- seq(from=e.interval[1], to=e.interval[2], length.out=n.points)#
			#
			for (i in 1:length(r.vals))#
			{#
				for (j in 1:(length(eps.vals))) {lik.vals[i,j] <- lik(pars=c(r.vals[i], eps.vals[j]))}#
			}#
			if (n.pieces > 1) {cat("Completed computing surface for piecewise model #", k, "\n", sep="")}#
			else {cat (" done.\n")}#
		#
# Perspective plot#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood", theta=-45, phi=45)#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood")#
#	points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
#	points(x=best.r, y=best.eps, pch=16, col="blue")#
#	points(modelSummary$Ln.Lik[model.id], x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
	#
	#
	#
	#
## *** Can check on distance between MLE and best point evaluated above; if large, advize evaluating further points#
# Perhaps determine the correct number of points this way automatically?#
	#
	#
	#
	#
# Contour plot#
			#
	# This shit is only good for determining the best number of points to evaluate#
			max.lik <- max(lik.vals,na.rm=T)#
			best.r <- numeric()#
			best.eps <- numeric()#
			#
# Need to figure out which parameter values lead to this likelihood...#
			i.best <- which(lik.vals==max.lik)#
			if (length(i.best) > 1) {i.best <- i.best[1]} # if more than one combination gives best value, just grab first#
			#
	# the following determines, from the r/eps sequences, where in the the likelihood matrix the MLE lies#
			if (i.best > n.points)#
			{#
				best.r <- r.vals[i.best%%n.points]#
				best.eps <- eps.vals[ceiling(i.best/n.points)]#
			} else {#
				best.r <- r.vals[i.best]#
				best.eps <- eps.vals[1]#
			}#
#			cat("Best likelihood found: ", max.lik, " for parameter combination #", i.best, "\n", sep="")#
			#
			#
			max.lik <- as.numeric(opt.model[partition,"LnLik.part"])  # MLE#
			lines <- c(max.lik-0.5, max.lik-1, max.lik-2, max.lik-3, max.lik-4, max.lik-5, max.lik-10, max.lik-50, max.lik-100)#
			contour(lik.vals, levels=lines, labels=c(0.5, 1, 2, 3, 4, 5, 10, 50, 100), axes=FALSE, xlab="r (b-d)", ylab="epsilon (d/b)")#
			tics<-floor(c(1, n.points/4, n.points/2, n.points*3/4, n.points))#
			axis(1, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(r.vals[tics], 3))#
			axis(2, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(eps.vals[tics], 3))#
			points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red") # inferred ML values#
#			points(x=best.r, y=best.eps, pch=16, col="blue") # best from surface samples#
#			legend("topright", c("ML","Best from sampled surface"), pch=16, col=c("red", "blue"), inset = .05, cex=0.75, bty="n")#
			legend("topright", "ML", pch=16, col="red", inset = .05, cex=0.75, bty="n")#
			if (n.pieces > 1) {title(main=paste("Piecewise model #", k, sep=""))}#
		}#
	}#
}#
#
#
#
#
#
#
#
#
# *** NOT used ***#
#
#
## Get b and d values from r (b-d) and epsilson (d/b)#
## Used in previous version of program; now in terms of r and epsilon#
## Possibly of use to users wishing to translate results#
get.b.d <- function(r, epsilon)#
{#
	b <- r/(1-epsilon)#
	d <- b-r   # Alternatively: d <- eps*r/(1-eps)#
	return(list(b=b, d=d))#
}#
#
## Print out tree with ape-style node-numbering#
## Possibly of interest for users to identify numbers of node(s) off interest#
 ## If this is the case, make sure to pass in pruned tree#
plotNN <- function (phy, time=TRUE, margin=TRUE, label.offset=0.5, cex=0.5, ...) #
{#
	phy$node.label <- (length(phy$tip.label) + 1):max(phy$edge)#
	plot.phylo(phy, show.node.label=TRUE, no.margin=!margin, label.offset=label.offset, cex=cex, ...)#
	if (time && !margin) cat("Cannot plot time axis without a margin.\n")#
	else if (time && margin) axisPhylo(cex.axis=0.75)#
}
summarizeFossilMEDUSA(results=carny.res)
m
ewhuiew
}
library(ape)#
library(multicore)#
library(geiger)#
#
## fossilMEDUSA #
## Written by Joseph W. Brown, Richard G. FitzJohn, Luke J. Harmon, and Michael E. Alfaro#
## Problems/bugs/questions/request: josephwb@uidaho.edu#
#
## runFossilMEDUSA:#
##  Takes in phylogeny 'phy' and (optional) 'richness' (containing extant and potentially fossil#
##  counts); 'fossil.richness' optionally passed in separately. #
## 	The species richness information (if supplied) must minimally have columns 'taxon' and 'n.taxa'; #
## 	'taxon' must match with a tip.label in the phylogeny 'phy'. May also include 'exemplar' column,#
## 	used for incompletely-sampled clades which requiring pruning. If no richness information#
##  is provided then it is assumed tips represent single species with comprehensive#
##  sampling. Returns a list of models with 0, 1, 2, ..., 'model.limit' partitions.#
##  'model.limit' can be supplied by user, but is overruled if large enough (relative#
##  to tree size) that AIC correction factor becomes undefined (different for pure birth vs.#
##  birth-death models). 'phy' is assumed to be ultrametric; this is not checked. #
## #
## Returned list has elements:#
##  $models, which contains:#
##     $par: i x 2 matrix (for birth-death parameters); the jth row contains #
##       the speciation and extinction rate for the jth rate class#
##     $lnLik.part: vector of length i; the jth element is the partial log#
##       likelihood value due to the jth rate class#
##     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
##     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
##  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
##  $z: a matrix listing branch times and richnesses; for summarizing results#
##  $anc: a list of all ancestors; for summarizing results#
##  $modelSummary: data.frame listing considered models, likelihoods, AIC, etc.#
#
## Features (to be) added: specify epsilon (for every piecewise model), estimate r.#
## An argument 'epsilon.value' is passed; if NULL, normal MEDUSA is performed.#
#
## TO-DO:#
 # 0. fossil counts in pendant edges - DONE (but slow when fossil.minimum==T)#
 # 1. option for no extinction (i.e. pure birth) (lower priority)#
 # 2. set epsilon to some value (for all piecewise models), estimate r (num.par = 2*num.models - 1)#
 # 3. implement cutAtStem=FALSE (very low priority) # abandon?!?#
 # calculate fossil likelihoods using C++ - WORKING#
#
#
## Function to prune tree using 'richness' information, assumed to have minimally two columns, "taxon" and "n.taxa"#
##   Perhaps relax on these column names, may cause too many problems#
## May also include 'exemplar' column; in that case, rename relevant tip.label before pruning.#
## In addition, may have columns 'n.fossils' and 'f.time'; must match names exactly or ambiguous error generated.#
##   Taxa without fossil counts should have NA in n.fossil and f.time columns.#
## If 'fossil.richness' passed in separately, merge with 'richness'#
pruneTreeMergeData <- function(phy, richness, fossil.richness=NULL, fossil.minimum=FALSE, verbose=T)#
{#
# Sort for downstream functions#
	if (is.null(richness$n.fossils))#
	{#
		richness <- richness[order(richness $taxon),]#
	} else {#
		richness <- richness[order(richness $taxon, -richness$f.time),]#
	}#
	rownames(richness) <- NULL#
# Rename exemplar taxa with taxon name in richness file#
	if (!is.null(richness$exemplar))#
	{#
# Change relevant tip.labels in phy; individual 'exemplar' may be NA, use original tip.label.#
# Ordering in richness file should NOT be assumed to match order of tip.labels#
		i.na <- is.na(richness$exemplar)#
		phy$tip.label[match(richness$exemplar[!i.na], phy$tip.label)] <- as.character(richness$taxon[!i.na])#
	}#
	#
# Check names against 'richness' (already fixed above). May use 'exemplar', but *must* use 'taxon'#
# Update 'n.fossils' and 'f.time' accordingly#
# Again, assume ordering is random, but that taxa are consistent across richness files#
# Annoying number of possible combinations of file format. Don't be so nice! Force them into one or few.#
	if (!is.null(fossil.richness)) # Merge 'fossil.richness' with 'richness'#
	{#
		if (!is.null(fossil.richness$exemplar) && !is.null(richness$exemplar))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$exemplar)#
		} else if (!is.null(fossil.richness$exemplar) && !is.null(richness$taxon))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$taxon)#
# This would be odd, but allow for it; need to change tip labels to 'exemplar' from 'fossil.richness'#
	# VERY low priority#
		} else {#
			i.fossil <- match(fossil.richness$taxon, richness$taxon)#
		}#
		#
		if (length(i.fossil) != length(fossil.richness[,1])) {stop("Problem matching extant and fossil taxon information.")}#
		#
		for (i in 1:length(fossil.richness[,1]))#
		{#
			richness[i.fossil[i],"n.fossils"] <- fossil.richness[i,"n.fossils"]#
			richness[i.fossil[i],"f.time"] <- fossil.richness[i,"f.time"]#
		}#
	}#
# Just for consistency with downstream functions:#
	if (is.null(richness$n.fossils)) {richness <- cbind(richness, n.fossils=NA, f.time=NA)}#
	#
# Check if fossil.minimum==T and if any n.fossil==1; delete and warn#
	if (fossil.minimum == TRUE)#
	{#
		if (!is.na(any(richness$n.fossils == 1)))  # is it possible to be uglier?!? make pretty later.#
		{#
			if(any(richness$n.fossils == 1))#
			{#
				drop.fossil <-  (richness$n.fossils == 1)#
				drop.fossil.taxa <- as.character(richness$taxon[drop.fossil])#
				#
				richness$n.fossils[drop.fossil] <- NA#
				richness$f.time[drop.fossil] <- NA#
				#
				cat("Warning: dropped fossil observations since cannot use fossil counts == 1 as minimums:\n")#
				print(drop.fossil.taxa)#
				cat("\n")#
			}#
		}#
	}#
	#
	if (length(phy$tip.label) != length(richness[,1]))#
	{#
# Prune tree down to lineages with assigned richnesses#
		temp <- richness[, "n.taxa"]#
		names(temp) <- richness[, "taxon"]#
		pruned <- treedata(phy, temp, warnings=verbose)  # geiger function calling ape (namecheck)#
		prunedTree <- pruned$phy#
# Check the tree#
	#	plotNN(prunedTree)					# Node numbers (ape-style) plotted#
		phy <- prunedTree#
	}#
	return(list(phy=phy, richness=richness))#
}#
#
#
#
## Original default was to fit 20 models (or less if the tree was small).#
## Changing to a stop-criterion e.g. when k = n-1 (i.e. when denominator of aicc correction is undefined).#
## k <- (3*i-1) # when BOTH birth and death are estimated#
  ## This occurs when i = n/3#
  ## if est.extinction=FALSE, k <- (2*i-1); max i = n/2#
## n <- (2*num.taxa - 1) == (2*length(richness[,1]) - 1) # i.e. total number of nodes in tree (internal + pendant)#
  ## if present, consider each fossil count as one data point; i.e. n <- num.nodes + num.fossils#
## Eventually use aicc itself as a stopping criterion (not urgent, as it is very fast).#
getMaxModelLimit <- function(richness, model.limit, est.extinction, stop, verbose)#
{#
	samp.size <- sum(!is.na(richness[,"n.fossils"])) + (2*length(richness[,1]) - 1)#
	max.model.limit <- numeric()#
	#
	if (est.extinction == TRUE)#
	{#
		max.model.limit <- as.integer(samp.size/3) - ((!samp.size %% 3) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	} else {#
		max.model.limit <- as.integer(samp.size/2) - ((!samp.size %% 2) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	}#
	#
	if (stop == "model.limit")#
	{#
		if (verbose) {cat("\nLimiting consideration to ", model.limit, " piecewise diversification models\n\n", sep="")}#
	} else if (stop == "threshold") {#
		model.limit <- max.model.limit#
		if (verbose) {cat("\nConsidering a maximum of ", model.limit, " piecewise diversification models (or until threshold is not satisfied)\n\n", sep="")}#
	}#
	return(model.limit)#
}#
#
#
#
## Fitted curve from random b-d simulations#
## Value corresponds to 95th percentile of AICc(split) - AICc(no-split) for no-split simulations#
getThreshold <- function (x)#
{#
	a = -3.5941052380332650E+01#
	b =  6.7372587299747000E+00#
	c = -1.0061508340754866E-01#
	Offset =  2.7516678664333408E+01#
	y <- a * (x-b)^c + Offset#
	if (y < 0) y <- 0#
	return(y)#
}#
#
#
#
## The make.cache.medusa function is like the first half of the original splitEdgeMatrix().#
## It works through and reorders the edges, then works out start and end times of these#
## based on the phylogeny's branching times.#
###
## In addition, every node's ancestors are also calculated.  The element 'anc' is a list.#
## $anc[i] contains the indices within $edge, $t.start, etc., of all ancestors of node 'i'#
## (in ape node numbering format).#
## #
## If multiple fossil observances present for a lineage, tie all to same ancestor#
make.cache.medusa <- function(phy, richness, mc, num.cores)#
{#
	if (is.null(richness)) {stop("This should not be possible.")}#
	#
# Fix for condition where there are only two branches (i.e. no internal)#
	#
	n.tips <- length(phy$tip.label)#
	n.int <- nrow(phy$edge) - n.tips#
	bt <- branching.times(phy)#
	#
# Broken up to more easily parse fossil information; consider only internal edges first#
	if (n.int > 1)#
	{#
		i.int <- seq_len(n.int)#
		interior <- phy$edge[,2] %in% phy$edge[,1]#
		#
		edges.int <- phy$edge[interior,]#
		colnames(edges.int) <- c("anc", "dec")#
		#
		t.0 <- bt[match(edges.int[,1], (n.tips+1):max(edges.int))]#
		t.1 <- c(t.0[i.int] - phy$edge.length[interior])#
		#
		z.internal <- cbind(edges.int, t.0, t.1, t.len=t.0 - t.1,#
			n.0=rep(1, n.int), n.t=rep(NA, n.int))#
	}#
	#
# Now, pendant edges; #
# Assume that if multiple fossils per taxon, use same 'taxon' and [optionally] 'exemplar'#
	edges.pendant <- phy$edge[match(seq_len(n.tips), phy$edge[,2]),]#
	colnames(edges.pendant) <- c("anc", "dec")#
	#
	t.0 <- bt[match(edges.pendant[,1], (n.tips+1):max(edges.pendant))]#
	#
	z.pendant <- data.frame() # Put each (sub)edge on a separate row#
	#
	#
# *** Is there a way to do this without the for loop?#
#
	# if (length(phy$tip.label) == length(richness[,1])) # if no fossils, can disregard a lot of matching#
	# {#
		#
	# } else {#
		# for (i in 1:n.tips) # *** This is the slow bit; only used for fossils.#
		# {#
			# i.taxon <- which(richness$taxon == phy$tip.label[i])#
			# tmp  <- data.frame()#
			# anc=edges.pendant[i,"anc"]#
			# dec=edges.pendant[i,"dec"]#
			# cur.r0 <- 1#
			# cur.t0 <- t.0[i]#
			#
			# tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
			# z.pendant <- rbind(z.pendant, tmp)#
		# }#
	# }#
#
#
	for (i in 1:n.tips)#
	{#
		i.taxon <- which(richness$taxon == phy$tip.label[i]) # May have multiple entties due to mutliple fossil observances#
		tmp  <- data.frame()#
		anc=edges.pendant[i,"anc"]#
		dec=edges.pendant[i,"dec"]#
		cur.r0 <- 1#
		cur.r1 <- richness$n.fossils[i.taxon[1]]#
		cur.t0 <- t.0[i]#
		cur.t1 <- richness$f.time[i.taxon[1]]#
		#
		if (is.na(cur.r1)) # no fossils#
		{#
			tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0,#
				t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
		} else { # n fossils; split into n+1 rows#
			for (j in 1:length(i.taxon))#
			{#
				foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
					t.1=cur.t1, t.len=cur.t0-cur.t1, n.0=cur.r0, n.t=cur.r1)#
				tmp <- rbind (tmp, foo)#
				#
				cur.r0 <- cur.r1#
				cur.t0 <- cur.t1#
				if (j != length(i.taxon))#
				{#
					cur.r1 <- richness$n.fossils[i.taxon[j+1]]#
					cur.t1 <- richness$f.time[i.taxon[j+1]]#
				}#
			}#
			foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
				t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon[1]])#
			tmp <- rbind (tmp, foo)#
		}#
		z.pendant <- rbind(z.pendant, tmp)#
	}#
	#
	if (n.int > 1) {z <- rbind(z.internal, z.pendant)#
	} else {z <- z.pendant}#
	z <- cbind(z,partition=rep(1, length(z[,1]))) # Stores piecewise model structure#
	rownames(z) <- NULL#
	#
# Used for identifying ancestral nodes below i.e. tracking breakpoints#
	all.edges <- as.matrix(z[,c("anc","dec")])#
	#
	if (mc)#
	{#
		list(z=z, anc=mclapply(seq_len(max(all.edges)), ancestors.idx, all.edges), mc.cores=num.cores)#
	} else {#
		list(z=z, anc=lapply(seq_len(max(all.edges)), ancestors.idx, all.edges))#
	} # And, we're good to go...#
}#
#
#
#
## This generates the indices of all ancestors of a node, using ape's edge matrix.#
## Deals with row numbers of the edge matrix rather than node numbers of the tree#
ancestors <- function(node, all.edges)#
{#
	ans <- node#
	repeat#
	{#
		node <- all.edges[all.edges[,1] %in% node,2]#
		if (length(node) > 0) {ans <- c(ans, node)} else {break}#
	}#
	unlist(ans)#
}#
#
## The function 'ancestors' returns the indices of all ancestors within the edge matrix.#
ancestors.idx <- function(node.list, all.edges)#
{#
	which(all.edges[,1] == node.list | all.edges[,2] %in% ancestors(node.list, all.edges))#
}#
#
#
## Needed for determining whether nodes are virgin nodes#
getNumTips <- function(node, phy)#
{#
	n <- length(node.leaves(phy,node))#
	return(n)#
}#
#
#
#
## Only used for base model#
medusa.ml.initial <- function(z, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
#	rootnode <- min(z[is.na(z[,"n.t"]),1]) # doesn't work if only two branches (i.e. no NA)#
	#
	rootnode <- min(z[,"anc"])#
	obj <- medusa.ml.fit.partition(1, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	modelFit <- calculateModelFit(fit=obj, z, est.extinction, epsilon.value)#
	#
	if (est.extinction)#
	{#
		list(par=matrix(obj$par, nrow=1, dimnames=list(NULL,c("r", "epsilon"))), lnLik.part=obj$lnLik, #
		   lnLik=obj$lnLik, split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	} else {#
		list(par=matrix(obj$par, nrow=1,dimnames=list(NULL,"r")), lnLik.part=obj$lnLik, lnLik=obj$lnLik,#
		   split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	}#
}#
#
#
## Pre-fit values for pendant edges; DON'T recalculate later; should account for ~25% of all calculations#
medusa.ml.prefit <- function(node, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
# Partition '2' represents the pendant edge#
	fitted <- medusa.ml.fit.partition(2, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	return(fitted)#
}#
#
#
#
## 'fit' contains parameter value(s) from previous model, used to initialize subsequent model#
## Pass in pre-fitted values for pendant edges; DON'T recalculate #
medusa.ml.update <- function(node, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
	aff <- obj$affected#
	#
	op <- fit$par#
	sp <- op[aff[1],] # Use previously fit parameter values from clade that is currently being split#
	#
	fit1 <- medusa.ml.fit.partition(aff[1], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	fit2 <- 0#
	#
## Check if pendant; calculations already done#
	if (node < root.node)#
	{#
		fit2 <- tips[[node]]#
## Check if virgin node; save more time!#
	} else if (length(unique(z[(z[,"partition"] == aff[2] & z[,"dec"] < root.node),"dec"])) == num.tips[[node]])#
	{#
		fit2 <- virgin.nodes[[node - root.node]]#
## Novel arrangement; need to calculate#
	} else {#
		fit2 <- medusa.ml.fit.partition(aff[2], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	}#
	#
	op[aff[1],] <- fit1$par # Replace parameters with new values for diminished clade#
	fit$par <- rbind(op, fit2$par)#
	fit$lnLik.part[aff] <- c(fit1$lnLik, fit2$lnLik) # Replace parameters with new values for diminished clade#
	fit$split.at <- c(fit$split.at, node)#
	fit$lnLik <- sum(fit$lnLik.part)#
	#
	modelFit <- calculateModelFit(fit, z, est.extinction, epsilon.value)#
	#
	fit$aic <- modelFit[1]#
	fit$aicc <- modelFit[2]#
	fit$num.par <- modelFit[3]#
	#
	return(fit)#
}#
#
#
#
## Split the edge matrix 'z' by adding a partition rooted at node 'node'.#
##   Note: in original MEDUSA parlance, this is cutAtStem=T.#
## The list 'anc' is a list of ancestors (see make.cache.medusa, above).#
## Returns a list with elements:#
##   z: new medusa matrix, with the new partition added#
##   affected: indices of the partitions affected by the split (n == 2).#
# Add cutAtStem = F option. Allow both within a single analysis?!?#
medusa.split <- function(node, z, anc)#
{#
	part <- z[,"partition"]#
	base <- min(part[z[,1] == node | z[,2] == node])#
	tag <- max(part) + 1#
#
	i <- anc[[node]]#
	idx <- i[part[i] == base]#
	z[idx,"partition"] <- tag#
	#
	z[which(z["dec"] == node),"partition"] <- tag # Possible to have several edges to consider#
#
	list(z=z, affected=c(unique(part[idx]), tag))#
}#
#
#
#
## sp = initializing values for r & epsilon#
## Default values should never be used (except for first model), as the values from the previous model are passed in.#
medusa.ml.fit.partition <- function(partition, z, est.extinction, epsilon.value, sp=c(0.1, 0.05), fossil.minimum)#
{#
# Construct likelihood function:#
	lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
	#
	if (est.extinction) # Possibly give a range of initializing values to "navigate the banana"#
	{#
		fit <- optim(fn=lik, par=sp, method="N", control=list(fnscale=-1))#
		list(par=fit$par, lnLik=fit$value)#
	} else {#
		fit <- optimize(fn=lik, interval=c(0, 1))  # check on a valid range#
		list(par=fit$minimum, lnLik=fit$objective)#
	}#
}#
#
#
#
## make.lik.medusa.part: generate a likelihood function for a single partition.#
###
## In the pendant calculations, the variables 'A' and 'B' are the A and B terms#
## in Foote et al. Science: 283 1310-1314, p. 1313, defined as:#
## #
##   A: probability of extinction of one lineage over time 't'#
##   B: A * lambda / mu OR A / epsilon#
###
## Where there is a single lineage at time 0 (a==1), the calculation is#
##   log(1 - A) + log(1 - B) + (n-1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1-A) on a log scale) which cancels to give:#
##   log(1 - B) + (n-1)*log(B)#
## when pendant richness==1 the calculation is even simpler:#
##   log(1 - B)#
###
## When a > 1 (more than one starting species; will only happen coming off of a fossil observation),#
## the calculations follow Foote et al. 1999, put into the function 'foote.fossil.pendant'.#
## 'est.extinction' determines whether yule model is assumed#
## 'epsilon.value', if != NULL, fixes epsilon for all partitions, estimates r; not yet implemented#
## 'fossil.minimum', if == FALSE, treat fossils as exact counts#
## Only one 'partition' is passed in at a time from a proposed split.#
make.lik.medusa.part <- function(partition, est.extinction=TRUE, epsilon.value=NULL, fossil.minimum=T)#
{#
#
# Handle internal, fossil, and pendant edges separately#
	is.int <- is.na(partition[,"n.t"])#
	is.fossil <- (partition[,"n.0"] > 1) | (partition[,"t.1"] > 0 & !is.int)#
	is.pend <- !is.int == !is.fossil # pendant edges *without* fossils#
	#
	n.int <- sum(is.int)#
	n.fossil <- sum(is.fossil)#
	n.pend <- sum(is.pend)#
	#
	if (n.int + n.fossil + n.pend != length(partition[,1])) stop("You messed up, yo.")#
	#
## Internal and pendant calculations differ; split'em up#
	int  <- partition[is.int,,drop=FALSE]#
	foss <- partition[is.fossil,,drop=FALSE]#
	pend <- partition[is.pend,,drop=FALSE]#
	#
	sum.int.t.len <- sum(int[,"t.len"])  # Simply sum all internal edges#
	int.t.0 <- int[,"t.0"]#
	#
# 'n.0' = Foote's 'a', initial diversity; 'n.t' = Foote's 'n', final diversity#
	pend.n.0 <- pend[,"n.0"] # Foote's 'a': initial diversity#
	pend.n.t <- pend[,"n.t"] # Foote's 'n': final diversity#
	pend.t.len <- pend[,"t.len"]#
	#
# Don't need much of this shit anymore#
	foss.n.0 <- foss[,"n.0"]   # Not necessarily equal 1 anymore#
	foss.n.t <- foss[,"n.t"]#
	foss.t.len <- foss[,"t.0"] - foss[,"t.1"]#
	#
# User may pass in epsilon; don't change it, just estimate r#
	f <- function(pars)#
	{#
		if (est.extinction == TRUE)#
		{#
			r <- pars[1]#
			epsilon <- pars[2]#
	#		bd <- get.b.d(r, epsilon)   # Not necessary#
	#		b <- bd$b#
	#		d <- bd$d#
			#
# Previous version where b & d were estimated:#
	#		b <- pars[1]#
	#		d <- pars[2]#
	#		r <- abs(b - d)#
	#		epsilon <- d / b#
			#
			if (r < 0 | epsilon <= 0 | epsilon >= 1) {return(-Inf)}#
		} else {#
## Implement pure birth; not currently working (for some reason). Not immediately urgent, as won't work with fossils anyway#
			r <- pars[1]#
			d <- 0#
			b <- r#
			epsilon <- 0#
			#
			if (r < 0) {return(-Inf)}#
		}#
		#
		if (n.int == 0) {l.int <- 0} else {#
## Likelihood of internal edges from Rabosky et al. (2007) equation (2.3):#
			l.int <- n.int * log(r) - r * sum.int.t.len - sum(log(1 - (epsilon * exp(-r * int.t.0))))#
# Under Yule, should be: l.int <- n.int * log(r) - r * sum.int.t.len#
#
		}#
		#
		if (n.pend == 0) {l.pend <- 0} else {#
## Calculations are from the following:#
## Rabosky et al. 2007. Proc. Roy. Soc. 274: 2915-2923.#
## Foote et al. 1999. Science. 283: 1310-1314#
## Raup. 1985. Paleobiology 11: 42-52 [Foote et al. correct the equation [A18] where a > 1]#
## Bailey. 1964. The Elements Of Stochastic Processes, With Applications To The Natural Sciences#
## Kendall. 1948. Ann. Math. Stat. 19: 1–15.#
###
## A = probability of extinction of one lineage over time 't'#
## B = A * (lambda/mu)#
###
## When there is a single lineage at time 0 (a = 1), the calculation is#
##   log(1 - A) + log(1 - B) + (n - 1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1 - A) on a log scale) which cancels to give:#
##   log(1 - B) + (n - 1)*log(B)#
##      - for n.t == 1, reduces further to log(1-B)#
###
## A = mu*(exp((lambda - mu)*t) - 1)) / (lambda*exp((lambda - mu)*t) - mu)#
##  let r = (lambda - mu); ert = exp((lambda - mu)*t)#
## A = mu*(ert - 1)/(lambda*ert - mu)#
###
## B = A * (lambda/mu)#
##   = [mu*(ert - 1)/(lambda*ert - mu)] * (lambda/mu)#
##   = (lambda*(ert - 1))/(lambda*ert - mu)#
##   = (lambda*(ert - 1))/(lambda(ert - mu/lambda))#
##   = (ert - 1) / (ert - epsilon)#
#
## All pendant nodes begin with richness '1'; calculations simple.#
#			i.pend.n.t.1 <- which(pend.n.t == 1)   # calculations even simpler: log(1-B)#
#			i.pend.n.t.n1 <- which(pend.n.t != 1)#
			#
			ert <- exp(r * pend.t.len)#
			B <- (ert - 1) / (ert - epsilon) # Equivalently: B <- (bert - b) / (bert - d)#
			#
	# Under Yule should be: B <- (ert - 1) / ert#
			#
	# separate out calculations; likely not any faster (slower?)#
#			l.pend.1 <- sum(log(1 - B[i.pend.n.t.1]))#
#			l.pend.n1 <- sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
#			l.pend <- l.pend.1 + l.pend.n1#
			#
#			l.pend <- sum(log(1 - B[i.pend.n.t.1])) + #
#			   sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
			#
			l.pend <- sum(log(1 - B) + (pend.n.t - 1)*log(B)) # equivalent single formula version#
		}#
		#
# Fossils!#
		if (n.fossil == 0) {l.fossil <- 0} else {#
#
# What is desired: P(n,t,N,T) = P(n,t,1)*P(N,T-t,n)#
# - each term (internal node to fossil, and fossil to pendant node) is conditioned on survival (dividing by [1-(P(0,t,a)]^a)]#
#
			if (fossil.minimum) # loop counts from 1 -> n-1 fossils; *** NEED TO SPEED THIS SHIT UP! ***#
			{#
## First consider path from internal node to fossil, conditioning on survival (i.e. divide by (1-A)^a, although 'a' is always 1 here):#
##  sum(over x from 1 to n-1) [(1-B)*B^(x-1)]#
				#
	### *** BROKEN!!! *** ####
	#
# *** UPDATE TO NEW FORMAT ***#
				#
				ert <- exp(r * foss.t.len)#
				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
			# Under Yule should be: B <- (ert - 1) / ert#
				#
				sum.prob.int.fossil <- numeric(length(foss.n.t))#
				for (i in 1:n.fossil)#
				{#
					tmp <- 0#
					for (j in 1:foss.n.t[i])#
					{#
						tmp <- sum((B.1[i]^(j-1)), tmp)#
					}#
					sum.prob.int.fossil[i] <- (1 - B.1[i]) * tmp # (1-B) brought outside sum, as it is present in every term#
				}#
				#
# Now consider path from fossil to pendant node; looping bits in 'foote.fossil.pendant.minimum'#
				ert <- exp(r * foss.t.len)#
				A <- (ert - 1) / ((ert/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.2 <- A / epsilon                   # Equivalently: B.2 <- A * (b/d)#
				#
			# Using raw probabilities:#
				sum.prob.fossil.pend <- foote.fossil.pendant.minimum(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(log(1 - (sum.prob.int.fossil * sum.prob.fossil.pend)))#
				#
			# Using log-scale values:#
#				sum.prob.fossil.pend <- foote.fossil.pendant.combined(foss.n.t, foss.n.t, A, B.2, fossil.minimum)#
#				l.fossil <- sum(log(1 - (sum.prob.int.fossil * exp(sum.prob.fossil.pend))))#
				#
			} else { # No looping; pretty fast#
# Two scenarios:#
# 1. coming off internal node (i.e. n.0 = 1); same calculation as above#
	# log(1 - B) + (n - 1)*log(B)#
# 2. coming off fossil (i.e. n.0 > 1); need Foote equations#
				off.node <- which(foss[,"n.0"] == 1)#
				off.fossil <- which(foss[,"n.0"] != 1)#
				#
	# First, off node; n.0 = 1#
				ert.off.node <- exp(r * foss[off.node,"t.len"]) # internal node to fossil#
				B.off.node <- (ert.off.node - 1) / (ert.off.node - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
				l.off.node <- sum(log(1 - B.off.node) + (foss[off.node,"n.t"] - 1)*log(B.off.node))#
				#
#				ert <- exp(r * foss.t.len) #
#				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
		# Under Yule should be: B <- (ert - 1) / ert#
				#
				ert.off.fossil <- exp(r * foss[off.fossil,"t.len"])        # fossil to pendant node or next fossil#
				A <- (ert.off.fossil - 1) / ((ert.off.fossil/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.off.fossil <- A / epsilon                                         # Equivalently: B.2 <- A * (b/d)#
				l.off.fossil <- foote.fossil.pendant.exact(foss[off.fossil,"n.0"], foss[off.fossil,"n.t"], A, B.off.fossil)#
				#
#				l.fossil <- sum(log(1 - B.1) + (foss.n.t - 1)*log(B.1)) + #
#				   foote.fossil.pendant.exact(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(l.off.node, l.off.fossil)#
			}#
		}#
		l.int + l.pend + l.fossil#
	}#
#	l.int + l.pend + l.fossil#
}#
#
#
## Calculates the probability of having *exactly* 'a' fossils and ending with *exactly* 'n' extant species.#
## Use only when 'a', starting richness, > 1 (i.e. if coming off a fossil count).#
## For 'off-fossil' calculations, richness may increase or decrease.#
foote.fossil.pendant.exact <- function(a, n, A, B)#
{#
	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
	lB <- log(B)#
	l1mA <- log(1 - A)#
	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
	l1mB <- log(1 - B)#
	l1mA1mB <- l1mA + l1mB#
	#
#	min.a.n <- pmin(a, n) # *Insanely* slow!#
	min.a.n <- pmin.int(a, n)#
	#
	l.exact.fossil <- numeric(length(min.a.n))#
	#
	for (i in 1:length(a))#
	{#
		ji <- seq_len(min.a.n[i])#
		ai <- a[i]#
		ni <- n[i]#
		#
#		tmp <- lchoose(ai, ji) + lchoose(ni - 1, ji - 1) + (ai - ji)*lA[i] + ji*l1mA1mB[i] + (ni - ji)*lB[i]#
		#
# Non-logspace version much faster#
		foo <- choose(ai, ji) * choose(ni - 1, ji - 1) * A[i]^(ai - ji) * ((1-A[i])*(1-B[i]))^ji * B[i]^(ni - ji)#
		tmp <- sum(foo)#
		#
## Conditioning on survival factors out of the sum:#
		l.exact.fossil[i] <- sum(tmp)/(r1mA.exp.a[i])#
		#
#		l.exact.fossil[i] <- logspace_sum(tmp) - l1mA.exp.a[i] # logspace_sum: calculate log(x+y) from log(x) and log(y)#
	#	l.exact.fossil[i] <- logspace_sum(tmp) - l1mA[i]  # old conditioning; not appropriate for a > 1#
	}#
#
#	sum(l.exact.fossil)#
	return(sum(log(l.exact.fossil)))#
}#
#
#
## Calculates the probability of having *at least* 'a' fossils and ending with exactly 'n' extant species.#
## Richness may increase or decrease.#
## Should this be computed on a log-scale?#
# *** THIS IS BROKEN ***#
foote.fossil.pendant.minimum <- function(a, n, A, B)#
{#
#	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
#	lB <- log(B)#
#	l1mA <- log(1 - A)#
#	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
#	l1mB <- log(1 - B)#
#	l1mA1mB <- l1mA + l1mB#
	#
	sum.prob.fossil.pend <- numeric(length(a))#
	#
	for (i in 1:length(a)) # Loop over fossils#
	{#
		tmp <- numeric(a[i]-1)#
		for (k in 1:(a[i]-1)) # For fossil i loop over from 1 to n[i]-1#
		{#
			ai <- k#
			ni <- n[i]#
			min.a.n <- pmin.int(ai, ni)#
#			min.a.n <- pmin(ai, ni) # *Insanely* slow! pmin.int saves 70s on a 107s job! WTF?!?#
	   		j <- seq_len(min.a.n)#
			#
	# *** Should this be put on a log scale to preserve precision? ***#
	  # Tests with reasonable data yield the same answer either way#
			foo <- choose(ai, j) * choose(ni - 1, j - 1) * A[i]^(ai - j) * ((1-A[i])*(1-B[i]))^j * B[i]^(ni - j)#
			tmp[k] <- sum(foo)#
	# Alternate log form:#
	  # foo <- lchoose(ai, j) + lchoose(ni - 1, j - 1) + (ai - j)*lA[i] + j*l1mA1mB[i] + (ni - j)*lB[i]#
	    }#
	#  	tmp[i] <- sum(tmp)/(1-A[i])  # old conditioning; not appropriate for a > 1#
			#
# Conditioning on survival factors out of the sum:#
		sum.prob.fossil.pend[i] <- sum(tmp)/(r1mA.exp.a[i])#
	# Alternate log form:#
	  #	foo <- (logspace_sum(tmp))#
	  #	sum.prob.fossil.pend[i] <- foo - l1mA.exp.a[i]#
	}#
#
	return(sum.prob.fossil.pend)#
}#
#
#
## 'fit' contains '$par' and '$lnlik'#
calculateModelFit <- function(fit, z, est.extinction, epsilon.value)#
{#
## Sample size taken (for now) as the total num.nodes in the tree (internal + pendant) plus num.fossil observations#
  # num.nodes = (2*length(phy$tip.label) - 1) == (2*length(richness[,1]) - 1) == length(z[,1]) + 1#
#	n <- (length(z[,1]) + 1) + sum(!is.na(z[,"n.f"]))#
	#
# Changed structure of data; no longer have z[,"n.f"]#
# Instead, each row of z constitutes an edge#
# Since each edge defines either a node or a fossil (i.e. an 'observation'), need only add root node as final obervation#
	n <- (length(z[,1]) + 1)#
	#
## Number of parameters estimated depends on values of est.extinction and epsilon.value#
  # Includes both formal parameters AND number of breaks. Note: first model does not involve a break.#
## Models where all parameters are estimated:#
  # 2 parameters for base model (no breakpoint) + 3 parameters (r, eps, breakpoint) for each subsequent model#
## Models where only one parameter is estimated:#
  # 1 parameter for base model (no breakpoint) + 2 parameters (r, breakpoint) for each subsequent model#
	#
	if (length(fit$par) < 3) # i.e. base model#
	{#
		num.models <- 1#
	} else {#
		num.models <- length(fit$par[,1])#
	}#
	#
	if (est.extinction == FALSE || !is.null(epsilon.value)) # only one parameter estimated (plus breakpoint)#
	{#
		k <- 1 + (2 * (num.models - 1))#
	} else {#
		k <- 2 + (3 * (num.models - 1))#
	}#
	#
	lnLik <- fit$lnLik#
	#
	aic <- (-2 * lnLik) + (2*k)#
	aicc <- aic + 2*k*(k+1)/(n-k-1)#
	#
	modelFit <- c(aic, aicc, k)#
	return(modelFit)#
}#
#
#
## Prints out a table of likelihoods, parameters, aic scores, and aic weights (delta-aics are also available, if desired)#
calculateModelFitSummary <- function (models, phy, plotFig, fig.title=NULL, ...)#
{#
	tmp <- matrix(nrow=(length(models)), ncol=6)#
	colnames(tmp) <- c("N.Models", "Break.Node", "Ln.Lik", "N.Param", "aic", "aicc")#
	#
	w.aic <- numeric(length(models))#
	w.aicc <- numeric(length(models))#
	#
	for (i in 1:length(tmp[,1]))#
	{#
		tmp[i,] <- c(i, as.integer(models[[i]]$split.at[i]), models[[i]]$lnLik, models[[i]]$num.par, models[[i]]$aic, models[[i]]$aicc)#
	}#
	#
	all.res <- as.data.frame(tmp)#
	all.res[1,2] <- NA # root node for base model#
	#
	w.aic <- calculateModelWeights(all.res$aic)#
	w.aicc <- calculateModelWeights(all.res$aicc)#
	#
	all.res <- cbind(all.res[,c(1:5)], w.aic=w.aic$w, aicc=all.res$aicc, w.aicc=w.aicc$w)#
	#
	if (plotFig)#
	{#
		dev.new()#
		plotModelFit(all.res)#
		if (!is.null(fig.title)) {title(main=fig.title, cex.main=0.75)}#
	}#
	return(all.res)#
}#
#
calculateModelWeights <- function (fit)#
{#
	best <- min(fit)#
	delta <- fit-best#
	sumDelta <- sum(exp(-0.5 * delta))#
	w <- (exp(-0.5 * delta)/sumDelta)#
	#
	results <- data.frame(fit=fit,delta=delta,w=w)#
	#
	return(results)#
}#
#
plotModelFit <- function (all.res)#
{#
	ylim <- c(min(all.res[,"aic"],all.res[,"aicc"]), max(all.res[,"aic"],all.res[,"aicc"]))#
	plot(all.res[,"N.Models"],all.res[,"aicc"], xlab="Number of Piecewise Models", ylab="Model Fit", ylim=ylim, type="l", col="blue")#
	points(all.res[,"N.Models"],all.res[,"aicc"], col="blue", pch=21, bg="white")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", type="l")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", pch=21, bg="white")#
	#
	legend("topleft", c("aicc","aic"), pch=21, pt.bg="white", lty=1, col=c("blue", "black"), inset = .05, cex=0.75, bty="n") # 'bottomright' also works#
}#
#
logspace_sum <- function(logx)#
{#
	r <- logx[1]#
	if (length(logx)>1)#
	{#
		for (i in 2:length(logx)) {r <- logspace_add(r, logx[i])}#
	}#
	return(r)	#
}#
#
# Calculate log(x+y) from log(x) and log(y)#
logspace_add <- function(logx, logy)#
{#
	if (logx == -Inf)#
	{#
		return(logy)#
	} else {#
		max(logx, logy) + log1p(exp (-abs (logx - logy)))#
	}#
}#
#
#
# Print out results from a given piecewise model. May be:#
#   1. optimal model under aicc: the default#
#   2. optimal model under aic: through setting "aic=T"#
#   3. aicc model using threshold improvement (like original MEDUSA): through setting "threshold" to some value#
#   4. aic model using threshold improvement (like original MEDUSA): through setting "aic=T" and "threshold" to some value#
#   5. user-selected model: through setting "model" to some integer value (from summary table)#
# In any case, also print out base model for comparison#
# Need to parse 'results' (list of lists). Contains elements:#
#  $models, which contains:#
#     $par: i x 2 matrix (for birth-death; i x 1 for pure-birth); the jth row contains #
#       the speciation and (optional) extinction rate for the jth rate class#
#     $lnLik.part: vector of length i; the jth element is the partial log#
#       likelihood value due to the jth rate class#
#     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
#     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
#  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
#  $z: a matrix listing branch times and richnesses; for summarizing results#
#  $anc: a list of all ancestors; for summarizing results#
#  $modelSummary: data.frame listing considered models, likelihoods, number of paramters, aicc, aicc, Akaike weights.#
#
#threshold=0; aic=F; plotTree=F; time=T; cex=0.5; plotSurface=T; est.extinction=T; fossil.minimum=F; n.points=100; node.labels=T;#
#r.interval=c(0.0000001,0.9999999); e.interval=r.interval; model=NULL;#
#
summarizeFossilMEDUSA <- function(results, model=NULL, cutoff="threshold", criterion="aicc", plotTree=TRUE, time=TRUE,#
	node.labels=TRUE, cex=0.5, plotSurface=FALSE, est.extinction=TRUE, fossil.minimum=FALSE, r.interval=c(1e-10,1.0),#
	e.interval=r.interval, n.points=100, ...)#
{#
# Desirables:#
#  1. table listing parameter values of selected model#
#  2. list parameters of base model#
#  3. tree printed with colour-coded edges, node labels to indicate split position(s)#
#  4. plot likelihood surface#
	#
# Extract constituent components from results#
	fit <- results$models#
	phy <- results$phy#
	z <- results$z#
	anc <- results$anc#
	modelSummary <- results$modelSummary#
	threshold <- results$threshold#
	#
# First, determine which model is desired#
	model.id <- 0#
	if (!is.null(model))#
	{#
		model.id <- model#
	} else {   # Find best model using threshold criterion#
		if (cutoff != "threshold") {threshold <- cutoff} else {#
#			cat("\nSelecting model based on corrected threshold (decrease in information theoretic score of ", -threshold, " units).\n", sep="")}#
		model.id <- 1#
		while (1)#
		{#
			if ((model.id + 1) > length(fit)) break;#
			if ((unlist(fit[[model.id]][criterion]) - unlist(fit[[model.id+1]][criterion])) > threshold) break;#
			model.id <- model.id + 1#
		}#
	}#
	#
	break.pts <- fit[[model.id]]$split.at#
	opt.model <- as.data.frame(cbind(Split.node=break.pts, fit[[model.id]]$par, LnLik.part=fit[[model.id]]$lnLik.part))#
	base.model <- as.data.frame(fit[[1]]$par)#
	#
	cat("\nEstimated parameter values for model #", model.id, ":\n\n", sep="")#
	print.data.frame(opt.model, digits=5)#
	opt.weight <- 0#
	optFit <- 0#
	base.weight <- 0#
	baseFit <- 0#
	if (criterion == "aicc")#
	{#
		opt.weight <- modelSummary$w.aicc[model.id]#
		optFit <- modelSummary$aicc[model.id]#
		base.weight <- modelSummary$w.aicc[1]#
		baseFit <- modelSummary$aicc[1]#
	} else { # aic used#
		opt.weight <- modelSummary$w.aic[model.id]#
		optFit <- modelSummary$aic[model.id]#
		base.weight <- modelSummary$w.aic[1]#
		baseFit <- modelSummary$aic[1]#
	}#
	cat("\nModel fit summary for model #", model.id, ":\n\n", sep="")#
	cat("\tLog-likelihood = ", as.numeric(results$models[[model.id]]["lnLik"]), "\n", sep="")#
	cat("\t", criterion, " = ", optFit, "\n", sep="")#
	cat("\t", criterion, " weight = ", opt.weight, "\n\n", sep="")#
	#
	if (model.id != 1)#
	{#
		cat("\nFor comparison, estimated values for the base model are:\n\n")#
		print.data.frame(base.model, digits=5, row.names=F)#
		cat("\nModel fit summary for base model:\n\n", sep="")#
		cat("\tLog-likelihood = ", as.numeric(results$models[[1]]["lnLik"]), "\n", sep="")#
		cat("\t", criterion, " = ", baseFit, "\n", sep="")#
		cat("\t", criterion, " weight = ", base.weight, "\n\n", sep="")#
	}#
	#
# Get desired tree-model conformation#
	if (length(break.pts) > 1)#
	{#
		for (i in 2:length(break.pts))#
		{#
			tmp <- medusa.split(break.pts[i], z, anc)#
			z <- tmp$z#
		}#
	}#
	#
	#
	#
	#
# Temporary workaround#
	epsilon.value <- NULL#
	#
	#
# Plot tree with purdy colours and labelled nodes (to better map between tree and table)#
	if (plotTree)#
	{#
		dev.new()#
		margin <- F#
		#
# This need to be changed to reflect new structure#
		mm <- match(phy$edge[,2], z[,"dec"])#
		if (time) {margin=T}#
#		plot(phy, edge.color=z[mm,10], no.margin=!margin, cex=cex, ...)#
		plot(phy, edge.color=z[mm,"partition"], no.margin=!margin, cex=cex, ...)#
		if (time)#
		{#
			axisPhylo(cex.axis=0.75)#
			mtext("Divergence Time (MYA)", at=(max(get("last_plot.phylo", envir = .PlotPhyloEnv)$xx)*0.5), side = 1, line = 2, cex=0.75)#
		}#
		if (node.labels)#
		{#
			for (i in  1:length(break.pts))#
			{#
				nodelabels(i, node= break.pts[i], frame = "c", font = 1, cex=0.5)#
			}#
		}#
	}#
	#
	if (plotSurface)#
	{#
		n.pieces <- length(opt.model[,1])#
		dev.new()#
		#
		if ((sqrt(n.pieces)) == round(sqrt(n.pieces)))  #make square plotting surface#
		{#
			op <- par(mfrow=c(sqrt(n.pieces),sqrt(n.pieces)))#
		} else {#
			layout(matrix(1:n.pieces))#
		}#
		#
#	min.r <- 0.000001#
#	max.r <- max(opt.model["r"]) * 2#
		#
		if (n.pieces > 1) {cat("Computing surfaces...\n")} else {cat("Computing surface...")}#
		for (k in 1: n.pieces)#
		{#
			partition <- k#
			#
			lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
			#
			lik.vals <- matrix(nrow=n.points, ncol=n.points)#
			r.vals <- seq(from=r.interval[1], to=r.interval[2], length.out=n.points)#
			eps.vals <- seq(from=e.interval[1], to=e.interval[2], length.out=n.points)#
			#
			for (i in 1:length(r.vals))#
			{#
				for (j in 1:(length(eps.vals))) {lik.vals[i,j] <- lik(pars=c(r.vals[i], eps.vals[j]))}#
			}#
			if (n.pieces > 1) {cat("Completed computing surface for piecewise model #", k, "\n", sep="")}#
			else {cat (" done.\n")}#
		#
# Perspective plot#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood", theta=-45, phi=45)#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood")#
#	points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
#	points(x=best.r, y=best.eps, pch=16, col="blue")#
#	points(modelSummary$Ln.Lik[model.id], x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
	#
	#
	#
	#
## *** Can check on distance between MLE and best point evaluated above; if large, advize evaluating further points#
# Perhaps determine the correct number of points this way automatically?#
	#
	#
	#
	#
# Contour plot#
			#
	# This shit is only good for determining the best number of points to evaluate#
			max.lik <- max(lik.vals,na.rm=T)#
			best.r <- numeric()#
			best.eps <- numeric()#
			#
# Need to figure out which parameter values lead to this likelihood...#
			i.best <- which(lik.vals==max.lik)#
			if (length(i.best) > 1) {i.best <- i.best[1]} # if more than one combination gives best value, just grab first#
			#
	# the following determines, from the r/eps sequences, where in the the likelihood matrix the MLE lies#
			if (i.best > n.points)#
			{#
				best.r <- r.vals[i.best%%n.points]#
				best.eps <- eps.vals[ceiling(i.best/n.points)]#
			} else {#
				best.r <- r.vals[i.best]#
				best.eps <- eps.vals[1]#
			}#
#			cat("Best likelihood found: ", max.lik, " for parameter combination #", i.best, "\n", sep="")#
			#
			#
			max.lik <- as.numeric(opt.model[partition,"LnLik.part"])  # MLE#
			lines <- c(max.lik-0.5, max.lik-1, max.lik-2, max.lik-3, max.lik-4, max.lik-5, max.lik-10, max.lik-50, max.lik-100)#
			contour(lik.vals, levels=lines, labels=c(0.5, 1, 2, 3, 4, 5, 10, 50, 100), axes=FALSE, xlab="r (b-d)", ylab="epsilon (d/b)")#
			tics<-floor(c(1, n.points/4, n.points/2, n.points*3/4, n.points))#
			axis(1, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(r.vals[tics], 3))#
			axis(2, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(eps.vals[tics], 3))#
			points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red") # inferred ML values#
#			points(x=best.r, y=best.eps, pch=16, col="blue") # best from surface samples#
#			legend("topright", c("ML","Best from sampled surface"), pch=16, col=c("red", "blue"), inset = .05, cex=0.75, bty="n")#
			legend("topright", "ML", pch=16, col="red", inset = .05, cex=0.75, bty="n")#
			if (n.pieces > 1) {title(main=paste("Piecewise model #", k, sep=""))}#
		}#
	}#
}#
#
#
#
#
#
#
#
#
# *** NOT used ***#
#
#
## Get b and d values from r (b-d) and epsilson (d/b)#
## Used in previous version of program; now in terms of r and epsilon#
## Possibly of use to users wishing to translate results#
get.b.d <- function(r, epsilon)#
{#
	b <- r/(1-epsilon)#
	d <- b-r   # Alternatively: d <- eps*r/(1-eps)#
	return(list(b=b, d=d))#
}#
#
## Print out tree with ape-style node-numbering#
## Possibly of interest for users to identify numbers of node(s) off interest#
 ## If this is the case, make sure to pass in pruned tree#
plotNN <- function (phy, time=TRUE, margin=TRUE, label.offset=0.5, cex=0.5, ...) #
{#
	phy$node.label <- (length(phy$tip.label) + 1):max(phy$edge)#
	plot.phylo(phy, show.node.label=TRUE, no.margin=!margin, label.offset=label.offset, cex=cex, ...)#
	if (time && !margin) cat("Cannot plot time axis without a margin.\n")#
	else if (time && margin) axisPhylo(cex.axis=0.75)#
}
library(ape)#
library(multicore)#
library(geiger)#
#
## fossilMEDUSA #
## Written by Joseph W. Brown, Richard G. FitzJohn, Luke J. Harmon, and Michael E. Alfaro#
## Problems/bugs/questions/request: josephwb@uidaho.edu#
#
## runFossilMEDUSA:#
##  Takes in phylogeny 'phy' and (optional) 'richness' (containing extant and potentially fossil#
##  counts); 'fossil.richness' optionally passed in separately. #
## 	The species richness information (if supplied) must minimally have columns 'taxon' and 'n.taxa'; #
## 	'taxon' must match with a tip.label in the phylogeny 'phy'. May also include 'exemplar' column,#
## 	used for incompletely-sampled clades which requiring pruning. If no richness information#
##  is provided then it is assumed tips represent single species with comprehensive#
##  sampling. Returns a list of models with 0, 1, 2, ..., 'model.limit' partitions.#
##  'model.limit' can be supplied by user, but is overruled if large enough (relative#
##  to tree size) that AIC correction factor becomes undefined (different for pure birth vs.#
##  birth-death models). 'phy' is assumed to be ultrametric; this is not checked. #
## #
## Returned list has elements:#
##  $models, which contains:#
##     $par: i x 2 matrix (for birth-death parameters); the jth row contains #
##       the speciation and extinction rate for the jth rate class#
##     $lnLik.part: vector of length i; the jth element is the partial log#
##       likelihood value due to the jth rate class#
##     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
##     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
##  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
##  $z: a matrix listing branch times and richnesses; for summarizing results#
##  $anc: a list of all ancestors; for summarizing results#
##  $modelSummary: data.frame listing considered models, likelihoods, AIC, etc.#
#
## Features (to be) added: specify epsilon (for every piecewise model), estimate r.#
## An argument 'epsilon.value' is passed; if NULL, normal MEDUSA is performed.#
#
## TO-DO:#
 # 0. fossil counts in pendant edges - DONE (but slow when fossil.minimum==T)#
 # 1. option for no extinction (i.e. pure birth) (lower priority)#
 # 2. set epsilon to some value (for all piecewise models), estimate r (num.par = 2*num.models - 1)#
 # 3. implement cutAtStem=FALSE (very low priority) # abandon?!?#
 # calculate fossil likelihoods using C++ - WORKING#
#
#
## Function to prune tree using 'richness' information, assumed to have minimally two columns, "taxon" and "n.taxa"#
##   Perhaps relax on these column names, may cause too many problems#
## May also include 'exemplar' column; in that case, rename relevant tip.label before pruning.#
## In addition, may have columns 'n.fossils' and 'f.time'; must match names exactly or ambiguous error generated.#
##   Taxa without fossil counts should have NA in n.fossil and f.time columns.#
## If 'fossil.richness' passed in separately, merge with 'richness'#
pruneTreeMergeData <- function(phy, richness, fossil.richness=NULL, fossil.minimum=FALSE, verbose=T)#
{#
# Sort for downstream functions#
	if (is.null(richness$n.fossils))#
	{#
		richness <- richness[order(richness $taxon),]#
	} else {#
		richness <- richness[order(richness $taxon, -richness$f.time),]#
	}#
	rownames(richness) <- NULL#
# Rename exemplar taxa with taxon name in richness file#
	if (!is.null(richness$exemplar))#
	{#
# Change relevant tip.labels in phy; individual 'exemplar' may be NA, use original tip.label.#
# Ordering in richness file should NOT be assumed to match order of tip.labels#
		i.na <- is.na(richness$exemplar)#
		phy$tip.label[match(richness$exemplar[!i.na], phy$tip.label)] <- as.character(richness$taxon[!i.na])#
	}#
	#
# Check names against 'richness' (already fixed above). May use 'exemplar', but *must* use 'taxon'#
# Update 'n.fossils' and 'f.time' accordingly#
# Again, assume ordering is random, but that taxa are consistent across richness files#
# Annoying number of possible combinations of file format. Don't be so nice! Force them into one or few.#
	if (!is.null(fossil.richness)) # Merge 'fossil.richness' with 'richness'#
	{#
		if (!is.null(fossil.richness$exemplar) && !is.null(richness$exemplar))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$exemplar)#
		} else if (!is.null(fossil.richness$exemplar) && !is.null(richness$taxon))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$taxon)#
# This would be odd, but allow for it; need to change tip labels to 'exemplar' from 'fossil.richness'#
	# VERY low priority#
		} else {#
			i.fossil <- match(fossil.richness$taxon, richness$taxon)#
		}#
		#
		if (length(i.fossil) != length(fossil.richness[,1])) {stop("Problem matching extant and fossil taxon information.")}#
		#
		for (i in 1:length(fossil.richness[,1]))#
		{#
			richness[i.fossil[i],"n.fossils"] <- fossil.richness[i,"n.fossils"]#
			richness[i.fossil[i],"f.time"] <- fossil.richness[i,"f.time"]#
		}#
	}#
# Just for consistency with downstream functions:#
	if (is.null(richness$n.fossils)) {richness <- cbind(richness, n.fossils=NA, f.time=NA)}#
	#
# Check if fossil.minimum==T and if any n.fossil==1; delete and warn#
	if (fossil.minimum == TRUE)#
	{#
		if (!is.na(any(richness$n.fossils == 1)))  # is it possible to be uglier?!? make pretty later.#
		{#
			if(any(richness$n.fossils == 1))#
			{#
				drop.fossil <-  (richness$n.fossils == 1)#
				drop.fossil.taxa <- as.character(richness$taxon[drop.fossil])#
				#
				richness$n.fossils[drop.fossil] <- NA#
				richness$f.time[drop.fossil] <- NA#
				#
				cat("Warning: dropped fossil observations since cannot use fossil counts == 1 as minimums:\n")#
				print(drop.fossil.taxa)#
				cat("\n")#
			}#
		}#
	}#
	#
	if (length(phy$tip.label) != length(richness[,1]))#
	{#
# Prune tree down to lineages with assigned richnesses#
		temp <- richness[, "n.taxa"]#
		names(temp) <- richness[, "taxon"]#
		pruned <- treedata(phy, temp, warnings=verbose)  # geiger function calling ape (namecheck)#
		prunedTree <- pruned$phy#
# Check the tree#
	#	plotNN(prunedTree)					# Node numbers (ape-style) plotted#
		phy <- prunedTree#
	}#
	return(list(phy=phy, richness=richness))#
}#
#
#
#
## Original default was to fit 20 models (or less if the tree was small).#
## Changing to a stop-criterion e.g. when k = n-1 (i.e. when denominator of aicc correction is undefined).#
## k <- (3*i-1) # when BOTH birth and death are estimated#
  ## This occurs when i = n/3#
  ## if est.extinction=FALSE, k <- (2*i-1); max i = n/2#
## n <- (2*num.taxa - 1) == (2*length(richness[,1]) - 1) # i.e. total number of nodes in tree (internal + pendant)#
  ## if present, consider each fossil count as one data point; i.e. n <- num.nodes + num.fossils#
## Eventually use aicc itself as a stopping criterion (not urgent, as it is very fast).#
getMaxModelLimit <- function(richness, model.limit, est.extinction, stop, verbose)#
{#
	samp.size <- sum(!is.na(richness[,"n.fossils"])) + (2*length(richness[,1]) - 1)#
	max.model.limit <- numeric()#
	#
	if (est.extinction == TRUE)#
	{#
		max.model.limit <- as.integer(samp.size/3) - ((!samp.size %% 3) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	} else {#
		max.model.limit <- as.integer(samp.size/2) - ((!samp.size %% 2) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	}#
	#
	if (stop == "model.limit")#
	{#
		if (verbose) {cat("\nLimiting consideration to ", model.limit, " piecewise diversification models\n\n", sep="")}#
	} else if (stop == "threshold") {#
		model.limit <- max.model.limit#
		if (verbose) {cat("\nConsidering a maximum of ", model.limit, " piecewise diversification models (or until threshold is not satisfied)\n\n", sep="")}#
	}#
	return(model.limit)#
}#
#
#
#
## Fitted curve from random b-d simulations#
## Value corresponds to 95th percentile of AICc(split) - AICc(no-split) for no-split simulations#
getThreshold <- function (x)#
{#
	a = -3.5941052380332650E+01#
	b =  6.7372587299747000E+00#
	c = -1.0061508340754866E-01#
	Offset =  2.7516678664333408E+01#
	y <- a * (x-b)^c + Offset#
	if (y < 0) y <- 0#
	return(y)#
}#
#
#
#
## The make.cache.medusa function is like the first half of the original splitEdgeMatrix().#
## It works through and reorders the edges, then works out start and end times of these#
## based on the phylogeny's branching times.#
###
## In addition, every node's ancestors are also calculated.  The element 'anc' is a list.#
## $anc[i] contains the indices within $edge, $t.start, etc., of all ancestors of node 'i'#
## (in ape node numbering format).#
## #
## If multiple fossil observances present for a lineage, tie all to same ancestor#
make.cache.medusa <- function(phy, richness, mc, num.cores)#
{#
	if (is.null(richness)) {stop("This should not be possible.")}#
	#
# Fix for condition where there are only two branches (i.e. no internal)#
	#
	n.tips <- length(phy$tip.label)#
	n.int <- nrow(phy$edge) - n.tips#
	bt <- branching.times(phy)#
	#
# Broken up to more easily parse fossil information; consider only internal edges first#
	if (n.int > 1)#
	{#
		i.int <- seq_len(n.int)#
		interior <- phy$edge[,2] %in% phy$edge[,1]#
		#
		edges.int <- phy$edge[interior,]#
		colnames(edges.int) <- c("anc", "dec")#
		#
		t.0 <- bt[match(edges.int[,1], (n.tips+1):max(edges.int))]#
		t.1 <- c(t.0[i.int] - phy$edge.length[interior])#
		#
		z.internal <- cbind(edges.int, t.0, t.1, t.len=t.0 - t.1,#
			n.0=rep(1, n.int), n.t=rep(NA, n.int))#
	}#
	#
# Now, pendant edges; #
# Assume that if multiple fossils per taxon, use same 'taxon' and [optionally] 'exemplar'#
	edges.pendant <- phy$edge[match(seq_len(n.tips), phy$edge[,2]),]#
	colnames(edges.pendant) <- c("anc", "dec")#
	#
	t.0 <- bt[match(edges.pendant[,1], (n.tips+1):max(edges.pendant))]#
	#
	z.pendant <- data.frame() # Put each (sub)edge on a separate row#
	#
	#
# *** Is there a way to do this without the for loop?#
#
	# if (length(phy$tip.label) == length(richness[,1])) # if no fossils, can disregard a lot of matching#
	# {#
		#
	# } else {#
		# for (i in 1:n.tips) # *** This is the slow bit; only used for fossils.#
		# {#
			# i.taxon <- which(richness$taxon == phy$tip.label[i])#
			# tmp  <- data.frame()#
			# anc=edges.pendant[i,"anc"]#
			# dec=edges.pendant[i,"dec"]#
			# cur.r0 <- 1#
			# cur.t0 <- t.0[i]#
			#
			# tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
			# z.pendant <- rbind(z.pendant, tmp)#
		# }#
	# }#
#
#
	for (i in 1:n.tips)#
	{#
		i.taxon <- which(richness$taxon == phy$tip.label[i]) # May have multiple entties due to mutliple fossil observances#
		tmp  <- data.frame()#
		anc=edges.pendant[i,"anc"]#
		dec=edges.pendant[i,"dec"]#
		cur.r0 <- 1#
		cur.r1 <- richness$n.fossils[i.taxon[1]]#
		cur.t0 <- t.0[i]#
		cur.t1 <- richness$f.time[i.taxon[1]]#
		#
		if (is.na(cur.r1)) # no fossils#
		{#
			tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0,#
				t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
		} else { # n fossils; split into n+1 rows#
			for (j in 1:length(i.taxon))#
			{#
				foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
					t.1=cur.t1, t.len=cur.t0-cur.t1, n.0=cur.r0, n.t=cur.r1)#
				tmp <- rbind (tmp, foo)#
				#
				cur.r0 <- cur.r1#
				cur.t0 <- cur.t1#
				if (j != length(i.taxon))#
				{#
					cur.r1 <- richness$n.fossils[i.taxon[j+1]]#
					cur.t1 <- richness$f.time[i.taxon[j+1]]#
				}#
			}#
			foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
				t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon[1]])#
			tmp <- rbind (tmp, foo)#
		}#
		z.pendant <- rbind(z.pendant, tmp)#
	}#
	#
	if (n.int > 1) {z <- rbind(z.internal, z.pendant)#
	} else {z <- z.pendant}#
	z <- cbind(z,partition=rep(1, length(z[,1]))) # Stores piecewise model structure#
	rownames(z) <- NULL#
	#
# Used for identifying ancestral nodes below i.e. tracking breakpoints#
	all.edges <- as.matrix(z[,c("anc","dec")])#
	#
	if (mc)#
	{#
		list(z=z, anc=mclapply(seq_len(max(all.edges)), ancestors.idx, all.edges), mc.cores=num.cores)#
	} else {#
		list(z=z, anc=lapply(seq_len(max(all.edges)), ancestors.idx, all.edges))#
	} # And, we're good to go...#
}#
#
#
#
## This generates the indices of all ancestors of a node, using ape's edge matrix.#
## Deals with row numbers of the edge matrix rather than node numbers of the tree#
ancestors <- function(node, all.edges)#
{#
	ans <- node#
	repeat#
	{#
		node <- all.edges[all.edges[,1] %in% node,2]#
		if (length(node) > 0) {ans <- c(ans, node)} else {break}#
	}#
	unlist(ans)#
}#
#
## The function 'ancestors' returns the indices of all ancestors within the edge matrix.#
ancestors.idx <- function(node.list, all.edges)#
{#
	which(all.edges[,1] == node.list | all.edges[,2] %in% ancestors(node.list, all.edges))#
}#
#
#
## Needed for determining whether nodes are virgin nodes#
getNumTips <- function(node, phy)#
{#
	n <- length(node.leaves(phy,node))#
	return(n)#
}#
#
#
#
## Only used for base model#
medusa.ml.initial <- function(z, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
#	rootnode <- min(z[is.na(z[,"n.t"]),1]) # doesn't work if only two branches (i.e. no NA)#
	#
	rootnode <- min(z[,"anc"])#
	obj <- medusa.ml.fit.partition(1, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	modelFit <- calculateModelFit(fit=obj, z, est.extinction, epsilon.value)#
	#
	if (est.extinction)#
	{#
		list(par=matrix(obj$par, nrow=1, dimnames=list(NULL,c("r", "epsilon"))), lnLik.part=obj$lnLik, #
		   lnLik=obj$lnLik, split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	} else {#
		list(par=matrix(obj$par, nrow=1,dimnames=list(NULL,"r")), lnLik.part=obj$lnLik, lnLik=obj$lnLik,#
		   split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	}#
}#
#
#
## Pre-fit values for pendant edges; DON'T recalculate later; should account for ~25% of all calculations#
medusa.ml.prefit <- function(node, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
# Partition '2' represents the pendant edge#
	fitted <- medusa.ml.fit.partition(2, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	return(fitted)#
}#
#
#
#
## 'fit' contains parameter value(s) from previous model, used to initialize subsequent model#
## Pass in pre-fitted values for pendant edges; DON'T recalculate #
medusa.ml.update <- function(node, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
	aff <- obj$affected#
	#
	op <- fit$par#
	sp <- op[aff[1],] # Use previously fit parameter values from clade that is currently being split#
	#
	fit1 <- medusa.ml.fit.partition(aff[1], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	fit2 <- 0#
	#
## Check if pendant; calculations already done#
	if (node < root.node)#
	{#
		fit2 <- tips[[node]]#
## Check if virgin node; save more time!#
	} else if (length(unique(z[(z[,"partition"] == aff[2] & z[,"dec"] < root.node),"dec"])) == num.tips[[node]])#
	{#
		fit2 <- virgin.nodes[[node - root.node]]#
## Novel arrangement; need to calculate#
	} else {#
		fit2 <- medusa.ml.fit.partition(aff[2], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	}#
	#
	op[aff[1],] <- fit1$par # Replace parameters with new values for diminished clade#
	fit$par <- rbind(op, fit2$par)#
	fit$lnLik.part[aff] <- c(fit1$lnLik, fit2$lnLik) # Replace parameters with new values for diminished clade#
	fit$split.at <- c(fit$split.at, node)#
	fit$lnLik <- sum(fit$lnLik.part)#
	#
	modelFit <- calculateModelFit(fit, z, est.extinction, epsilon.value)#
	#
	fit$aic <- modelFit[1]#
	fit$aicc <- modelFit[2]#
	fit$num.par <- modelFit[3]#
	#
	return(fit)#
}#
#
#
#
## Split the edge matrix 'z' by adding a partition rooted at node 'node'.#
##   Note: in original MEDUSA parlance, this is cutAtStem=T.#
## The list 'anc' is a list of ancestors (see make.cache.medusa, above).#
## Returns a list with elements:#
##   z: new medusa matrix, with the new partition added#
##   affected: indices of the partitions affected by the split (n == 2).#
# Add cutAtStem = F option. Allow both within a single analysis?!?#
medusa.split <- function(node, z, anc)#
{#
	part <- z[,"partition"]#
	base <- min(part[z[,1] == node | z[,2] == node])#
	tag <- max(part) + 1#
#
	i <- anc[[node]]#
	idx <- i[part[i] == base]#
	z[idx,"partition"] <- tag#
	#
	z[which(z["dec"] == node),"partition"] <- tag # Possible to have several edges to consider#
#
	list(z=z, affected=c(unique(part[idx]), tag))#
}#
#
#
#
## sp = initializing values for r & epsilon#
## Default values should never be used (except for first model), as the values from the previous model are passed in.#
medusa.ml.fit.partition <- function(partition, z, est.extinction, epsilon.value, sp=c(0.1, 0.05), fossil.minimum)#
{#
# Construct likelihood function:#
	lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
	#
	if (est.extinction) # Possibly give a range of initializing values to "navigate the banana"#
	{#
		fit <- optim(fn=lik, par=sp, method="N", control=list(fnscale=-1))#
		list(par=fit$par, lnLik=fit$value)#
	} else {#
		fit <- optimize(fn=lik, interval=c(0, 1))  # check on a valid range#
		list(par=fit$minimum, lnLik=fit$objective)#
	}#
}#
#
#
#
## make.lik.medusa.part: generate a likelihood function for a single partition.#
###
## In the pendant calculations, the variables 'A' and 'B' are the A and B terms#
## in Foote et al. Science: 283 1310-1314, p. 1313, defined as:#
## #
##   A: probability of extinction of one lineage over time 't'#
##   B: A * lambda / mu OR A / epsilon#
###
## Where there is a single lineage at time 0 (a==1), the calculation is#
##   log(1 - A) + log(1 - B) + (n-1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1-A) on a log scale) which cancels to give:#
##   log(1 - B) + (n-1)*log(B)#
## when pendant richness==1 the calculation is even simpler:#
##   log(1 - B)#
###
## When a > 1 (more than one starting species; will only happen coming off of a fossil observation),#
## the calculations follow Foote et al. 1999, put into the function 'foote.fossil.pendant'.#
## 'est.extinction' determines whether yule model is assumed#
## 'epsilon.value', if != NULL, fixes epsilon for all partitions, estimates r; not yet implemented#
## 'fossil.minimum', if == FALSE, treat fossils as exact counts#
## Only one 'partition' is passed in at a time from a proposed split.#
make.lik.medusa.part <- function(partition, est.extinction=TRUE, epsilon.value=NULL, fossil.minimum=T)#
{#
#
# Handle internal, fossil, and pendant edges separately#
	is.int <- is.na(partition[,"n.t"])#
	is.fossil <- (partition[,"n.0"] > 1) | (partition[,"t.1"] > 0 & !is.int)#
	is.pend <- !is.int == !is.fossil # pendant edges *without* fossils#
	#
	n.int <- sum(is.int)#
	n.fossil <- sum(is.fossil)#
	n.pend <- sum(is.pend)#
	#
	if (n.int + n.fossil + n.pend != length(partition[,1])) stop("You messed up, yo.")#
	#
## Internal and pendant calculations differ; split'em up#
	int  <- partition[is.int,,drop=FALSE]#
	foss <- partition[is.fossil,,drop=FALSE]#
	pend <- partition[is.pend,,drop=FALSE]#
	#
	sum.int.t.len <- sum(int[,"t.len"])  # Simply sum all internal edges#
	int.t.0 <- int[,"t.0"]#
	#
# 'n.0' = Foote's 'a', initial diversity; 'n.t' = Foote's 'n', final diversity#
	pend.n.0 <- pend[,"n.0"] # Foote's 'a': initial diversity#
	pend.n.t <- pend[,"n.t"] # Foote's 'n': final diversity#
	pend.t.len <- pend[,"t.len"]#
	#
# Don't need much of this shit anymore#
	foss.n.0 <- foss[,"n.0"]   # Not necessarily equal 1 anymore#
	foss.n.t <- foss[,"n.t"]#
	foss.t.len <- foss[,"t.0"] - foss[,"t.1"]#
	#
# User may pass in epsilon; don't change it, just estimate r#
	f <- function(pars)#
	{#
		if (est.extinction == TRUE)#
		{#
			r <- pars[1]#
			epsilon <- pars[2]#
	#		bd <- get.b.d(r, epsilon)   # Not necessary#
	#		b <- bd$b#
	#		d <- bd$d#
			#
# Previous version where b & d were estimated:#
	#		b <- pars[1]#
	#		d <- pars[2]#
	#		r <- abs(b - d)#
	#		epsilon <- d / b#
			#
			if (r < 0 | epsilon <= 0 | epsilon >= 1) {return(-Inf)}#
		} else {#
## Implement pure birth; not currently working (for some reason). Not immediately urgent, as won't work with fossils anyway#
			r <- pars[1]#
			d <- 0#
			b <- r#
			epsilon <- 0#
			#
			if (r < 0) {return(-Inf)}#
		}#
		#
		if (n.int == 0) {l.int <- 0} else {#
## Likelihood of internal edges from Rabosky et al. (2007) equation (2.3):#
			l.int <- n.int * log(r) - r * sum.int.t.len - sum(log(1 - (epsilon * exp(-r * int.t.0))))#
# Under Yule, should be: l.int <- n.int * log(r) - r * sum.int.t.len#
#
		}#
		#
		if (n.pend == 0) {l.pend <- 0} else {#
## Calculations are from the following:#
## Rabosky et al. 2007. Proc. Roy. Soc. 274: 2915-2923.#
## Foote et al. 1999. Science. 283: 1310-1314#
## Raup. 1985. Paleobiology 11: 42-52 [Foote et al. correct the equation [A18] where a > 1]#
## Bailey. 1964. The Elements Of Stochastic Processes, With Applications To The Natural Sciences#
## Kendall. 1948. Ann. Math. Stat. 19: 1–15.#
###
## A = probability of extinction of one lineage over time 't'#
## B = A * (lambda/mu)#
###
## When there is a single lineage at time 0 (a = 1), the calculation is#
##   log(1 - A) + log(1 - B) + (n - 1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1 - A) on a log scale) which cancels to give:#
##   log(1 - B) + (n - 1)*log(B)#
##      - for n.t == 1, reduces further to log(1-B)#
###
## A = mu*(exp((lambda - mu)*t) - 1)) / (lambda*exp((lambda - mu)*t) - mu)#
##  let r = (lambda - mu); ert = exp((lambda - mu)*t)#
## A = mu*(ert - 1)/(lambda*ert - mu)#
###
## B = A * (lambda/mu)#
##   = [mu*(ert - 1)/(lambda*ert - mu)] * (lambda/mu)#
##   = (lambda*(ert - 1))/(lambda*ert - mu)#
##   = (lambda*(ert - 1))/(lambda(ert - mu/lambda))#
##   = (ert - 1) / (ert - epsilon)#
#
## All pendant nodes begin with richness '1'; calculations simple.#
#			i.pend.n.t.1 <- which(pend.n.t == 1)   # calculations even simpler: log(1-B)#
#			i.pend.n.t.n1 <- which(pend.n.t != 1)#
			#
			ert <- exp(r * pend.t.len)#
			B <- (ert - 1) / (ert - epsilon) # Equivalently: B <- (bert - b) / (bert - d)#
			#
	# Under Yule should be: B <- (ert - 1) / ert#
			#
	# separate out calculations; likely not any faster (slower?)#
#			l.pend.1 <- sum(log(1 - B[i.pend.n.t.1]))#
#			l.pend.n1 <- sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
#			l.pend <- l.pend.1 + l.pend.n1#
			#
#			l.pend <- sum(log(1 - B[i.pend.n.t.1])) + #
#			   sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
			#
			l.pend <- sum(log(1 - B) + (pend.n.t - 1)*log(B)) # equivalent single formula version#
		}#
		#
# Fossils!#
		if (n.fossil == 0) {l.fossil <- 0} else {#
#
# What is desired: P(n,t,N,T) = P(n,t,1)*P(N,T-t,n)#
# - each term (internal node to fossil, and fossil to pendant node) is conditioned on survival (dividing by [1-(P(0,t,a)]^a)]#
#
			if (fossil.minimum) # loop counts from 1 -> n-1 fossils; *** NEED TO SPEED THIS SHIT UP! ***#
			{#
## First consider path from internal node to fossil, conditioning on survival (i.e. divide by (1-A)^a, although 'a' is always 1 here):#
##  sum(over x from 1 to n-1) [(1-B)*B^(x-1)]#
				#
	### *** BROKEN!!! *** ####
	#
# *** UPDATE TO NEW FORMAT ***#
				#
				ert <- exp(r * foss.t.len)#
				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
			# Under Yule should be: B <- (ert - 1) / ert#
				#
				sum.prob.int.fossil <- numeric(length(foss.n.t))#
				for (i in 1:n.fossil)#
				{#
					tmp <- 0#
					for (j in 1:foss.n.t[i])#
					{#
						tmp <- sum((B.1[i]^(j-1)), tmp)#
					}#
					sum.prob.int.fossil[i] <- (1 - B.1[i]) * tmp # (1-B) brought outside sum, as it is present in every term#
				}#
				#
# Now consider path from fossil to pendant node; looping bits in 'foote.fossil.pendant.minimum'#
				ert <- exp(r * foss.t.len)#
				A <- (ert - 1) / ((ert/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.2 <- A / epsilon                   # Equivalently: B.2 <- A * (b/d)#
				#
			# Using raw probabilities:#
				sum.prob.fossil.pend <- foote.fossil.pendant.minimum(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(log(1 - (sum.prob.int.fossil * sum.prob.fossil.pend)))#
				#
			# Using log-scale values:#
#				sum.prob.fossil.pend <- foote.fossil.pendant.combined(foss.n.t, foss.n.t, A, B.2, fossil.minimum)#
#				l.fossil <- sum(log(1 - (sum.prob.int.fossil * exp(sum.prob.fossil.pend))))#
				#
			} else { # No looping; pretty fast#
# Two scenarios:#
# 1. coming off internal node (i.e. n.0 = 1); same calculation as above#
	# log(1 - B) + (n - 1)*log(B)#
# 2. coming off fossil (i.e. n.0 > 1); need Foote equations#
				off.node <- which(foss[,"n.0"] == 1)#
				off.fossil <- which(foss[,"n.0"] != 1)#
				#
	# First, off node; n.0 = 1#
				ert.off.node <- exp(r * foss[off.node,"t.len"]) # internal node to fossil#
				B.off.node <- (ert.off.node - 1) / (ert.off.node - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
				l.off.node <- sum(log(1 - B.off.node) + (foss[off.node,"n.t"] - 1)*log(B.off.node))#
				#
#				ert <- exp(r * foss.t.len) #
#				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
		# Under Yule should be: B <- (ert - 1) / ert#
				#
				ert.off.fossil <- exp(r * foss[off.fossil,"t.len"])        # fossil to pendant node or next fossil#
				A <- (ert.off.fossil - 1) / ((ert.off.fossil/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.off.fossil <- A / epsilon                                         # Equivalently: B.2 <- A * (b/d)#
				l.off.fossil <- foote.fossil.pendant.exact(foss[off.fossil,"n.0"], foss[off.fossil,"n.t"], A, B.off.fossil)#
				#
#				l.fossil <- sum(log(1 - B.1) + (foss.n.t - 1)*log(B.1)) + #
#				   foote.fossil.pendant.exact(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(l.off.node, l.off.fossil)#
			}#
		}#
		l.int + l.pend + l.fossil#
	}#
#	l.int + l.pend + l.fossil#
}#
#
#
## Calculates the probability of having *exactly* 'a' fossils and ending with *exactly* 'n' extant species.#
## Use only when 'a', starting richness, > 1 (i.e. if coming off a fossil count).#
## For 'off-fossil' calculations, richness may increase or decrease.#
foote.fossil.pendant.exact <- function(a, n, A, B)#
{#
	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
	lB <- log(B)#
	l1mA <- log(1 - A)#
	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
	l1mB <- log(1 - B)#
	l1mA1mB <- l1mA + l1mB#
	#
#	min.a.n <- pmin(a, n) # *Insanely* slow!#
	min.a.n <- pmin.int(a, n)#
	#
	l.exact.fossil <- numeric(length(min.a.n))#
	#
	for (i in 1:length(a))#
	{#
		ji <- seq_len(min.a.n[i])#
		ai <- a[i]#
		ni <- n[i]#
		#
#		tmp <- lchoose(ai, ji) + lchoose(ni - 1, ji - 1) + (ai - ji)*lA[i] + ji*l1mA1mB[i] + (ni - ji)*lB[i]#
		#
# Non-logspace version much faster#
		foo <- choose(ai, ji) * choose(ni - 1, ji - 1) * A[i]^(ai - ji) * ((1-A[i])*(1-B[i]))^ji * B[i]^(ni - ji)#
		tmp <- sum(foo)#
		#
## Conditioning on survival factors out of the sum:#
		l.exact.fossil[i] <- sum(tmp)/(r1mA.exp.a[i])#
		#
#		l.exact.fossil[i] <- logspace_sum(tmp) - l1mA.exp.a[i] # logspace_sum: calculate log(x+y) from log(x) and log(y)#
	#	l.exact.fossil[i] <- logspace_sum(tmp) - l1mA[i]  # old conditioning; not appropriate for a > 1#
	}#
#
#	sum(l.exact.fossil)#
	return(sum(log(l.exact.fossil)))#
}#
#
#
## Calculates the probability of having *at least* 'a' fossils and ending with exactly 'n' extant species.#
## Richness may increase or decrease.#
## Should this be computed on a log-scale?#
# *** THIS IS BROKEN ***#
foote.fossil.pendant.minimum <- function(a, n, A, B)#
{#
#	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
#	lB <- log(B)#
#	l1mA <- log(1 - A)#
#	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
#	l1mB <- log(1 - B)#
#	l1mA1mB <- l1mA + l1mB#
	#
	sum.prob.fossil.pend <- numeric(length(a))#
	#
	for (i in 1:length(a)) # Loop over fossils#
	{#
		tmp <- numeric(a[i]-1)#
		for (k in 1:(a[i]-1)) # For fossil i loop over from 1 to n[i]-1#
		{#
			ai <- k#
			ni <- n[i]#
			min.a.n <- pmin.int(ai, ni)#
#			min.a.n <- pmin(ai, ni) # *Insanely* slow! pmin.int saves 70s on a 107s job! WTF?!?#
	   		j <- seq_len(min.a.n)#
			#
	# *** Should this be put on a log scale to preserve precision? ***#
	  # Tests with reasonable data yield the same answer either way#
			foo <- choose(ai, j) * choose(ni - 1, j - 1) * A[i]^(ai - j) * ((1-A[i])*(1-B[i]))^j * B[i]^(ni - j)#
			tmp[k] <- sum(foo)#
	# Alternate log form:#
	  # foo <- lchoose(ai, j) + lchoose(ni - 1, j - 1) + (ai - j)*lA[i] + j*l1mA1mB[i] + (ni - j)*lB[i]#
	    }#
	#  	tmp[i] <- sum(tmp)/(1-A[i])  # old conditioning; not appropriate for a > 1#
			#
# Conditioning on survival factors out of the sum:#
		sum.prob.fossil.pend[i] <- sum(tmp)/(r1mA.exp.a[i])#
	# Alternate log form:#
	  #	foo <- (logspace_sum(tmp))#
	  #	sum.prob.fossil.pend[i] <- foo - l1mA.exp.a[i]#
	}#
#
	return(sum.prob.fossil.pend)#
}#
#
#
## 'fit' contains '$par' and '$lnlik'#
calculateModelFit <- function(fit, z, est.extinction, epsilon.value)#
{#
## Sample size taken (for now) as the total num.nodes in the tree (internal + pendant) plus num.fossil observations#
  # num.nodes = (2*length(phy$tip.label) - 1) == (2*length(richness[,1]) - 1) == length(z[,1]) + 1#
#	n <- (length(z[,1]) + 1) + sum(!is.na(z[,"n.f"]))#
	#
# Changed structure of data; no longer have z[,"n.f"]#
# Instead, each row of z constitutes an edge#
# Since each edge defines either a node or a fossil (i.e. an 'observation'), need only add root node as final obervation#
	n <- (length(z[,1]) + 1)#
	#
## Number of parameters estimated depends on values of est.extinction and epsilon.value#
  # Includes both formal parameters AND number of breaks. Note: first model does not involve a break.#
## Models where all parameters are estimated:#
  # 2 parameters for base model (no breakpoint) + 3 parameters (r, eps, breakpoint) for each subsequent model#
## Models where only one parameter is estimated:#
  # 1 parameter for base model (no breakpoint) + 2 parameters (r, breakpoint) for each subsequent model#
	#
	if (length(fit$par) < 3) # i.e. base model#
	{#
		num.models <- 1#
	} else {#
		num.models <- length(fit$par[,1])#
	}#
	#
	if (est.extinction == FALSE || !is.null(epsilon.value)) # only one parameter estimated (plus breakpoint)#
	{#
		k <- 1 + (2 * (num.models - 1))#
	} else {#
		k <- 2 + (3 * (num.models - 1))#
	}#
	#
	lnLik <- fit$lnLik#
	#
	aic <- (-2 * lnLik) + (2*k)#
	aicc <- aic + 2*k*(k+1)/(n-k-1)#
	#
	modelFit <- c(aic, aicc, k)#
	return(modelFit)#
}#
#
#
## Prints out a table of likelihoods, parameters, aic scores, and aic weights (delta-aics are also available, if desired)#
calculateModelFitSummary <- function (models, phy, plotFig, fig.title=NULL, ...)#
{#
	tmp <- matrix(nrow=(length(models)), ncol=6)#
	colnames(tmp) <- c("N.Models", "Break.Node", "Ln.Lik", "N.Param", "aic", "aicc")#
	#
	w.aic <- numeric(length(models))#
	w.aicc <- numeric(length(models))#
	#
	for (i in 1:length(tmp[,1]))#
	{#
		tmp[i,] <- c(i, as.integer(models[[i]]$split.at[i]), models[[i]]$lnLik, models[[i]]$num.par, models[[i]]$aic, models[[i]]$aicc)#
	}#
	#
	all.res <- as.data.frame(tmp)#
	all.res[1,2] <- NA # root node for base model#
	#
	w.aic <- calculateModelWeights(all.res$aic)#
	w.aicc <- calculateModelWeights(all.res$aicc)#
	#
	all.res <- cbind(all.res[,c(1:5)], w.aic=w.aic$w, aicc=all.res$aicc, w.aicc=w.aicc$w)#
	#
	if (plotFig)#
	{#
		dev.new()#
		plotModelFit(all.res)#
		if (!is.null(fig.title)) {title(main=fig.title, cex.main=0.75)}#
	}#
	return(all.res)#
}#
#
calculateModelWeights <- function (fit)#
{#
	best <- min(fit)#
	delta <- fit-best#
	sumDelta <- sum(exp(-0.5 * delta))#
	w <- (exp(-0.5 * delta)/sumDelta)#
	#
	results <- data.frame(fit=fit,delta=delta,w=w)#
	#
	return(results)#
}#
#
plotModelFit <- function (all.res)#
{#
	ylim <- c(min(all.res[,"aic"],all.res[,"aicc"]), max(all.res[,"aic"],all.res[,"aicc"]))#
	plot(all.res[,"N.Models"],all.res[,"aicc"], xlab="Number of Piecewise Models", ylab="Model Fit", ylim=ylim, type="l", col="blue")#
	points(all.res[,"N.Models"],all.res[,"aicc"], col="blue", pch=21, bg="white")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", type="l")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", pch=21, bg="white")#
	#
	legend("topleft", c("aicc","aic"), pch=21, pt.bg="white", lty=1, col=c("blue", "black"), inset = .05, cex=0.75, bty="n") # 'bottomright' also works#
}#
#
logspace_sum <- function(logx)#
{#
	r <- logx[1]#
	if (length(logx)>1)#
	{#
		for (i in 2:length(logx)) {r <- logspace_add(r, logx[i])}#
	}#
	return(r)	#
}#
#
# Calculate log(x+y) from log(x) and log(y)#
logspace_add <- function(logx, logy)#
{#
	if (logx == -Inf)#
	{#
		return(logy)#
	} else {#
		max(logx, logy) + log1p(exp (-abs (logx - logy)))#
	}#
}#
#
#
# Print out results from a given piecewise model. May be:#
#   1. optimal model under aicc: the default#
#   2. optimal model under aic: through setting "aic=T"#
#   3. aicc model using threshold improvement (like original MEDUSA): through setting "threshold" to some value#
#   4. aic model using threshold improvement (like original MEDUSA): through setting "aic=T" and "threshold" to some value#
#   5. user-selected model: through setting "model" to some integer value (from summary table)#
# In any case, also print out base model for comparison#
# Need to parse 'results' (list of lists). Contains elements:#
#  $models, which contains:#
#     $par: i x 2 matrix (for birth-death; i x 1 for pure-birth); the jth row contains #
#       the speciation and (optional) extinction rate for the jth rate class#
#     $lnLik.part: vector of length i; the jth element is the partial log#
#       likelihood value due to the jth rate class#
#     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
#     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
#  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
#  $z: a matrix listing branch times and richnesses; for summarizing results#
#  $anc: a list of all ancestors; for summarizing results#
#  $modelSummary: data.frame listing considered models, likelihoods, number of paramters, aicc, aicc, Akaike weights.#
#
#threshold=0; aic=F; plotTree=F; time=T; cex=0.5; plotSurface=T; est.extinction=T; fossil.minimum=F; n.points=100; node.labels=T;#
#r.interval=c(0.0000001,0.9999999); e.interval=r.interval; model=NULL;#
#
summarizeFossilMEDUSA <- function(results, model=NULL, cutoff="threshold", criterion="aicc", plotTree=TRUE, time=TRUE,#
	node.labels=TRUE, cex=0.5, plotSurface=FALSE, est.extinction=TRUE, fossil.minimum=FALSE, r.interval=c(1e-10,1.0),#
	e.interval=r.interval, n.points=100, ...)#
{#
# Desirables:#
#  1. table listing parameter values of selected model#
#  2. list parameters of base model#
#  3. tree printed with colour-coded edges, node labels to indicate split position(s)#
#  4. plot likelihood surface#
	#
# Extract constituent components from results#
	fit <- results$models#
	phy <- results$phy#
	z <- results$z#
	anc <- results$anc#
	modelSummary <- results$modelSummary#
	threshold <- results$threshold#
	#
# First, determine which model is desired#
	model.id <- 0#
	if (!is.null(model))#
	{#
		model.id <- model#
	} else {   # Find best model using threshold criterion#
		if (cutoff != "threshold") {threshold <- cutoff}#
#		else {cat("\nSelecting model based on corrected threshold (decrease in information theoretic score of ", -threshold, " units).\n", sep="")}#
		model.id <- 1#
		while (1)#
		{#
			if ((model.id + 1) > length(fit)) break;#
			if ((unlist(fit[[model.id]][criterion]) - unlist(fit[[model.id+1]][criterion])) > threshold) break;#
			model.id <- model.id + 1#
		}#
	}#
	#
	break.pts <- fit[[model.id]]$split.at#
	opt.model <- as.data.frame(cbind(Split.node=break.pts, fit[[model.id]]$par, LnLik.part=fit[[model.id]]$lnLik.part))#
	base.model <- as.data.frame(fit[[1]]$par)#
	#
	cat("\nEstimated parameter values for model #", model.id, ":\n\n", sep="")#
	print.data.frame(opt.model, digits=5)#
	opt.weight <- 0#
	optFit <- 0#
	base.weight <- 0#
	baseFit <- 0#
	if (criterion == "aicc")#
	{#
		opt.weight <- modelSummary$w.aicc[model.id]#
		optFit <- modelSummary$aicc[model.id]#
		base.weight <- modelSummary$w.aicc[1]#
		baseFit <- modelSummary$aicc[1]#
	} else { # aic used#
		opt.weight <- modelSummary$w.aic[model.id]#
		optFit <- modelSummary$aic[model.id]#
		base.weight <- modelSummary$w.aic[1]#
		baseFit <- modelSummary$aic[1]#
	}#
	cat("\nModel fit summary for model #", model.id, ":\n\n", sep="")#
	cat("\tLog-likelihood = ", as.numeric(results$models[[model.id]]["lnLik"]), "\n", sep="")#
	cat("\t", criterion, " = ", optFit, "\n", sep="")#
	cat("\t", criterion, " weight = ", opt.weight, "\n\n", sep="")#
	#
	if (model.id != 1)#
	{#
		cat("\nFor comparison, estimated values for the base model are:\n\n")#
		print.data.frame(base.model, digits=5, row.names=F)#
		cat("\nModel fit summary for base model:\n\n", sep="")#
		cat("\tLog-likelihood = ", as.numeric(results$models[[1]]["lnLik"]), "\n", sep="")#
		cat("\t", criterion, " = ", baseFit, "\n", sep="")#
		cat("\t", criterion, " weight = ", base.weight, "\n\n", sep="")#
	}#
	#
# Get desired tree-model conformation#
	if (length(break.pts) > 1)#
	{#
		for (i in 2:length(break.pts))#
		{#
			tmp <- medusa.split(break.pts[i], z, anc)#
			z <- tmp$z#
		}#
	}#
	#
	#
	#
	#
# Temporary workaround#
	epsilon.value <- NULL#
	#
	#
# Plot tree with purdy colours and labelled nodes (to better map between tree and table)#
	if (plotTree)#
	{#
		dev.new()#
		margin <- F#
		#
# This need to be changed to reflect new structure#
		mm <- match(phy$edge[,2], z[,"dec"])#
		if (time) {margin=T}#
#		plot(phy, edge.color=z[mm,10], no.margin=!margin, cex=cex, ...)#
		plot(phy, edge.color=z[mm,"partition"], no.margin=!margin, cex=cex, ...)#
		if (time)#
		{#
			axisPhylo(cex.axis=0.75)#
			mtext("Divergence Time (MYA)", at=(max(get("last_plot.phylo", envir = .PlotPhyloEnv)$xx)*0.5), side = 1, line = 2, cex=0.75)#
		}#
		if (node.labels)#
		{#
			for (i in  1:length(break.pts))#
			{#
				nodelabels(i, node= break.pts[i], frame = "c", font = 1, cex=0.5)#
			}#
		}#
	}#
	#
	if (plotSurface)#
	{#
		n.pieces <- length(opt.model[,1])#
		dev.new()#
		#
		if ((sqrt(n.pieces)) == round(sqrt(n.pieces)))  #make square plotting surface#
		{#
			op <- par(mfrow=c(sqrt(n.pieces),sqrt(n.pieces)))#
		} else {#
			layout(matrix(1:n.pieces))#
		}#
		#
#	min.r <- 0.000001#
#	max.r <- max(opt.model["r"]) * 2#
		#
		if (n.pieces > 1) {cat("Computing surfaces...\n")} else {cat("Computing surface...")}#
		for (k in 1: n.pieces)#
		{#
			partition <- k#
			#
			lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
			#
			lik.vals <- matrix(nrow=n.points, ncol=n.points)#
			r.vals <- seq(from=r.interval[1], to=r.interval[2], length.out=n.points)#
			eps.vals <- seq(from=e.interval[1], to=e.interval[2], length.out=n.points)#
			#
			for (i in 1:length(r.vals))#
			{#
				for (j in 1:(length(eps.vals))) {lik.vals[i,j] <- lik(pars=c(r.vals[i], eps.vals[j]))}#
			}#
			if (n.pieces > 1) {cat("Completed computing surface for piecewise model #", k, "\n", sep="")}#
			else {cat (" done.\n")}#
		#
# Perspective plot#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood", theta=-45, phi=45)#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood")#
#	points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
#	points(x=best.r, y=best.eps, pch=16, col="blue")#
#	points(modelSummary$Ln.Lik[model.id], x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
	#
	#
	#
	#
## *** Can check on distance between MLE and best point evaluated above; if large, advize evaluating further points#
# Perhaps determine the correct number of points this way automatically?#
	#
	#
	#
	#
# Contour plot#
			#
	# This shit is only good for determining the best number of points to evaluate#
			max.lik <- max(lik.vals,na.rm=T)#
			best.r <- numeric()#
			best.eps <- numeric()#
			#
# Need to figure out which parameter values lead to this likelihood...#
			i.best <- which(lik.vals==max.lik)#
			if (length(i.best) > 1) {i.best <- i.best[1]} # if more than one combination gives best value, just grab first#
			#
	# the following determines, from the r/eps sequences, where in the the likelihood matrix the MLE lies#
			if (i.best > n.points)#
			{#
				best.r <- r.vals[i.best%%n.points]#
				best.eps <- eps.vals[ceiling(i.best/n.points)]#
			} else {#
				best.r <- r.vals[i.best]#
				best.eps <- eps.vals[1]#
			}#
#			cat("Best likelihood found: ", max.lik, " for parameter combination #", i.best, "\n", sep="")#
			#
			#
			max.lik <- as.numeric(opt.model[partition,"LnLik.part"])  # MLE#
			lines <- c(max.lik-0.5, max.lik-1, max.lik-2, max.lik-3, max.lik-4, max.lik-5, max.lik-10, max.lik-50, max.lik-100)#
			contour(lik.vals, levels=lines, labels=c(0.5, 1, 2, 3, 4, 5, 10, 50, 100), axes=FALSE, xlab="r (b-d)", ylab="epsilon (d/b)")#
			tics<-floor(c(1, n.points/4, n.points/2, n.points*3/4, n.points))#
			axis(1, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(r.vals[tics], 3))#
			axis(2, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(eps.vals[tics], 3))#
			points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red") # inferred ML values#
#			points(x=best.r, y=best.eps, pch=16, col="blue") # best from surface samples#
#			legend("topright", c("ML","Best from sampled surface"), pch=16, col=c("red", "blue"), inset = .05, cex=0.75, bty="n")#
			legend("topright", "ML", pch=16, col="red", inset = .05, cex=0.75, bty="n")#
			if (n.pieces > 1) {title(main=paste("Piecewise model #", k, sep=""))}#
		}#
	}#
}#
#
#
#
#
#
#
#
#
# *** NOT used ***#
#
#
## Get b and d values from r (b-d) and epsilson (d/b)#
## Used in previous version of program; now in terms of r and epsilon#
## Possibly of use to users wishing to translate results#
get.b.d <- function(r, epsilon)#
{#
	b <- r/(1-epsilon)#
	d <- b-r   # Alternatively: d <- eps*r/(1-eps)#
	return(list(b=b, d=d))#
}#
#
## Print out tree with ape-style node-numbering#
## Possibly of interest for users to identify numbers of node(s) off interest#
 ## If this is the case, make sure to pass in pruned tree#
plotNN <- function (phy, time=TRUE, margin=TRUE, label.offset=0.5, cex=0.5, ...) #
{#
	phy$node.label <- (length(phy$tip.label) + 1):max(phy$edge)#
	plot.phylo(phy, show.node.label=TRUE, no.margin=!margin, label.offset=label.offset, cex=cex, ...)#
	if (time && !margin) cat("Cannot plot time axis without a margin.\n")#
	else if (time && margin) axisPhylo(cex.axis=0.75)#
}
……dijsij
library(ape)#
library(multicore)#
library(geiger)#
#
## fossilMEDUSA #
## Written by Joseph W. Brown, Richard G. FitzJohn, Luke J. Harmon, and Michael E. Alfaro#
## Problems/bugs/questions/request: josephwb@uidaho.edu#
#
## runFossilMEDUSA:#
##  Takes in phylogeny 'phy' and (optional) 'richness' (containing extant and potentially fossil#
##  counts); 'fossil.richness' optionally passed in separately. #
## 	The species richness information (if supplied) must minimally have columns 'taxon' and 'n.taxa'; #
## 	'taxon' must match with a tip.label in the phylogeny 'phy'. May also include 'exemplar' column,#
## 	used for incompletely-sampled clades which requiring pruning. If no richness information#
##  is provided then it is assumed tips represent single species with comprehensive#
##  sampling. Returns a list of models with 0, 1, 2, ..., 'model.limit' partitions.#
##  'model.limit' can be supplied by user, but is overruled if large enough (relative#
##  to tree size) that AIC correction factor becomes undefined (different for pure birth vs.#
##  birth-death models). 'phy' is assumed to be ultrametric; this is not checked. #
## #
## Returned list has elements:#
##  $models, which contains:#
##     $par: i x 2 matrix (for birth-death parameters); the jth row contains #
##       the speciation and extinction rate for the jth rate class#
##     $lnLik.part: vector of length i; the jth element is the partial log#
##       likelihood value due to the jth rate class#
##     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
##     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
##  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
##  $z: a matrix listing branch times and richnesses; for summarizing results#
##  $anc: a list of all ancestors; for summarizing results#
##  $modelSummary: data.frame listing considered models, likelihoods, AIC, etc.#
#
## Features (to be) added: specify epsilon (for every piecewise model), estimate r.#
## An argument 'epsilon.value' is passed; if NULL, normal MEDUSA is performed.#
#
## TO-DO:#
 # 0. fossil counts in pendant edges - DONE (but slow when fossil.minimum==T)#
 # 1. option for no extinction (i.e. pure birth) (lower priority)#
 # 2. set epsilon to some value (for all piecewise models), estimate r (num.par = 2*num.models - 1)#
 # 3. implement cutAtStem=FALSE (very low priority) # abandon?!?#
 # calculate fossil likelihoods using C++ - WORKING#
#
#
## Function to prune tree using 'richness' information, assumed to have minimally two columns, "taxon" and "n.taxa"#
##   Perhaps relax on these column names, may cause too many problems#
## May also include 'exemplar' column; in that case, rename relevant tip.label before pruning.#
## In addition, may have columns 'n.fossils' and 'f.time'; must match names exactly or ambiguous error generated.#
##   Taxa without fossil counts should have NA in n.fossil and f.time columns.#
## If 'fossil.richness' passed in separately, merge with 'richness'#
pruneTreeMergeData <- function(phy, richness, fossil.richness=NULL, fossil.minimum=FALSE, verbose=T)#
{#
# Sort for downstream functions#
	if (is.null(richness$n.fossils))#
	{#
		richness <- richness[order(richness $taxon),]#
	} else {#
		richness <- richness[order(richness $taxon, -richness$f.time),]#
	}#
	rownames(richness) <- NULL#
# Rename exemplar taxa with taxon name in richness file#
	if (!is.null(richness$exemplar))#
	{#
# Change relevant tip.labels in phy; individual 'exemplar' may be NA, use original tip.label.#
# Ordering in richness file should NOT be assumed to match order of tip.labels#
		i.na <- is.na(richness$exemplar)#
		phy$tip.label[match(richness$exemplar[!i.na], phy$tip.label)] <- as.character(richness$taxon[!i.na])#
	}#
	#
# Check names against 'richness' (already fixed above). May use 'exemplar', but *must* use 'taxon'#
# Update 'n.fossils' and 'f.time' accordingly#
# Again, assume ordering is random, but that taxa are consistent across richness files#
# Annoying number of possible combinations of file format. Don't be so nice! Force them into one or few.#
	if (!is.null(fossil.richness)) # Merge 'fossil.richness' with 'richness'#
	{#
		if (!is.null(fossil.richness$exemplar) && !is.null(richness$exemplar))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$exemplar)#
		} else if (!is.null(fossil.richness$exemplar) && !is.null(richness$taxon))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$taxon)#
# This would be odd, but allow for it; need to change tip labels to 'exemplar' from 'fossil.richness'#
	# VERY low priority#
		} else {#
			i.fossil <- match(fossil.richness$taxon, richness$taxon)#
		}#
		#
		if (length(i.fossil) != length(fossil.richness[,1])) {stop("Problem matching extant and fossil taxon information.")}#
		#
		for (i in 1:length(fossil.richness[,1]))#
		{#
			richness[i.fossil[i],"n.fossils"] <- fossil.richness[i,"n.fossils"]#
			richness[i.fossil[i],"f.time"] <- fossil.richness[i,"f.time"]#
		}#
	}#
# Just for consistency with downstream functions:#
	if (is.null(richness$n.fossils)) {richness <- cbind(richness, n.fossils=NA, f.time=NA)}#
	#
# Check if fossil.minimum==T and if any n.fossil==1; delete and warn#
	if (fossil.minimum == TRUE)#
	{#
		if (!is.na(any(richness$n.fossils == 1)))  # is it possible to be uglier?!? make pretty later.#
		{#
			if(any(richness$n.fossils == 1))#
			{#
				drop.fossil <-  (richness$n.fossils == 1)#
				drop.fossil.taxa <- as.character(richness$taxon[drop.fossil])#
				#
				richness$n.fossils[drop.fossil] <- NA#
				richness$f.time[drop.fossil] <- NA#
				#
				cat("Warning: dropped fossil observations since cannot use fossil counts == 1 as minimums:\n")#
				print(drop.fossil.taxa)#
				cat("\n")#
			}#
		}#
	}#
	#
	if (length(phy$tip.label) != length(richness[,1]))#
	{#
# Prune tree down to lineages with assigned richnesses#
		temp <- richness[, "n.taxa"]#
		names(temp) <- richness[, "taxon"]#
		pruned <- treedata(phy, temp, warnings=verbose)  # geiger function calling ape (namecheck)#
		prunedTree <- pruned$phy#
# Check the tree#
	#	plotNN(prunedTree)					# Node numbers (ape-style) plotted#
		phy <- prunedTree#
	}#
	return(list(phy=phy, richness=richness))#
}#
#
#
#
## Original default was to fit 20 models (or less if the tree was small).#
## Changing to a stop-criterion e.g. when k = n-1 (i.e. when denominator of aicc correction is undefined).#
## k <- (3*i-1) # when BOTH birth and death are estimated#
  ## This occurs when i = n/3#
  ## if est.extinction=FALSE, k <- (2*i-1); max i = n/2#
## n <- (2*num.taxa - 1) == (2*length(richness[,1]) - 1) # i.e. total number of nodes in tree (internal + pendant)#
  ## if present, consider each fossil count as one data point; i.e. n <- num.nodes + num.fossils#
## Eventually use aicc itself as a stopping criterion (not urgent, as it is very fast).#
getMaxModelLimit <- function(richness, model.limit, est.extinction, stop, verbose)#
{#
	samp.size <- sum(!is.na(richness[,"n.fossils"])) + (2*length(richness[,1]) - 1)#
	max.model.limit <- numeric()#
	#
	if (est.extinction == TRUE)#
	{#
		max.model.limit <- as.integer(samp.size/3) - ((!samp.size %% 3) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	} else {#
		max.model.limit <- as.integer(samp.size/2) - ((!samp.size %% 2) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	}#
	#
	if (stop == "model.limit")#
	{#
		if (verbose) {cat("\nLimiting consideration to ", model.limit, " piecewise diversification models\n\n", sep="")}#
	} else if (stop == "threshold") {#
		model.limit <- max.model.limit#
		if (verbose) {cat("\nConsidering a maximum of ", model.limit, " piecewise diversification models (or until threshold is not satisfied)\n\n", sep="")}#
	}#
	return(model.limit)#
}#
#
#
#
## Fitted curve from random b-d simulations#
## Value corresponds to 95th percentile of AICc(split) - AICc(no-split) for no-split simulations#
getThreshold <- function (x)#
{#
	a = -3.5941052380332650E+01#
	b =  6.7372587299747000E+00#
	c = -1.0061508340754866E-01#
	Offset =  2.7516678664333408E+01#
	y <- a * (x-b)^c + Offset#
	if (y < 0) y <- 0#
	return(y)#
}#
#
#
#
## The make.cache.medusa function is like the first half of the original splitEdgeMatrix().#
## It works through and reorders the edges, then works out start and end times of these#
## based on the phylogeny's branching times.#
###
## In addition, every node's ancestors are also calculated.  The element 'anc' is a list.#
## $anc[i] contains the indices within $edge, $t.start, etc., of all ancestors of node 'i'#
## (in ape node numbering format).#
## #
## If multiple fossil observances present for a lineage, tie all to same ancestor#
make.cache.medusa <- function(phy, richness, mc, num.cores)#
{#
	if (is.null(richness)) {stop("This should not be possible.")}#
	#
# Fix for condition where there are only two branches (i.e. no internal)#
	#
	n.tips <- length(phy$tip.label)#
	n.int <- nrow(phy$edge) - n.tips#
	bt <- branching.times(phy)#
	#
# Broken up to more easily parse fossil information; consider only internal edges first#
	if (n.int > 1)#
	{#
		i.int <- seq_len(n.int)#
		interior <- phy$edge[,2] %in% phy$edge[,1]#
		#
		edges.int <- phy$edge[interior,]#
		colnames(edges.int) <- c("anc", "dec")#
		#
		t.0 <- bt[match(edges.int[,1], (n.tips+1):max(edges.int))]#
		t.1 <- c(t.0[i.int] - phy$edge.length[interior])#
		#
		z.internal <- cbind(edges.int, t.0, t.1, t.len=t.0 - t.1,#
			n.0=rep(1, n.int), n.t=rep(NA, n.int))#
	}#
	#
# Now, pendant edges; #
# Assume that if multiple fossils per taxon, use same 'taxon' and [optionally] 'exemplar'#
	edges.pendant <- phy$edge[match(seq_len(n.tips), phy$edge[,2]),]#
	colnames(edges.pendant) <- c("anc", "dec")#
	#
	t.0 <- bt[match(edges.pendant[,1], (n.tips+1):max(edges.pendant))]#
	#
	z.pendant <- data.frame() # Put each (sub)edge on a separate row#
	#
	#
# *** Is there a way to do this without the for loop?#
#
	# if (length(phy$tip.label) == length(richness[,1])) # if no fossils, can disregard a lot of matching#
	# {#
		#
	# } else {#
		# for (i in 1:n.tips) # *** This is the slow bit; only used for fossils.#
		# {#
			# i.taxon <- which(richness$taxon == phy$tip.label[i])#
			# tmp  <- data.frame()#
			# anc=edges.pendant[i,"anc"]#
			# dec=edges.pendant[i,"dec"]#
			# cur.r0 <- 1#
			# cur.t0 <- t.0[i]#
			#
			# tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
			# z.pendant <- rbind(z.pendant, tmp)#
		# }#
	# }#
#
#
	for (i in 1:n.tips)#
	{#
		i.taxon <- which(richness$taxon == phy$tip.label[i]) # May have multiple entties due to mutliple fossil observances#
		tmp  <- data.frame()#
		anc=edges.pendant[i,"anc"]#
		dec=edges.pendant[i,"dec"]#
		cur.r0 <- 1#
		cur.r1 <- richness$n.fossils[i.taxon[1]]#
		cur.t0 <- t.0[i]#
		cur.t1 <- richness$f.time[i.taxon[1]]#
		#
		if (is.na(cur.r1)) # no fossils#
		{#
			tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0,#
				t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
		} else { # n fossils; split into n+1 rows#
			for (j in 1:length(i.taxon))#
			{#
				foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
					t.1=cur.t1, t.len=cur.t0-cur.t1, n.0=cur.r0, n.t=cur.r1)#
				tmp <- rbind (tmp, foo)#
				#
				cur.r0 <- cur.r1#
				cur.t0 <- cur.t1#
				if (j != length(i.taxon))#
				{#
					cur.r1 <- richness$n.fossils[i.taxon[j+1]]#
					cur.t1 <- richness$f.time[i.taxon[j+1]]#
				}#
			}#
			foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
				t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon[1]])#
			tmp <- rbind (tmp, foo)#
		}#
		z.pendant <- rbind(z.pendant, tmp)#
	}#
	#
	if (n.int > 1) {z <- rbind(z.internal, z.pendant)#
	} else {z <- z.pendant}#
	z <- cbind(z,partition=rep(1, length(z[,1]))) # Stores piecewise model structure#
	rownames(z) <- NULL#
	#
# Used for identifying ancestral nodes below i.e. tracking breakpoints#
	all.edges <- as.matrix(z[,c("anc","dec")])#
	#
	if (mc)#
	{#
		list(z=z, anc=mclapply(seq_len(max(all.edges)), ancestors.idx, all.edges), mc.cores=num.cores)#
	} else {#
		list(z=z, anc=lapply(seq_len(max(all.edges)), ancestors.idx, all.edges))#
	} # And, we're good to go...#
}#
#
#
#
## This generates the indices of all ancestors of a node, using ape's edge matrix.#
## Deals with row numbers of the edge matrix rather than node numbers of the tree#
ancestors <- function(node, all.edges)#
{#
	ans <- node#
	repeat#
	{#
		node <- all.edges[all.edges[,1] %in% node,2]#
		if (length(node) > 0) {ans <- c(ans, node)} else {break}#
	}#
	unlist(ans)#
}#
#
## The function 'ancestors' returns the indices of all ancestors within the edge matrix.#
ancestors.idx <- function(node.list, all.edges)#
{#
	which(all.edges[,1] == node.list | all.edges[,2] %in% ancestors(node.list, all.edges))#
}#
#
#
## Needed for determining whether nodes are virgin nodes#
getNumTips <- function(node, phy)#
{#
	n <- length(node.leaves(phy,node))#
	return(n)#
}#
#
#
#
## Only used for base model#
medusa.ml.initial <- function(z, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
#	rootnode <- min(z[is.na(z[,"n.t"]),1]) # doesn't work if only two branches (i.e. no NA)#
	#
	rootnode <- min(z[,"anc"])#
	obj <- medusa.ml.fit.partition(1, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	modelFit <- calculateModelFit(fit=obj, z, est.extinction, epsilon.value)#
	#
	if (est.extinction)#
	{#
		list(par=matrix(obj$par, nrow=1, dimnames=list(NULL,c("r", "epsilon"))), lnLik.part=obj$lnLik, #
		   lnLik=obj$lnLik, split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	} else {#
		list(par=matrix(obj$par, nrow=1,dimnames=list(NULL,"r")), lnLik.part=obj$lnLik, lnLik=obj$lnLik,#
		   split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	}#
}#
#
#
## Pre-fit values for pendant edges; DON'T recalculate later; should account for ~25% of all calculations#
medusa.ml.prefit <- function(node, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
# Partition '2' represents the pendant edge#
	fitted <- medusa.ml.fit.partition(2, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	return(fitted)#
}#
#
#
#
## 'fit' contains parameter value(s) from previous model, used to initialize subsequent model#
## Pass in pre-fitted values for pendant edges; DON'T recalculate #
medusa.ml.update <- function(node, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
	aff <- obj$affected#
	#
	op <- fit$par#
	sp <- op[aff[1],] # Use previously fit parameter values from clade that is currently being split#
	#
	fit1 <- medusa.ml.fit.partition(aff[1], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	fit2 <- 0#
	#
## Check if pendant; calculations already done#
	if (node < root.node)#
	{#
		fit2 <- tips[[node]]#
## Check if virgin node; save more time!#
	} else if (length(unique(z[(z[,"partition"] == aff[2] & z[,"dec"] < root.node),"dec"])) == num.tips[[node]])#
	{#
		fit2 <- virgin.nodes[[node - root.node]]#
## Novel arrangement; need to calculate#
	} else {#
		fit2 <- medusa.ml.fit.partition(aff[2], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	}#
	#
	op[aff[1],] <- fit1$par # Replace parameters with new values for diminished clade#
	fit$par <- rbind(op, fit2$par)#
	fit$lnLik.part[aff] <- c(fit1$lnLik, fit2$lnLik) # Replace parameters with new values for diminished clade#
	fit$split.at <- c(fit$split.at, node)#
	fit$lnLik <- sum(fit$lnLik.part)#
	#
	modelFit <- calculateModelFit(fit, z, est.extinction, epsilon.value)#
	#
	fit$aic <- modelFit[1]#
	fit$aicc <- modelFit[2]#
	fit$num.par <- modelFit[3]#
	#
	return(fit)#
}#
#
#
#
## Split the edge matrix 'z' by adding a partition rooted at node 'node'.#
##   Note: in original MEDUSA parlance, this is cutAtStem=T.#
## The list 'anc' is a list of ancestors (see make.cache.medusa, above).#
## Returns a list with elements:#
##   z: new medusa matrix, with the new partition added#
##   affected: indices of the partitions affected by the split (n == 2).#
# Add cutAtStem = F option. Allow both within a single analysis?!?#
medusa.split <- function(node, z, anc)#
{#
	part <- z[,"partition"]#
	base <- min(part[z[,1] == node | z[,2] == node])#
	tag <- max(part) + 1#
#
	i <- anc[[node]]#
	idx <- i[part[i] == base]#
	z[idx,"partition"] <- tag#
	#
	z[which(z["dec"] == node),"partition"] <- tag # Possible to have several edges to consider#
#
	list(z=z, affected=c(unique(part[idx]), tag))#
}#
#
#
#
## sp = initializing values for r & epsilon#
## Default values should never be used (except for first model), as the values from the previous model are passed in.#
medusa.ml.fit.partition <- function(partition, z, est.extinction, epsilon.value, sp=c(0.1, 0.05), fossil.minimum)#
{#
# Construct likelihood function:#
	lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
	#
	if (est.extinction) # Possibly give a range of initializing values to "navigate the banana"#
	{#
		fit <- optim(fn=lik, par=sp, method="N", control=list(fnscale=-1))#
		list(par=fit$par, lnLik=fit$value)#
	} else {#
		fit <- optimize(fn=lik, interval=c(0, 1))  # check on a valid range#
		list(par=fit$minimum, lnLik=fit$objective)#
	}#
}#
#
#
#
## make.lik.medusa.part: generate a likelihood function for a single partition.#
###
## In the pendant calculations, the variables 'A' and 'B' are the A and B terms#
## in Foote et al. Science: 283 1310-1314, p. 1313, defined as:#
## #
##   A: probability of extinction of one lineage over time 't'#
##   B: A * lambda / mu OR A / epsilon#
###
## Where there is a single lineage at time 0 (a==1), the calculation is#
##   log(1 - A) + log(1 - B) + (n-1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1-A) on a log scale) which cancels to give:#
##   log(1 - B) + (n-1)*log(B)#
## when pendant richness==1 the calculation is even simpler:#
##   log(1 - B)#
###
## When a > 1 (more than one starting species; will only happen coming off of a fossil observation),#
## the calculations follow Foote et al. 1999, put into the function 'foote.fossil.pendant'.#
## 'est.extinction' determines whether yule model is assumed#
## 'epsilon.value', if != NULL, fixes epsilon for all partitions, estimates r; not yet implemented#
## 'fossil.minimum', if == FALSE, treat fossils as exact counts#
## Only one 'partition' is passed in at a time from a proposed split.#
make.lik.medusa.part <- function(partition, est.extinction=TRUE, epsilon.value=NULL, fossil.minimum=T)#
{#
#
# Handle internal, fossil, and pendant edges separately#
	is.int <- is.na(partition[,"n.t"])#
	is.fossil <- (partition[,"n.0"] > 1) | (partition[,"t.1"] > 0 & !is.int)#
	is.pend <- !is.int == !is.fossil # pendant edges *without* fossils#
	#
	n.int <- sum(is.int)#
	n.fossil <- sum(is.fossil)#
	n.pend <- sum(is.pend)#
	#
	if (n.int + n.fossil + n.pend != length(partition[,1])) stop("You messed up, yo.")#
	#
## Internal and pendant calculations differ; split'em up#
	int  <- partition[is.int,,drop=FALSE]#
	foss <- partition[is.fossil,,drop=FALSE]#
	pend <- partition[is.pend,,drop=FALSE]#
	#
	sum.int.t.len <- sum(int[,"t.len"])  # Simply sum all internal edges#
	int.t.0 <- int[,"t.0"]#
	#
# 'n.0' = Foote's 'a', initial diversity; 'n.t' = Foote's 'n', final diversity#
	pend.n.0 <- pend[,"n.0"] # Foote's 'a': initial diversity#
	pend.n.t <- pend[,"n.t"] # Foote's 'n': final diversity#
	pend.t.len <- pend[,"t.len"]#
	#
# Don't need much of this shit anymore#
	foss.n.0 <- foss[,"n.0"]   # Not necessarily equal 1 anymore#
	foss.n.t <- foss[,"n.t"]#
	foss.t.len <- foss[,"t.0"] - foss[,"t.1"]#
	#
# User may pass in epsilon; don't change it, just estimate r#
	f <- function(pars)#
	{#
		if (est.extinction == TRUE)#
		{#
			r <- pars[1]#
			epsilon <- pars[2]#
	#		bd <- get.b.d(r, epsilon)   # Not necessary#
	#		b <- bd$b#
	#		d <- bd$d#
			#
# Previous version where b & d were estimated:#
	#		b <- pars[1]#
	#		d <- pars[2]#
	#		r <- abs(b - d)#
	#		epsilon <- d / b#
			#
			if (r < 0 | epsilon <= 0 | epsilon >= 1) {return(-Inf)}#
		} else {#
## Implement pure birth; not currently working (for some reason). Not immediately urgent, as won't work with fossils anyway#
			r <- pars[1]#
			d <- 0#
			b <- r#
			epsilon <- 0#
			#
			if (r < 0) {return(-Inf)}#
		}#
		#
		if (n.int == 0) {l.int <- 0} else {#
## Likelihood of internal edges from Rabosky et al. (2007) equation (2.3):#
			l.int <- n.int * log(r) - r * sum.int.t.len - sum(log(1 - (epsilon * exp(-r * int.t.0))))#
# Under Yule, should be: l.int <- n.int * log(r) - r * sum.int.t.len#
#
		}#
		#
		if (n.pend == 0) {l.pend <- 0} else {#
## Calculations are from the following:#
## Rabosky et al. 2007. Proc. Roy. Soc. 274: 2915-2923.#
## Foote et al. 1999. Science. 283: 1310-1314#
## Raup. 1985. Paleobiology 11: 42-52 [Foote et al. correct the equation [A18] where a > 1]#
## Bailey. 1964. The Elements Of Stochastic Processes, With Applications To The Natural Sciences#
## Kendall. 1948. Ann. Math. Stat. 19: 1–15.#
###
## A = probability of extinction of one lineage over time 't'#
## B = A * (lambda/mu)#
###
## When there is a single lineage at time 0 (a = 1), the calculation is#
##   log(1 - A) + log(1 - B) + (n - 1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1 - A) on a log scale) which cancels to give:#
##   log(1 - B) + (n - 1)*log(B)#
##      - for n.t == 1, reduces further to log(1-B)#
###
## A = mu*(exp((lambda - mu)*t) - 1)) / (lambda*exp((lambda - mu)*t) - mu)#
##  let r = (lambda - mu); ert = exp((lambda - mu)*t)#
## A = mu*(ert - 1)/(lambda*ert - mu)#
###
## B = A * (lambda/mu)#
##   = [mu*(ert - 1)/(lambda*ert - mu)] * (lambda/mu)#
##   = (lambda*(ert - 1))/(lambda*ert - mu)#
##   = (lambda*(ert - 1))/(lambda(ert - mu/lambda))#
##   = (ert - 1) / (ert - epsilon)#
#
## All pendant nodes begin with richness '1'; calculations simple.#
#			i.pend.n.t.1 <- which(pend.n.t == 1)   # calculations even simpler: log(1-B)#
#			i.pend.n.t.n1 <- which(pend.n.t != 1)#
			#
			ert <- exp(r * pend.t.len)#
			B <- (ert - 1) / (ert - epsilon) # Equivalently: B <- (bert - b) / (bert - d)#
			#
	# Under Yule should be: B <- (ert - 1) / ert#
			#
	# separate out calculations; likely not any faster (slower?)#
#			l.pend.1 <- sum(log(1 - B[i.pend.n.t.1]))#
#			l.pend.n1 <- sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
#			l.pend <- l.pend.1 + l.pend.n1#
			#
#			l.pend <- sum(log(1 - B[i.pend.n.t.1])) + #
#			   sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
			#
			l.pend <- sum(log(1 - B) + (pend.n.t - 1)*log(B)) # equivalent single formula version#
		}#
		#
# Fossils!#
		if (n.fossil == 0) {l.fossil <- 0} else {#
#
# What is desired: P(n,t,N,T) = P(n,t,1)*P(N,T-t,n)#
# - each term (internal node to fossil, and fossil to pendant node) is conditioned on survival (dividing by [1-(P(0,t,a)]^a)]#
#
			if (fossil.minimum) # loop counts from 1 -> n-1 fossils; *** NEED TO SPEED THIS SHIT UP! ***#
			{#
## First consider path from internal node to fossil, conditioning on survival (i.e. divide by (1-A)^a, although 'a' is always 1 here):#
##  sum(over x from 1 to n-1) [(1-B)*B^(x-1)]#
				#
	### *** BROKEN!!! *** ####
	#
# *** UPDATE TO NEW FORMAT ***#
				#
				ert <- exp(r * foss.t.len)#
				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
			# Under Yule should be: B <- (ert - 1) / ert#
				#
				sum.prob.int.fossil <- numeric(length(foss.n.t))#
				for (i in 1:n.fossil)#
				{#
					tmp <- 0#
					for (j in 1:foss.n.t[i])#
					{#
						tmp <- sum((B.1[i]^(j-1)), tmp)#
					}#
					sum.prob.int.fossil[i] <- (1 - B.1[i]) * tmp # (1-B) brought outside sum, as it is present in every term#
				}#
				#
# Now consider path from fossil to pendant node; looping bits in 'foote.fossil.pendant.minimum'#
				ert <- exp(r * foss.t.len)#
				A <- (ert - 1) / ((ert/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.2 <- A / epsilon                   # Equivalently: B.2 <- A * (b/d)#
				#
			# Using raw probabilities:#
				sum.prob.fossil.pend <- foote.fossil.pendant.minimum(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(log(1 - (sum.prob.int.fossil * sum.prob.fossil.pend)))#
				#
			# Using log-scale values:#
#				sum.prob.fossil.pend <- foote.fossil.pendant.combined(foss.n.t, foss.n.t, A, B.2, fossil.minimum)#
#				l.fossil <- sum(log(1 - (sum.prob.int.fossil * exp(sum.prob.fossil.pend))))#
				#
			} else { # No looping; pretty fast#
# Two scenarios:#
# 1. coming off internal node (i.e. n.0 = 1); same calculation as above#
	# log(1 - B) + (n - 1)*log(B)#
# 2. coming off fossil (i.e. n.0 > 1); need Foote equations#
				off.node <- which(foss[,"n.0"] == 1)#
				off.fossil <- which(foss[,"n.0"] != 1)#
				#
	# First, off node; n.0 = 1#
				ert.off.node <- exp(r * foss[off.node,"t.len"]) # internal node to fossil#
				B.off.node <- (ert.off.node - 1) / (ert.off.node - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
				l.off.node <- sum(log(1 - B.off.node) + (foss[off.node,"n.t"] - 1)*log(B.off.node))#
				#
#				ert <- exp(r * foss.t.len) #
#				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
		# Under Yule should be: B <- (ert - 1) / ert#
				#
				ert.off.fossil <- exp(r * foss[off.fossil,"t.len"])        # fossil to pendant node or next fossil#
				A <- (ert.off.fossil - 1) / ((ert.off.fossil/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.off.fossil <- A / epsilon                                         # Equivalently: B.2 <- A * (b/d)#
				l.off.fossil <- foote.fossil.pendant.exact(foss[off.fossil,"n.0"], foss[off.fossil,"n.t"], A, B.off.fossil)#
				#
#				l.fossil <- sum(log(1 - B.1) + (foss.n.t - 1)*log(B.1)) + #
#				   foote.fossil.pendant.exact(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(l.off.node, l.off.fossil)#
			}#
		}#
		l.int + l.pend + l.fossil#
	}#
#	l.int + l.pend + l.fossil#
}#
#
#
## Calculates the probability of having *exactly* 'a' fossils and ending with *exactly* 'n' extant species.#
## Use only when 'a', starting richness, > 1 (i.e. if coming off a fossil count).#
## For 'off-fossil' calculations, richness may increase or decrease.#
foote.fossil.pendant.exact <- function(a, n, A, B)#
{#
	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
	lB <- log(B)#
	l1mA <- log(1 - A)#
	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
	l1mB <- log(1 - B)#
	l1mA1mB <- l1mA + l1mB#
	#
#	min.a.n <- pmin(a, n) # *Insanely* slow!#
	min.a.n <- pmin.int(a, n)#
	#
	l.exact.fossil <- numeric(length(min.a.n))#
	#
	for (i in 1:length(a))#
	{#
		ji <- seq_len(min.a.n[i])#
		ai <- a[i]#
		ni <- n[i]#
		#
#		tmp <- lchoose(ai, ji) + lchoose(ni - 1, ji - 1) + (ai - ji)*lA[i] + ji*l1mA1mB[i] + (ni - ji)*lB[i]#
		#
# Non-logspace version much faster#
		foo <- choose(ai, ji) * choose(ni - 1, ji - 1) * A[i]^(ai - ji) * ((1-A[i])*(1-B[i]))^ji * B[i]^(ni - ji)#
		tmp <- sum(foo)#
		#
## Conditioning on survival factors out of the sum:#
		l.exact.fossil[i] <- sum(tmp)/(r1mA.exp.a[i])#
		#
#		l.exact.fossil[i] <- logspace_sum(tmp) - l1mA.exp.a[i] # logspace_sum: calculate log(x+y) from log(x) and log(y)#
	#	l.exact.fossil[i] <- logspace_sum(tmp) - l1mA[i]  # old conditioning; not appropriate for a > 1#
	}#
#
#	sum(l.exact.fossil)#
	return(sum(log(l.exact.fossil)))#
}#
#
#
## Calculates the probability of having *at least* 'a' fossils and ending with exactly 'n' extant species.#
## Richness may increase or decrease.#
## Should this be computed on a log-scale?#
# *** THIS IS BROKEN ***#
foote.fossil.pendant.minimum <- function(a, n, A, B)#
{#
#	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
#	lB <- log(B)#
#	l1mA <- log(1 - A)#
#	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
#	l1mB <- log(1 - B)#
#	l1mA1mB <- l1mA + l1mB#
	#
	sum.prob.fossil.pend <- numeric(length(a))#
	#
	for (i in 1:length(a)) # Loop over fossils#
	{#
		tmp <- numeric(a[i]-1)#
		for (k in 1:(a[i]-1)) # For fossil i loop over from 1 to n[i]-1#
		{#
			ai <- k#
			ni <- n[i]#
			min.a.n <- pmin.int(ai, ni)#
#			min.a.n <- pmin(ai, ni) # *Insanely* slow! pmin.int saves 70s on a 107s job! WTF?!?#
	   		j <- seq_len(min.a.n)#
			#
	# *** Should this be put on a log scale to preserve precision? ***#
	  # Tests with reasonable data yield the same answer either way#
			foo <- choose(ai, j) * choose(ni - 1, j - 1) * A[i]^(ai - j) * ((1-A[i])*(1-B[i]))^j * B[i]^(ni - j)#
			tmp[k] <- sum(foo)#
	# Alternate log form:#
	  # foo <- lchoose(ai, j) + lchoose(ni - 1, j - 1) + (ai - j)*lA[i] + j*l1mA1mB[i] + (ni - j)*lB[i]#
	    }#
	#  	tmp[i] <- sum(tmp)/(1-A[i])  # old conditioning; not appropriate for a > 1#
			#
# Conditioning on survival factors out of the sum:#
		sum.prob.fossil.pend[i] <- sum(tmp)/(r1mA.exp.a[i])#
	# Alternate log form:#
	  #	foo <- (logspace_sum(tmp))#
	  #	sum.prob.fossil.pend[i] <- foo - l1mA.exp.a[i]#
	}#
#
	return(sum.prob.fossil.pend)#
}#
#
#
## 'fit' contains '$par' and '$lnlik'#
calculateModelFit <- function(fit, z, est.extinction, epsilon.value)#
{#
## Sample size taken (for now) as the total num.nodes in the tree (internal + pendant) plus num.fossil observations#
  # num.nodes = (2*length(phy$tip.label) - 1) == (2*length(richness[,1]) - 1) == length(z[,1]) + 1#
#	n <- (length(z[,1]) + 1) + sum(!is.na(z[,"n.f"]))#
	#
# Changed structure of data; no longer have z[,"n.f"]#
# Instead, each row of z constitutes an edge#
# Since each edge defines either a node or a fossil (i.e. an 'observation'), need only add root node as final obervation#
	n <- (length(z[,1]) + 1)#
	#
## Number of parameters estimated depends on values of est.extinction and epsilon.value#
  # Includes both formal parameters AND number of breaks. Note: first model does not involve a break.#
## Models where all parameters are estimated:#
  # 2 parameters for base model (no breakpoint) + 3 parameters (r, eps, breakpoint) for each subsequent model#
## Models where only one parameter is estimated:#
  # 1 parameter for base model (no breakpoint) + 2 parameters (r, breakpoint) for each subsequent model#
	#
	if (length(fit$par) < 3) # i.e. base model#
	{#
		num.models <- 1#
	} else {#
		num.models <- length(fit$par[,1])#
	}#
	#
	if (est.extinction == FALSE || !is.null(epsilon.value)) # only one parameter estimated (plus breakpoint)#
	{#
		k <- 1 + (2 * (num.models - 1))#
	} else {#
		k <- 2 + (3 * (num.models - 1))#
	}#
	#
	lnLik <- fit$lnLik#
	#
	aic <- (-2 * lnLik) + (2*k)#
	aicc <- aic + 2*k*(k+1)/(n-k-1)#
	#
	modelFit <- c(aic, aicc, k)#
	return(modelFit)#
}#
#
#
## Prints out a table of likelihoods, parameters, aic scores, and aic weights (delta-aics are also available, if desired)#
calculateModelFitSummary <- function (models, phy, plotFig, fig.title=NULL, ...)#
{#
	tmp <- matrix(nrow=(length(models)), ncol=6)#
	colnames(tmp) <- c("N.Models", "Break.Node", "Ln.Lik", "N.Param", "aic", "aicc")#
	#
	w.aic <- numeric(length(models))#
	w.aicc <- numeric(length(models))#
	#
	for (i in 1:length(tmp[,1]))#
	{#
		tmp[i,] <- c(i, as.integer(models[[i]]$split.at[i]), models[[i]]$lnLik, models[[i]]$num.par, models[[i]]$aic, models[[i]]$aicc)#
	}#
	#
	all.res <- as.data.frame(tmp)#
	all.res[1,2] <- NA # root node for base model#
	#
	w.aic <- calculateModelWeights(all.res$aic)#
	w.aicc <- calculateModelWeights(all.res$aicc)#
	#
	all.res <- cbind(all.res[,c(1:5)], w.aic=w.aic$w, aicc=all.res$aicc, w.aicc=w.aicc$w)#
	#
	if (plotFig)#
	{#
		dev.new()#
		plotModelFit(all.res)#
		if (!is.null(fig.title)) {title(main=fig.title, cex.main=0.75)}#
	}#
	return(all.res)#
}#
#
calculateModelWeights <- function (fit)#
{#
	best <- min(fit)#
	delta <- fit-best#
	sumDelta <- sum(exp(-0.5 * delta))#
	w <- (exp(-0.5 * delta)/sumDelta)#
	#
	results <- data.frame(fit=fit,delta=delta,w=w)#
	#
	return(results)#
}#
#
plotModelFit <- function (all.res)#
{#
	ylim <- c(min(all.res[,"aic"],all.res[,"aicc"]), max(all.res[,"aic"],all.res[,"aicc"]))#
	plot(all.res[,"N.Models"],all.res[,"aicc"], xlab="Number of Piecewise Models", ylab="Model Fit", ylim=ylim, type="l", col="blue")#
	points(all.res[,"N.Models"],all.res[,"aicc"], col="blue", pch=21, bg="white")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", type="l")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", pch=21, bg="white")#
	#
	legend("topleft", c("aicc","aic"), pch=21, pt.bg="white", lty=1, col=c("blue", "black"), inset = .05, cex=0.75, bty="n") # 'bottomright' also works#
}#
#
logspace_sum <- function(logx)#
{#
	r <- logx[1]#
	if (length(logx)>1)#
	{#
		for (i in 2:length(logx)) {r <- logspace_add(r, logx[i])}#
	}#
	return(r)	#
}#
#
# Calculate log(x+y) from log(x) and log(y)#
logspace_add <- function(logx, logy)#
{#
	if (logx == -Inf)#
	{#
		return(logy)#
	} else {#
		max(logx, logy) + log1p(exp (-abs (logx - logy)))#
	}#
}#
#
#
# Print out results from a given piecewise model. May be:#
#   1. optimal model under aicc: the default#
#   2. optimal model under aic: through setting "aic=T"#
#   3. aicc model using threshold improvement (like original MEDUSA): through setting "threshold" to some value#
#   4. aic model using threshold improvement (like original MEDUSA): through setting "aic=T" and "threshold" to some value#
#   5. user-selected model: through setting "model" to some integer value (from summary table)#
# In any case, also print out base model for comparison#
# Need to parse 'results' (list of lists). Contains elements:#
#  $models, which contains:#
#     $par: i x 2 matrix (for birth-death; i x 1 for pure-birth); the jth row contains #
#       the speciation and (optional) extinction rate for the jth rate class#
#     $lnLik.part: vector of length i; the jth element is the partial log#
#       likelihood value due to the jth rate class#
#     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
#     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
#  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
#  $z: a matrix listing branch times and richnesses; for summarizing results#
#  $anc: a list of all ancestors; for summarizing results#
#  $modelSummary: data.frame listing considered models, likelihoods, number of paramters, aicc, aicc, Akaike weights.#
#
#threshold=0; aic=F; plotTree=F; time=T; cex=0.5; plotSurface=T; est.extinction=T; fossil.minimum=F; n.points=100; node.labels=T;#
#r.interval=c(0.0000001,0.9999999); e.interval=r.interval; model=NULL;#
#
summarizeFossilMEDUSA <- function(results, model=NULL, cutoff="threshold", criterion="aicc", plotTree=TRUE, time=TRUE,#
	node.labels=TRUE, cex=0.5, plotSurface=FALSE, est.extinction=TRUE, fossil.minimum=FALSE, r.interval=c(1e-10,1.0),#
	e.interval=r.interval, n.points=100, ...)#
{#
# Desirables:#
#  1. table listing parameter values of selected model#
#  2. list parameters of base model#
#  3. tree printed with colour-coded edges, node labels to indicate split position(s)#
#  4. plot likelihood surface#
	#
# Extract constituent components from results#
	fit <- results$models#
	phy <- results$phy#
	z <- results$z#
	anc <- results$anc#
	modelSummary <- results$modelSummary#
	threshold <- results$threshold#
	#
# First, determine which model is desired#
	model.id <- 0#
	if (!is.null(model))#
	{#
		model.id <- model#
	} else {   # Find best model using threshold criterion#
		if (cutoff != "threshold") {threshold <- cutoff}#
#		else {cat("\nSelecting model based on corrected threshold (decrease in information theoretic score of ", -threshold, " units).\n", sep="")}#
		model.id <- 1#
		while (1)#
		{#
			if ((model.id + 1) > length(fit)) break;#
			if ((unlist(fit[[model.id]][criterion]) - unlist(fit[[model.id+1]][criterion])) > threshold) break;#
			model.id <- model.id + 1#
		}#
	}#
	#
	break.pts <- fit[[model.id]]$split.at#
	opt.model <- as.data.frame(cbind(Split.node=break.pts, fit[[model.id]]$par, LnLik.part=fit[[model.id]]$lnLik.part))#
	base.model <- as.data.frame(fit[[1]]$par)#
	#
	cat("\nEstimated parameter values for model #", model.id, ":\n\n", sep="")#
	print.data.frame(opt.model, digits=5)#
	opt.weight <- 0#
	optFit <- 0#
	base.weight <- 0#
	baseFit <- 0#
	if (criterion == "aicc")#
	{#
		opt.weight <- modelSummary$w.aicc[model.id]#
		optFit <- modelSummary$aicc[model.id]#
		base.weight <- modelSummary$w.aicc[1]#
		baseFit <- modelSummary$aicc[1]#
	} else { # aic used#
		opt.weight <- modelSummary$w.aic[model.id]#
		optFit <- modelSummary$aic[model.id]#
		base.weight <- modelSummary$w.aic[1]#
		baseFit <- modelSummary$aic[1]#
	}#
	cat("\nModel fit summary for model #", model.id, ":\n\n", sep="")#
	cat("\tLog-likelihood = ", as.numeric(results$models[[model.id]]["lnLik"]), "\n", sep="")#
	cat("\t", criterion, " = ", optFit, "\n", sep="")#
	cat("\t", criterion, " weight = ", opt.weight, "\n\n", sep="")#
	#
	if (model.id != 1)#
	{#
		cat("\nFor comparison, estimated values for the base model are:\n\n")#
		print.data.frame(base.model, digits=5, row.names=F)#
		cat("\nModel fit summary for base model:\n\n", sep="")#
		cat("\tLog-likelihood = ", as.numeric(results$models[[1]]["lnLik"]), "\n", sep="")#
		cat("\t", criterion, " = ", baseFit, "\n", sep="")#
		cat("\t", criterion, " weight = ", base.weight, "\n\n", sep="")#
	}#
	#
# Get desired tree-model conformation#
	if (length(break.pts) > 1)#
	{#
		for (i in 2:length(break.pts))#
		{#
			tmp <- medusa.split(break.pts[i], z, anc)#
			z <- tmp$z#
		}#
	}#
	#
	#
	#
	#
# Temporary workaround#
	epsilon.value <- NULL#
	#
	#
# Plot tree with purdy colours and labelled nodes (to better map between tree and table)#
	if (plotTree)#
	{#
		dev.new()#
		margin <- F#
		#
# This need to be changed to reflect new structure#
		mm <- match(phy$edge[,2], z[,"dec"])#
		if (time) {margin=T}#
#		plot(phy, edge.color=z[mm,10], no.margin=!margin, cex=cex, ...)#
		plot(phy, edge.color=z[mm,"partition"], no.margin=!margin, cex=cex, ...)#
		if (time)#
		{#
			axisPhylo(cex.axis=0.75)#
			mtext("Divergence Time (MYA)", at=(max(get("last_plot.phylo", envir = .PlotPhyloEnv)$xx)*0.5), side = 1, line = 2, cex=0.75)#
		}#
		if (node.labels)#
		{#
			for (i in  1:length(break.pts))#
			{#
				nodelabels(i, node= break.pts[i], frame = "c", font = 1, cex=0.5)#
			}#
		}#
	}#
	#
	if (plotSurface)#
	{#
		n.pieces <- length(opt.model[,1])#
		dev.new()#
		#
		if ((sqrt(n.pieces)) == round(sqrt(n.pieces)))  #make square plotting surface#
		{#
			op <- par(mfrow=c(sqrt(n.pieces),sqrt(n.pieces)))#
		} else {#
			layout(matrix(1:n.pieces))#
		}#
		#
#	min.r <- 0.000001#
#	max.r <- max(opt.model["r"]) * 2#
		#
		if (n.pieces > 1) {cat("Computing surfaces...\n")} else {cat("Computing surface...")}#
		for (k in 1: n.pieces)#
		{#
			partition <- k#
			#
			lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
			#
			lik.vals <- matrix(nrow=n.points, ncol=n.points)#
			r.vals <- seq(from=r.interval[1], to=r.interval[2], length.out=n.points)#
			eps.vals <- seq(from=e.interval[1], to=e.interval[2], length.out=n.points)#
			#
			for (i in 1:length(r.vals))#
			{#
				for (j in 1:(length(eps.vals))) {lik.vals[i,j] <- lik(pars=c(r.vals[i], eps.vals[j]))}#
			}#
			if (n.pieces > 1) {cat("Completed computing surface for piecewise model #", k, "\n", sep="")}#
			else {cat (" done.\n")}#
		#
# Perspective plot#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood", theta=-45, phi=45)#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood")#
#	points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
#	points(x=best.r, y=best.eps, pch=16, col="blue")#
#	points(modelSummary$Ln.Lik[model.id], x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
	#
	#
	#
	#
## *** Can check on distance between MLE and best point evaluated above; if large, advize evaluating further points#
# Perhaps determine the correct number of points this way automatically?#
	#
	#
	#
	#
# Contour plot#
			#
	# This shit is only good for determining the best number of points to evaluate#
			max.lik <- max(lik.vals,na.rm=T)#
			best.r <- numeric()#
			best.eps <- numeric()#
			#
# Need to figure out which parameter values lead to this likelihood...#
			i.best <- which(lik.vals==max.lik)#
			if (length(i.best) > 1) {i.best <- i.best[1]} # if more than one combination gives best value, just grab first#
			#
	# the following determines, from the r/eps sequences, where in the the likelihood matrix the MLE lies#
			if (i.best > n.points)#
			{#
				best.r <- r.vals[i.best%%n.points]#
				best.eps <- eps.vals[ceiling(i.best/n.points)]#
			} else {#
				best.r <- r.vals[i.best]#
				best.eps <- eps.vals[1]#
			}#
#			cat("Best likelihood found: ", max.lik, " for parameter combination #", i.best, "\n", sep="")#
			#
			#
			max.lik <- as.numeric(opt.model[partition,"LnLik.part"])  # MLE#
			lines <- c(max.lik-0.5, max.lik-1, max.lik-2, max.lik-3, max.lik-4, max.lik-5, max.lik-10, max.lik-50, max.lik-100)#
			contour(lik.vals, levels=lines, labels=c(0.5, 1, 2, 3, 4, 5, 10, 50, 100), axes=FALSE, xlab="r (b-d)", ylab="epsilon (d/b)")#
			tics<-floor(c(1, n.points/4, n.points/2, n.points*3/4, n.points))#
			axis(1, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(r.vals[tics], 3))#
			axis(2, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(eps.vals[tics], 3))#
			points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red") # inferred ML values#
#			points(x=best.r, y=best.eps, pch=16, col="blue") # best from surface samples#
#			legend("topright", c("ML","Best from sampled surface"), pch=16, col=c("red", "blue"), inset = .05, cex=0.75, bty="n")#
			legend("topright", "ML", pch=16, col="red", inset = .05, cex=0.75, bty="n")#
			if (n.pieces > 1) {title(main=paste("Piecewise model #", k, sep=""))}#
		}#
	}#
}#
#
#
#
#
#
#
#
#
# *** NOT used ***#
#
#
## Get b and d values from r (b-d) and epsilson (d/b)#
## Used in previous version of program; now in terms of r and epsilon#
## Possibly of use to users wishing to translate results#
get.b.d <- function(r, epsilon)#
{#
	b <- r/(1-epsilon)#
	d <- b-r   # Alternatively: d <- eps*r/(1-eps)#
	return(list(b=b, d=d))#
}#
#
## Print out tree with ape-style node-numbering#
## Possibly of interest for users to identify numbers of node(s) off interest#
 ## If this is the case, make sure to pass in pruned tree#
plotNN <- function (phy, time=TRUE, margin=TRUE, label.offset=0.5, cex=0.5, ...) #
{#
	phy$node.label <- (length(phy$tip.label) + 1):max(phy$edge)#
	plot.phylo(phy, show.node.label=TRUE, no.margin=!margin, label.offset=label.offset, cex=cex, ...)#
	if (time && !margin) cat("Cannot plot time axis without a margin.\n")#
	else if (time && margin) axisPhylo(cex.axis=0.75)#
}
summarizeFossilMEDUSA(results=carny.res)
criterion
library(ape)#
library(multicore)#
library(geiger)#
#
## fossilMEDUSA #
## Written by Joseph W. Brown, Richard G. FitzJohn, Luke J. Harmon, and Michael E. Alfaro#
## Problems/bugs/questions/request: josephwb@uidaho.edu#
#
## runFossilMEDUSA:#
##  Takes in phylogeny 'phy' and (optional) 'richness' (containing extant and potentially fossil#
##  counts); 'fossil.richness' optionally passed in separately. #
## 	The species richness information (if supplied) must minimally have columns 'taxon' and 'n.taxa'; #
## 	'taxon' must match with a tip.label in the phylogeny 'phy'. May also include 'exemplar' column,#
## 	used for incompletely-sampled clades which requiring pruning. If no richness information#
##  is provided then it is assumed tips represent single species with comprehensive#
##  sampling. Returns a list of models with 0, 1, 2, ..., 'model.limit' partitions.#
##  'model.limit' can be supplied by user, but is overruled if large enough (relative#
##  to tree size) that AIC correction factor becomes undefined (different for pure birth vs.#
##  birth-death models). 'phy' is assumed to be ultrametric; this is not checked. #
## #
## Returned list has elements:#
##  $models, which contains:#
##     $par: i x 2 matrix (for birth-death parameters); the jth row contains #
##       the speciation and extinction rate for the jth rate class#
##     $lnLik.part: vector of length i; the jth element is the partial log#
##       likelihood value due to the jth rate class#
##     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
##     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
##  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
##  $z: a matrix listing branch times and richnesses; for summarizing results#
##  $anc: a list of all ancestors; for summarizing results#
##  $modelSummary: data.frame listing considered models, likelihoods, AIC, etc.#
#
## Features (to be) added: specify epsilon (for every piecewise model), estimate r.#
## An argument 'epsilon.value' is passed; if NULL, normal MEDUSA is performed.#
#
## TO-DO:#
 # 0. fossil counts in pendant edges - DONE (but slow when fossil.minimum==T)#
 # 1. option for no extinction (i.e. pure birth) (lower priority)#
 # 2. set epsilon to some value (for all piecewise models), estimate r (num.par = 2*num.models - 1)#
 # 3. implement cutAtStem=FALSE (very low priority) # abandon?!?#
 # calculate fossil likelihoods using C++ - WORKING#
#
#
## Function to prune tree using 'richness' information, assumed to have minimally two columns, "taxon" and "n.taxa"#
##   Perhaps relax on these column names, may cause too many problems#
## May also include 'exemplar' column; in that case, rename relevant tip.label before pruning.#
## In addition, may have columns 'n.fossils' and 'f.time'; must match names exactly or ambiguous error generated.#
##   Taxa without fossil counts should have NA in n.fossil and f.time columns.#
## If 'fossil.richness' passed in separately, merge with 'richness'#
pruneTreeMergeData <- function(phy, richness, fossil.richness=NULL, fossil.minimum=FALSE, verbose=T)#
{#
# Sort for downstream functions#
	if (is.null(richness$n.fossils))#
	{#
		richness <- richness[order(richness $taxon),]#
	} else {#
		richness <- richness[order(richness $taxon, -richness$f.time),]#
	}#
	rownames(richness) <- NULL#
# Rename exemplar taxa with taxon name in richness file#
	if (!is.null(richness$exemplar))#
	{#
# Change relevant tip.labels in phy; individual 'exemplar' may be NA, use original tip.label.#
# Ordering in richness file should NOT be assumed to match order of tip.labels#
		i.na <- is.na(richness$exemplar)#
		phy$tip.label[match(richness$exemplar[!i.na], phy$tip.label)] <- as.character(richness$taxon[!i.na])#
	}#
	#
# Check names against 'richness' (already fixed above). May use 'exemplar', but *must* use 'taxon'#
# Update 'n.fossils' and 'f.time' accordingly#
# Again, assume ordering is random, but that taxa are consistent across richness files#
# Annoying number of possible combinations of file format. Don't be so nice! Force them into one or few.#
	if (!is.null(fossil.richness)) # Merge 'fossil.richness' with 'richness'#
	{#
		if (!is.null(fossil.richness$exemplar) && !is.null(richness$exemplar))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$exemplar)#
		} else if (!is.null(fossil.richness$exemplar) && !is.null(richness$taxon))#
		{#
			i.fossil <- match(fossil.richness$exemplar, richness$taxon)#
# This would be odd, but allow for it; need to change tip labels to 'exemplar' from 'fossil.richness'#
	# VERY low priority#
		} else {#
			i.fossil <- match(fossil.richness$taxon, richness$taxon)#
		}#
		#
		if (length(i.fossil) != length(fossil.richness[,1])) {stop("Problem matching extant and fossil taxon information.")}#
		#
		for (i in 1:length(fossil.richness[,1]))#
		{#
			richness[i.fossil[i],"n.fossils"] <- fossil.richness[i,"n.fossils"]#
			richness[i.fossil[i],"f.time"] <- fossil.richness[i,"f.time"]#
		}#
	}#
# Just for consistency with downstream functions:#
	if (is.null(richness$n.fossils)) {richness <- cbind(richness, n.fossils=NA, f.time=NA)}#
	#
# Check if fossil.minimum==T and if any n.fossil==1; delete and warn#
	if (fossil.minimum == TRUE)#
	{#
		if (!is.na(any(richness$n.fossils == 1)))  # is it possible to be uglier?!? make pretty later.#
		{#
			if(any(richness$n.fossils == 1))#
			{#
				drop.fossil <-  (richness$n.fossils == 1)#
				drop.fossil.taxa <- as.character(richness$taxon[drop.fossil])#
				#
				richness$n.fossils[drop.fossil] <- NA#
				richness$f.time[drop.fossil] <- NA#
				#
				cat("Warning: dropped fossil observations since cannot use fossil counts == 1 as minimums:\n")#
				print(drop.fossil.taxa)#
				cat("\n")#
			}#
		}#
	}#
	#
	if (length(phy$tip.label) != length(richness[,1]))#
	{#
# Prune tree down to lineages with assigned richnesses#
		temp <- richness[, "n.taxa"]#
		names(temp) <- richness[, "taxon"]#
		pruned <- treedata(phy, temp, warnings=verbose)  # geiger function calling ape (namecheck)#
		prunedTree <- pruned$phy#
# Check the tree#
	#	plotNN(prunedTree)					# Node numbers (ape-style) plotted#
		phy <- prunedTree#
	}#
	return(list(phy=phy, richness=richness))#
}#
#
#
#
## Original default was to fit 20 models (or less if the tree was small).#
## Changing to a stop-criterion e.g. when k = n-1 (i.e. when denominator of aicc correction is undefined).#
## k <- (3*i-1) # when BOTH birth and death are estimated#
  ## This occurs when i = n/3#
  ## if est.extinction=FALSE, k <- (2*i-1); max i = n/2#
## n <- (2*num.taxa - 1) == (2*length(richness[,1]) - 1) # i.e. total number of nodes in tree (internal + pendant)#
  ## if present, consider each fossil count as one data point; i.e. n <- num.nodes + num.fossils#
## Eventually use aicc itself as a stopping criterion (not urgent, as it is very fast).#
getMaxModelLimit <- function(richness, model.limit, est.extinction, stop, verbose)#
{#
	samp.size <- sum(!is.na(richness[,"n.fossils"])) + (2*length(richness[,1]) - 1)#
	max.model.limit <- numeric()#
	#
	if (est.extinction == TRUE)#
	{#
		max.model.limit <- as.integer(samp.size/3) - ((!samp.size %% 3) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	} else {#
		max.model.limit <- as.integer(samp.size/2) - ((!samp.size %% 2) * 1)#
		if (model.limit > max.model.limit) {model.limit <- max.model.limit}#
	}#
	#
	if (stop == "model.limit")#
	{#
		if (verbose) {cat("\nLimiting consideration to ", model.limit, " piecewise diversification models\n\n", sep="")}#
	} else if (stop == "threshold") {#
		model.limit <- max.model.limit#
		if (verbose) {cat("\nConsidering a maximum of ", model.limit, " piecewise diversification models (or until threshold is not satisfied)\n\n", sep="")}#
	}#
	return(model.limit)#
}#
#
#
#
## Fitted curve from random b-d simulations#
## Value corresponds to 95th percentile of AICc(split) - AICc(no-split) for no-split simulations#
getThreshold <- function (x)#
{#
	a = -3.5941052380332650E+01#
	b =  6.7372587299747000E+00#
	c = -1.0061508340754866E-01#
	Offset =  2.7516678664333408E+01#
	y <- a * (x-b)^c + Offset#
	if (y < 0) y <- 0#
	return(y)#
}#
#
#
#
## The make.cache.medusa function is like the first half of the original splitEdgeMatrix().#
## It works through and reorders the edges, then works out start and end times of these#
## based on the phylogeny's branching times.#
###
## In addition, every node's ancestors are also calculated.  The element 'anc' is a list.#
## $anc[i] contains the indices within $edge, $t.start, etc., of all ancestors of node 'i'#
## (in ape node numbering format).#
## #
## If multiple fossil observances present for a lineage, tie all to same ancestor#
make.cache.medusa <- function(phy, richness, mc, num.cores)#
{#
	if (is.null(richness)) {stop("This should not be possible.")}#
	#
# Fix for condition where there are only two branches (i.e. no internal)#
	#
	n.tips <- length(phy$tip.label)#
	n.int <- nrow(phy$edge) - n.tips#
	bt <- branching.times(phy)#
	#
# Broken up to more easily parse fossil information; consider only internal edges first#
	if (n.int > 1)#
	{#
		i.int <- seq_len(n.int)#
		interior <- phy$edge[,2] %in% phy$edge[,1]#
		#
		edges.int <- phy$edge[interior,]#
		colnames(edges.int) <- c("anc", "dec")#
		#
		t.0 <- bt[match(edges.int[,1], (n.tips+1):max(edges.int))]#
		t.1 <- c(t.0[i.int] - phy$edge.length[interior])#
		#
		z.internal <- cbind(edges.int, t.0, t.1, t.len=t.0 - t.1,#
			n.0=rep(1, n.int), n.t=rep(NA, n.int))#
	}#
	#
# Now, pendant edges; #
# Assume that if multiple fossils per taxon, use same 'taxon' and [optionally] 'exemplar'#
	edges.pendant <- phy$edge[match(seq_len(n.tips), phy$edge[,2]),]#
	colnames(edges.pendant) <- c("anc", "dec")#
	#
	t.0 <- bt[match(edges.pendant[,1], (n.tips+1):max(edges.pendant))]#
	#
	z.pendant <- data.frame() # Put each (sub)edge on a separate row#
	#
	#
# *** Is there a way to do this without the for loop?#
#
	# if (length(phy$tip.label) == length(richness[,1])) # if no fossils, can disregard a lot of matching#
	# {#
		#
	# } else {#
		# for (i in 1:n.tips) # *** This is the slow bit; only used for fossils.#
		# {#
			# i.taxon <- which(richness$taxon == phy$tip.label[i])#
			# tmp  <- data.frame()#
			# anc=edges.pendant[i,"anc"]#
			# dec=edges.pendant[i,"dec"]#
			# cur.r0 <- 1#
			# cur.t0 <- t.0[i]#
			#
			# tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
			# z.pendant <- rbind(z.pendant, tmp)#
		# }#
	# }#
#
#
	for (i in 1:n.tips)#
	{#
		i.taxon <- which(richness$taxon == phy$tip.label[i]) # May have multiple entties due to mutliple fossil observances#
		tmp  <- data.frame()#
		anc=edges.pendant[i,"anc"]#
		dec=edges.pendant[i,"dec"]#
		cur.r0 <- 1#
		cur.r1 <- richness$n.fossils[i.taxon[1]]#
		cur.t0 <- t.0[i]#
		cur.t1 <- richness$f.time[i.taxon[1]]#
		#
		if (is.na(cur.r1)) # no fossils#
		{#
			tmp <- cbind(anc=anc, dec=dec, t.0=cur.t0, t.1=0,#
				t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon])#
		} else { # n fossils; split into n+1 rows#
			for (j in 1:length(i.taxon))#
			{#
				foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
					t.1=cur.t1, t.len=cur.t0-cur.t1, n.0=cur.r0, n.t=cur.r1)#
				tmp <- rbind (tmp, foo)#
				#
				cur.r0 <- cur.r1#
				cur.t0 <- cur.t1#
				if (j != length(i.taxon))#
				{#
					cur.r1 <- richness$n.fossils[i.taxon[j+1]]#
					cur.t1 <- richness$f.time[i.taxon[j+1]]#
				}#
			}#
			foo <- cbind(anc=anc, dec=dec, t.0=cur.t0,#
				t.1=0, t.len=cur.t0, n.0=cur.r0, n.t=richness$n.taxa[i.taxon[1]])#
			tmp <- rbind (tmp, foo)#
		}#
		z.pendant <- rbind(z.pendant, tmp)#
	}#
	#
	if (n.int > 1) {z <- rbind(z.internal, z.pendant)#
	} else {z <- z.pendant}#
	z <- cbind(z,partition=rep(1, length(z[,1]))) # Stores piecewise model structure#
	rownames(z) <- NULL#
	#
# Used for identifying ancestral nodes below i.e. tracking breakpoints#
	all.edges <- as.matrix(z[,c("anc","dec")])#
	#
	if (mc)#
	{#
		list(z=z, anc=mclapply(seq_len(max(all.edges)), ancestors.idx, all.edges), mc.cores=num.cores)#
	} else {#
		list(z=z, anc=lapply(seq_len(max(all.edges)), ancestors.idx, all.edges))#
	} # And, we're good to go...#
}#
#
#
#
## This generates the indices of all ancestors of a node, using ape's edge matrix.#
## Deals with row numbers of the edge matrix rather than node numbers of the tree#
ancestors <- function(node, all.edges)#
{#
	ans <- node#
	repeat#
	{#
		node <- all.edges[all.edges[,1] %in% node,2]#
		if (length(node) > 0) {ans <- c(ans, node)} else {break}#
	}#
	unlist(ans)#
}#
#
## The function 'ancestors' returns the indices of all ancestors within the edge matrix.#
ancestors.idx <- function(node.list, all.edges)#
{#
	which(all.edges[,1] == node.list | all.edges[,2] %in% ancestors(node.list, all.edges))#
}#
#
#
## Needed for determining whether nodes are virgin nodes#
getNumTips <- function(node, phy)#
{#
	n <- length(node.leaves(phy,node))#
	return(n)#
}#
#
#
#
## Only used for base model#
medusa.ml.initial <- function(z, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
#	rootnode <- min(z[is.na(z[,"n.t"]),1]) # doesn't work if only two branches (i.e. no NA)#
	#
	rootnode <- min(z[,"anc"])#
	obj <- medusa.ml.fit.partition(1, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	modelFit <- calculateModelFit(fit=obj, z, est.extinction, epsilon.value)#
	#
	if (est.extinction)#
	{#
		list(par=matrix(obj$par, nrow=1, dimnames=list(NULL,c("r", "epsilon"))), lnLik.part=obj$lnLik, #
		   lnLik=obj$lnLik, split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	} else {#
		list(par=matrix(obj$par, nrow=1,dimnames=list(NULL,"r")), lnLik.part=obj$lnLik, lnLik=obj$lnLik,#
		   split.at=rootnode, aic=modelFit[1], aicc=modelFit[2], num.par=modelFit[3])#
	}#
}#
#
#
## Pre-fit values for pendant edges; DON'T recalculate later; should account for ~25% of all calculations#
medusa.ml.prefit <- function(node, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
# Partition '2' represents the pendant edge#
	fitted <- medusa.ml.fit.partition(2, z, est.extinction, epsilon.value, sp=c(initial.r, initial.e), fossil.minimum=fossil.minimum)#
	#
	return(fitted)#
}#
#
#
#
## 'fit' contains parameter value(s) from previous model, used to initialize subsequent model#
## Pass in pre-fitted values for pendant edges; DON'T recalculate #
medusa.ml.update <- function(node, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum)#
{#
	obj <- medusa.split(node, z, anc)#
	z <- obj$z#
	aff <- obj$affected#
	#
	op <- fit$par#
	sp <- op[aff[1],] # Use previously fit parameter values from clade that is currently being split#
	#
	fit1 <- medusa.ml.fit.partition(aff[1], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	fit2 <- 0#
	#
## Check if pendant; calculations already done#
	if (node < root.node)#
	{#
		fit2 <- tips[[node]]#
## Check if virgin node; save more time!#
	} else if (length(unique(z[(z[,"partition"] == aff[2] & z[,"dec"] < root.node),"dec"])) == num.tips[[node]])#
	{#
		fit2 <- virgin.nodes[[node - root.node]]#
## Novel arrangement; need to calculate#
	} else {#
		fit2 <- medusa.ml.fit.partition(aff[2], z, est.extinction, epsilon.value, sp, fossil.minimum)#
	}#
	#
	op[aff[1],] <- fit1$par # Replace parameters with new values for diminished clade#
	fit$par <- rbind(op, fit2$par)#
	fit$lnLik.part[aff] <- c(fit1$lnLik, fit2$lnLik) # Replace parameters with new values for diminished clade#
	fit$split.at <- c(fit$split.at, node)#
	fit$lnLik <- sum(fit$lnLik.part)#
	#
	modelFit <- calculateModelFit(fit, z, est.extinction, epsilon.value)#
	#
	fit$aic <- modelFit[1]#
	fit$aicc <- modelFit[2]#
	fit$num.par <- modelFit[3]#
	#
	return(fit)#
}#
#
#
#
## Split the edge matrix 'z' by adding a partition rooted at node 'node'.#
##   Note: in original MEDUSA parlance, this is cutAtStem=T.#
## The list 'anc' is a list of ancestors (see make.cache.medusa, above).#
## Returns a list with elements:#
##   z: new medusa matrix, with the new partition added#
##   affected: indices of the partitions affected by the split (n == 2).#
# Add cutAtStem = F option. Allow both within a single analysis?!?#
medusa.split <- function(node, z, anc)#
{#
	part <- z[,"partition"]#
	base <- min(part[z[,1] == node | z[,2] == node])#
	tag <- max(part) + 1#
#
	i <- anc[[node]]#
	idx <- i[part[i] == base]#
	z[idx,"partition"] <- tag#
	#
	z[which(z["dec"] == node),"partition"] <- tag # Possible to have several edges to consider#
#
	list(z=z, affected=c(unique(part[idx]), tag))#
}#
#
#
#
## sp = initializing values for r & epsilon#
## Default values should never be used (except for first model), as the values from the previous model are passed in.#
medusa.ml.fit.partition <- function(partition, z, est.extinction, epsilon.value, sp=c(0.1, 0.05), fossil.minimum)#
{#
# Construct likelihood function:#
	lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
	#
	if (est.extinction) # Possibly give a range of initializing values to "navigate the banana"#
	{#
		fit <- optim(fn=lik, par=sp, method="N", control=list(fnscale=-1))#
		list(par=fit$par, lnLik=fit$value)#
	} else {#
		fit <- optimize(fn=lik, interval=c(0, 1))  # check on a valid range#
		list(par=fit$minimum, lnLik=fit$objective)#
	}#
}#
#
#
#
## make.lik.medusa.part: generate a likelihood function for a single partition.#
###
## In the pendant calculations, the variables 'A' and 'B' are the A and B terms#
## in Foote et al. Science: 283 1310-1314, p. 1313, defined as:#
## #
##   A: probability of extinction of one lineage over time 't'#
##   B: A * lambda / mu OR A / epsilon#
###
## Where there is a single lineage at time 0 (a==1), the calculation is#
##   log(1 - A) + log(1 - B) + (n-1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1-A) on a log scale) which cancels to give:#
##   log(1 - B) + (n-1)*log(B)#
## when pendant richness==1 the calculation is even simpler:#
##   log(1 - B)#
###
## When a > 1 (more than one starting species; will only happen coming off of a fossil observation),#
## the calculations follow Foote et al. 1999, put into the function 'foote.fossil.pendant'.#
## 'est.extinction' determines whether yule model is assumed#
## 'epsilon.value', if != NULL, fixes epsilon for all partitions, estimates r; not yet implemented#
## 'fossil.minimum', if == FALSE, treat fossils as exact counts#
## Only one 'partition' is passed in at a time from a proposed split.#
make.lik.medusa.part <- function(partition, est.extinction=TRUE, epsilon.value=NULL, fossil.minimum=T)#
{#
#
# Handle internal, fossil, and pendant edges separately#
	is.int <- is.na(partition[,"n.t"])#
	is.fossil <- (partition[,"n.0"] > 1) | (partition[,"t.1"] > 0 & !is.int)#
	is.pend <- !is.int == !is.fossil # pendant edges *without* fossils#
	#
	n.int <- sum(is.int)#
	n.fossil <- sum(is.fossil)#
	n.pend <- sum(is.pend)#
	#
	if (n.int + n.fossil + n.pend != length(partition[,1])) stop("You messed up, yo.")#
	#
## Internal and pendant calculations differ; split'em up#
	int  <- partition[is.int,,drop=FALSE]#
	foss <- partition[is.fossil,,drop=FALSE]#
	pend <- partition[is.pend,,drop=FALSE]#
	#
	sum.int.t.len <- sum(int[,"t.len"])  # Simply sum all internal edges#
	int.t.0 <- int[,"t.0"]#
	#
# 'n.0' = Foote's 'a', initial diversity; 'n.t' = Foote's 'n', final diversity#
	pend.n.0 <- pend[,"n.0"] # Foote's 'a': initial diversity#
	pend.n.t <- pend[,"n.t"] # Foote's 'n': final diversity#
	pend.t.len <- pend[,"t.len"]#
	#
# Don't need much of this shit anymore#
	foss.n.0 <- foss[,"n.0"]   # Not necessarily equal 1 anymore#
	foss.n.t <- foss[,"n.t"]#
	foss.t.len <- foss[,"t.0"] - foss[,"t.1"]#
	#
# User may pass in epsilon; don't change it, just estimate r#
	f <- function(pars)#
	{#
		if (est.extinction == TRUE)#
		{#
			r <- pars[1]#
			epsilon <- pars[2]#
	#		bd <- get.b.d(r, epsilon)   # Not necessary#
	#		b <- bd$b#
	#		d <- bd$d#
			#
# Previous version where b & d were estimated:#
	#		b <- pars[1]#
	#		d <- pars[2]#
	#		r <- abs(b - d)#
	#		epsilon <- d / b#
			#
			if (r < 0 | epsilon <= 0 | epsilon >= 1) {return(-Inf)}#
		} else {#
## Implement pure birth; not currently working (for some reason). Not immediately urgent, as won't work with fossils anyway#
			r <- pars[1]#
			d <- 0#
			b <- r#
			epsilon <- 0#
			#
			if (r < 0) {return(-Inf)}#
		}#
		#
		if (n.int == 0) {l.int <- 0} else {#
## Likelihood of internal edges from Rabosky et al. (2007) equation (2.3):#
			l.int <- n.int * log(r) - r * sum.int.t.len - sum(log(1 - (epsilon * exp(-r * int.t.0))))#
# Under Yule, should be: l.int <- n.int * log(r) - r * sum.int.t.len#
#
		}#
		#
		if (n.pend == 0) {l.pend <- 0} else {#
## Calculations are from the following:#
## Rabosky et al. 2007. Proc. Roy. Soc. 274: 2915-2923.#
## Foote et al. 1999. Science. 283: 1310-1314#
## Raup. 1985. Paleobiology 11: 42-52 [Foote et al. correct the equation [A18] where a > 1]#
## Bailey. 1964. The Elements Of Stochastic Processes, With Applications To The Natural Sciences#
## Kendall. 1948. Ann. Math. Stat. 19: 1–15.#
###
## A = probability of extinction of one lineage over time 't'#
## B = A * (lambda/mu)#
###
## When there is a single lineage at time 0 (a = 1), the calculation is#
##   log(1 - A) + log(1 - B) + (n - 1)*log(B)#
## but this is conditioned on survival by dividing by (1-A)#
## (subtracting log(1 - A) on a log scale) which cancels to give:#
##   log(1 - B) + (n - 1)*log(B)#
##      - for n.t == 1, reduces further to log(1-B)#
###
## A = mu*(exp((lambda - mu)*t) - 1)) / (lambda*exp((lambda - mu)*t) - mu)#
##  let r = (lambda - mu); ert = exp((lambda - mu)*t)#
## A = mu*(ert - 1)/(lambda*ert - mu)#
###
## B = A * (lambda/mu)#
##   = [mu*(ert - 1)/(lambda*ert - mu)] * (lambda/mu)#
##   = (lambda*(ert - 1))/(lambda*ert - mu)#
##   = (lambda*(ert - 1))/(lambda(ert - mu/lambda))#
##   = (ert - 1) / (ert - epsilon)#
#
## All pendant nodes begin with richness '1'; calculations simple.#
#			i.pend.n.t.1 <- which(pend.n.t == 1)   # calculations even simpler: log(1-B)#
#			i.pend.n.t.n1 <- which(pend.n.t != 1)#
			#
			ert <- exp(r * pend.t.len)#
			B <- (ert - 1) / (ert - epsilon) # Equivalently: B <- (bert - b) / (bert - d)#
			#
	# Under Yule should be: B <- (ert - 1) / ert#
			#
	# separate out calculations; likely not any faster (slower?)#
#			l.pend.1 <- sum(log(1 - B[i.pend.n.t.1]))#
#			l.pend.n1 <- sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
#			l.pend <- l.pend.1 + l.pend.n1#
			#
#			l.pend <- sum(log(1 - B[i.pend.n.t.1])) + #
#			   sum(log(1 - B[i.pend.n.t.n1]) + (pend.n.t[i.pend.n.t.n1] - 1)*log(B[i.pend.n.t.n1]))#
			#
			l.pend <- sum(log(1 - B) + (pend.n.t - 1)*log(B)) # equivalent single formula version#
		}#
		#
# Fossils!#
		if (n.fossil == 0) {l.fossil <- 0} else {#
#
# What is desired: P(n,t,N,T) = P(n,t,1)*P(N,T-t,n)#
# - each term (internal node to fossil, and fossil to pendant node) is conditioned on survival (dividing by [1-(P(0,t,a)]^a)]#
#
			if (fossil.minimum) # loop counts from 1 -> n-1 fossils; *** NEED TO SPEED THIS SHIT UP! ***#
			{#
## First consider path from internal node to fossil, conditioning on survival (i.e. divide by (1-A)^a, although 'a' is always 1 here):#
##  sum(over x from 1 to n-1) [(1-B)*B^(x-1)]#
				#
	### *** BROKEN!!! *** ####
	#
# *** UPDATE TO NEW FORMAT ***#
				#
				ert <- exp(r * foss.t.len)#
				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
			# Under Yule should be: B <- (ert - 1) / ert#
				#
				sum.prob.int.fossil <- numeric(length(foss.n.t))#
				for (i in 1:n.fossil)#
				{#
					tmp <- 0#
					for (j in 1:foss.n.t[i])#
					{#
						tmp <- sum((B.1[i]^(j-1)), tmp)#
					}#
					sum.prob.int.fossil[i] <- (1 - B.1[i]) * tmp # (1-B) brought outside sum, as it is present in every term#
				}#
				#
# Now consider path from fossil to pendant node; looping bits in 'foote.fossil.pendant.minimum'#
				ert <- exp(r * foss.t.len)#
				A <- (ert - 1) / ((ert/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.2 <- A / epsilon                   # Equivalently: B.2 <- A * (b/d)#
				#
			# Using raw probabilities:#
				sum.prob.fossil.pend <- foote.fossil.pendant.minimum(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(log(1 - (sum.prob.int.fossil * sum.prob.fossil.pend)))#
				#
			# Using log-scale values:#
#				sum.prob.fossil.pend <- foote.fossil.pendant.combined(foss.n.t, foss.n.t, A, B.2, fossil.minimum)#
#				l.fossil <- sum(log(1 - (sum.prob.int.fossil * exp(sum.prob.fossil.pend))))#
				#
			} else { # No looping; pretty fast#
# Two scenarios:#
# 1. coming off internal node (i.e. n.0 = 1); same calculation as above#
	# log(1 - B) + (n - 1)*log(B)#
# 2. coming off fossil (i.e. n.0 > 1); need Foote equations#
				off.node <- which(foss[,"n.0"] == 1)#
				off.fossil <- which(foss[,"n.0"] != 1)#
				#
	# First, off node; n.0 = 1#
				ert.off.node <- exp(r * foss[off.node,"t.len"]) # internal node to fossil#
				B.off.node <- (ert.off.node - 1) / (ert.off.node - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
				l.off.node <- sum(log(1 - B.off.node) + (foss[off.node,"n.t"] - 1)*log(B.off.node))#
				#
#				ert <- exp(r * foss.t.len) #
#				B.1 <- (ert - 1) / (ert - epsilon) # Equivalently: B.1 <- (bert - b) / (bert - d)#
		# Under Yule should be: B <- (ert - 1) / ert#
				#
				ert.off.fossil <- exp(r * foss[off.fossil,"t.len"])        # fossil to pendant node or next fossil#
				A <- (ert.off.fossil - 1) / ((ert.off.fossil/epsilon) - 1) # Equivalently: A <- (d*(ert - 1)) / ((b*ert) - d)#
				B.off.fossil <- A / epsilon                                         # Equivalently: B.2 <- A * (b/d)#
				l.off.fossil <- foote.fossil.pendant.exact(foss[off.fossil,"n.0"], foss[off.fossil,"n.t"], A, B.off.fossil)#
				#
#				l.fossil <- sum(log(1 - B.1) + (foss.n.t - 1)*log(B.1)) + #
#				   foote.fossil.pendant.exact(foss.n.t, foss.n.t, A, B.2)#
				l.fossil <- sum(l.off.node, l.off.fossil)#
			}#
		}#
		l.int + l.pend + l.fossil#
	}#
#	l.int + l.pend + l.fossil#
}#
#
#
## Calculates the probability of having *exactly* 'a' fossils and ending with *exactly* 'n' extant species.#
## Use only when 'a', starting richness, > 1 (i.e. if coming off a fossil count).#
## For 'off-fossil' calculations, richness may increase or decrease.#
foote.fossil.pendant.exact <- function(a, n, A, B)#
{#
	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
	lB <- log(B)#
	l1mA <- log(1 - A)#
	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
	l1mB <- log(1 - B)#
	l1mA1mB <- l1mA + l1mB#
	#
#	min.a.n <- pmin(a, n) # *Insanely* slow!#
	min.a.n <- pmin.int(a, n)#
	#
	l.exact.fossil <- numeric(length(min.a.n))#
	#
	for (i in 1:length(a))#
	{#
		ji <- seq_len(min.a.n[i])#
		ai <- a[i]#
		ni <- n[i]#
		#
#		tmp <- lchoose(ai, ji) + lchoose(ni - 1, ji - 1) + (ai - ji)*lA[i] + ji*l1mA1mB[i] + (ni - ji)*lB[i]#
		#
# Non-logspace version much faster#
		foo <- choose(ai, ji) * choose(ni - 1, ji - 1) * A[i]^(ai - ji) * ((1-A[i])*(1-B[i]))^ji * B[i]^(ni - ji)#
		tmp <- sum(foo)#
		#
## Conditioning on survival factors out of the sum:#
		l.exact.fossil[i] <- sum(tmp)/(r1mA.exp.a[i])#
		#
#		l.exact.fossil[i] <- logspace_sum(tmp) - l1mA.exp.a[i] # logspace_sum: calculate log(x+y) from log(x) and log(y)#
	#	l.exact.fossil[i] <- logspace_sum(tmp) - l1mA[i]  # old conditioning; not appropriate for a > 1#
	}#
#
#	sum(l.exact.fossil)#
	return(sum(log(l.exact.fossil)))#
}#
#
#
## Calculates the probability of having *at least* 'a' fossils and ending with exactly 'n' extant species.#
## Richness may increase or decrease.#
## Should this be computed on a log-scale?#
# *** THIS IS BROKEN ***#
foote.fossil.pendant.minimum <- function(a, n, A, B)#
{#
#	lA <- log(A)#
	A.exp.a <- A^a					# P(0,t,a) i.e. does not survive#
#	lB <- log(B)#
#	l1mA <- log(1 - A)#
#	l1mA.exp.a <- log(1 - A.exp.a)	# P(lineage survives), used to condition upon, logscale#
	r1mA.exp.a <- (1 - A.exp.a)		# P(lineage survives), used to condition upon, rawscale#
	#
#	l1mB <- log(1 - B)#
#	l1mA1mB <- l1mA + l1mB#
	#
	sum.prob.fossil.pend <- numeric(length(a))#
	#
	for (i in 1:length(a)) # Loop over fossils#
	{#
		tmp <- numeric(a[i]-1)#
		for (k in 1:(a[i]-1)) # For fossil i loop over from 1 to n[i]-1#
		{#
			ai <- k#
			ni <- n[i]#
			min.a.n <- pmin.int(ai, ni)#
#			min.a.n <- pmin(ai, ni) # *Insanely* slow! pmin.int saves 70s on a 107s job! WTF?!?#
	   		j <- seq_len(min.a.n)#
			#
	# *** Should this be put on a log scale to preserve precision? ***#
	  # Tests with reasonable data yield the same answer either way#
			foo <- choose(ai, j) * choose(ni - 1, j - 1) * A[i]^(ai - j) * ((1-A[i])*(1-B[i]))^j * B[i]^(ni - j)#
			tmp[k] <- sum(foo)#
	# Alternate log form:#
	  # foo <- lchoose(ai, j) + lchoose(ni - 1, j - 1) + (ai - j)*lA[i] + j*l1mA1mB[i] + (ni - j)*lB[i]#
	    }#
	#  	tmp[i] <- sum(tmp)/(1-A[i])  # old conditioning; not appropriate for a > 1#
			#
# Conditioning on survival factors out of the sum:#
		sum.prob.fossil.pend[i] <- sum(tmp)/(r1mA.exp.a[i])#
	# Alternate log form:#
	  #	foo <- (logspace_sum(tmp))#
	  #	sum.prob.fossil.pend[i] <- foo - l1mA.exp.a[i]#
	}#
#
	return(sum.prob.fossil.pend)#
}#
#
#
## 'fit' contains '$par' and '$lnlik'#
calculateModelFit <- function(fit, z, est.extinction, epsilon.value)#
{#
## Sample size taken (for now) as the total num.nodes in the tree (internal + pendant) plus num.fossil observations#
  # num.nodes = (2*length(phy$tip.label) - 1) == (2*length(richness[,1]) - 1) == length(z[,1]) + 1#
#	n <- (length(z[,1]) + 1) + sum(!is.na(z[,"n.f"]))#
	#
# Changed structure of data; no longer have z[,"n.f"]#
# Instead, each row of z constitutes an edge#
# Since each edge defines either a node or a fossil (i.e. an 'observation'), need only add root node as final obervation#
	n <- (length(z[,1]) + 1)#
	#
## Number of parameters estimated depends on values of est.extinction and epsilon.value#
  # Includes both formal parameters AND number of breaks. Note: first model does not involve a break.#
## Models where all parameters are estimated:#
  # 2 parameters for base model (no breakpoint) + 3 parameters (r, eps, breakpoint) for each subsequent model#
## Models where only one parameter is estimated:#
  # 1 parameter for base model (no breakpoint) + 2 parameters (r, breakpoint) for each subsequent model#
	#
	if (length(fit$par) < 3) # i.e. base model#
	{#
		num.models <- 1#
	} else {#
		num.models <- length(fit$par[,1])#
	}#
	#
	if (est.extinction == FALSE || !is.null(epsilon.value)) # only one parameter estimated (plus breakpoint)#
	{#
		k <- 1 + (2 * (num.models - 1))#
	} else {#
		k <- 2 + (3 * (num.models - 1))#
	}#
	#
	lnLik <- fit$lnLik#
	#
	aic <- (-2 * lnLik) + (2*k)#
	aicc <- aic + 2*k*(k+1)/(n-k-1)#
	#
	modelFit <- c(aic, aicc, k)#
	return(modelFit)#
}#
#
#
## Prints out a table of likelihoods, parameters, aic scores, and aic weights (delta-aics are also available, if desired)#
calculateModelFitSummary <- function (models, phy, plotFig, fig.title=NULL, ...)#
{#
	tmp <- matrix(nrow=(length(models)), ncol=6)#
	colnames(tmp) <- c("N.Models", "Break.Node", "Ln.Lik", "N.Param", "aic", "aicc")#
	#
	w.aic <- numeric(length(models))#
	w.aicc <- numeric(length(models))#
	#
	for (i in 1:length(tmp[,1]))#
	{#
		tmp[i,] <- c(i, as.integer(models[[i]]$split.at[i]), models[[i]]$lnLik, models[[i]]$num.par, models[[i]]$aic, models[[i]]$aicc)#
	}#
	#
	all.res <- as.data.frame(tmp)#
	all.res[1,2] <- NA # root node for base model#
	#
	w.aic <- calculateModelWeights(all.res$aic)#
	w.aicc <- calculateModelWeights(all.res$aicc)#
	#
	all.res <- cbind(all.res[,c(1:5)], w.aic=w.aic$w, aicc=all.res$aicc, w.aicc=w.aicc$w)#
	#
	if (plotFig)#
	{#
		dev.new()#
		plotModelFit(all.res)#
		if (!is.null(fig.title)) {title(main=fig.title, cex.main=0.75)}#
	}#
	return(all.res)#
}#
#
calculateModelWeights <- function (fit)#
{#
	best <- min(fit)#
	delta <- fit-best#
	sumDelta <- sum(exp(-0.5 * delta))#
	w <- (exp(-0.5 * delta)/sumDelta)#
	#
	results <- data.frame(fit=fit,delta=delta,w=w)#
	#
	return(results)#
}#
#
plotModelFit <- function (all.res)#
{#
	ylim <- c(min(all.res[,"aic"],all.res[,"aicc"]), max(all.res[,"aic"],all.res[,"aicc"]))#
	plot(all.res[,"N.Models"],all.res[,"aicc"], xlab="Number of Piecewise Models", ylab="Model Fit", ylim=ylim, type="l", col="blue")#
	points(all.res[,"N.Models"],all.res[,"aicc"], col="blue", pch=21, bg="white")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", type="l")#
	points(all.res[,"N.Models"],all.res[,"aic"], col="black", pch=21, bg="white")#
	#
	legend("topleft", c("aicc","aic"), pch=21, pt.bg="white", lty=1, col=c("blue", "black"), inset = .05, cex=0.75, bty="n") # 'bottomright' also works#
}#
#
logspace_sum <- function(logx)#
{#
	r <- logx[1]#
	if (length(logx)>1)#
	{#
		for (i in 2:length(logx)) {r <- logspace_add(r, logx[i])}#
	}#
	return(r)	#
}#
#
# Calculate log(x+y) from log(x) and log(y)#
logspace_add <- function(logx, logy)#
{#
	if (logx == -Inf)#
	{#
		return(logy)#
	} else {#
		max(logx, logy) + log1p(exp (-abs (logx - logy)))#
	}#
}#
#
#
# Print out results from a given piecewise model. May be:#
#   1. optimal model under aicc: the default#
#   2. optimal model under aic: through setting "aic=T"#
#   3. aicc model using threshold improvement (like original MEDUSA): through setting "threshold" to some value#
#   4. aic model using threshold improvement (like original MEDUSA): through setting "aic=T" and "threshold" to some value#
#   5. user-selected model: through setting "model" to some integer value (from summary table)#
# In any case, also print out base model for comparison#
# Need to parse 'results' (list of lists). Contains elements:#
#  $models, which contains:#
#     $par: i x 2 matrix (for birth-death; i x 1 for pure-birth); the jth row contains #
#       the speciation and (optional) extinction rate for the jth rate class#
#     $lnLik.part: vector of length i; the jth element is the partial log#
#       likelihood value due to the jth rate class#
#     $lnLik: = sum(lnLik.part); the overall log-likelihood of this model#
#     $split.at: the i+1 locations of splits.  The first element is the root node (i.e. background rate).#
#  $phy: the tree, which may have been manipulated (renamed, pruned) in the analysis#
#  $z: a matrix listing branch times and richnesses; for summarizing results#
#  $anc: a list of all ancestors; for summarizing results#
#  $modelSummary: data.frame listing considered models, likelihoods, number of paramters, aicc, aicc, Akaike weights.#
#
#threshold=0; aic=F; plotTree=F; time=T; cex=0.5; plotSurface=T; est.extinction=T; fossil.minimum=F; n.points=100; node.labels=T;#
#r.interval=c(0.0000001,0.9999999); e.interval=r.interval; model=NULL;#
#
summarizeFossilMEDUSA <- function(results, model=NULL, cutoff="threshold", criterion="aicc", plotTree=TRUE, time=TRUE,#
	node.labels=TRUE, cex=0.5, plotSurface=FALSE, est.extinction=TRUE, fossil.minimum=FALSE, r.interval=c(1e-10,1.0),#
	e.interval=r.interval, n.points=100, ...)#
{#
# Desirables:#
#  1. table listing parameter values of selected model#
#  2. list parameters of base model#
#  3. tree printed with colour-coded edges, node labels to indicate split position(s)#
#  4. plot likelihood surface#
	#
# Extract constituent components from results#
	fit <- results$models#
	phy <- results$phy#
	z <- results$z#
	anc <- results$anc#
	modelSummary <- results$modelSummary#
	threshold <- results$threshold#
	#
# First, determine which model is desired#
	model.id <- 0#
	if (!is.null(model))#
	{#
		model.id <- model#
	} else {   # Find best model using threshold criterion#
		if (cutoff != "threshold") {threshold <- cutoff}#
		else {cat("\nSelecting model based on corrected threshold (decrease in information theoretic score of ", -threshold, " units).\n", sep="")}#
		model.id <- 1#
		while (1)#
		{#
			if ((model.id + 1) > length(fit)) break;#
			if ((unlist(fit[[model.id]][criterion]) - unlist(fit[[model.id+1]][criterion])) > threshold) break;#
			model.id <- model.id + 1#
		}#
	}#
	#
	break.pts <- fit[[model.id]]$split.at#
	opt.model <- as.data.frame(cbind(Split.node=break.pts, fit[[model.id]]$par, LnLik.part=fit[[model.id]]$lnLik.part))#
	base.model <- as.data.frame(fit[[1]]$par)#
	#
	cat("\nEstimated parameter values for model #", model.id, ":\n\n", sep="")#
	print.data.frame(opt.model, digits=5)#
	opt.weight <- 0#
	optFit <- 0#
	base.weight <- 0#
	baseFit <- 0#
	if (criterion == "aicc")#
	{#
		opt.weight <- modelSummary$w.aicc[model.id]#
		optFit <- modelSummary$aicc[model.id]#
		base.weight <- modelSummary$w.aicc[1]#
		baseFit <- modelSummary$aicc[1]#
	} else { # aic used#
		opt.weight <- modelSummary$w.aic[model.id]#
		optFit <- modelSummary$aic[model.id]#
		base.weight <- modelSummary$w.aic[1]#
		baseFit <- modelSummary$aic[1]#
	}#
	cat("\nModel fit summary for model #", model.id, ":\n\n", sep="")#
	cat("\tLog-likelihood = ", as.numeric(results$models[[model.id]]["lnLik"]), "\n", sep="")#
	cat("\t", criterion, " = ", optFit, "\n", sep="")#
	cat("\t", criterion, " weight = ", opt.weight, "\n\n", sep="")#
	#
	if (model.id != 1)#
	{#
		cat("\nFor comparison, estimated values for the base model are:\n\n")#
		print.data.frame(base.model, digits=5, row.names=F)#
		cat("\nModel fit summary for base model:\n\n", sep="")#
		cat("\tLog-likelihood = ", as.numeric(results$models[[1]]["lnLik"]), "\n", sep="")#
		cat("\t", criterion, " = ", baseFit, "\n", sep="")#
		cat("\t", criterion, " weight = ", base.weight, "\n\n", sep="")#
	}#
	#
# Get desired tree-model conformation#
	if (length(break.pts) > 1)#
	{#
		for (i in 2:length(break.pts))#
		{#
			tmp <- medusa.split(break.pts[i], z, anc)#
			z <- tmp$z#
		}#
	}#
	#
	#
	#
	#
# Temporary workaround#
	epsilon.value <- NULL#
	#
	#
# Plot tree with purdy colours and labelled nodes (to better map between tree and table)#
	if (plotTree)#
	{#
		dev.new()#
		margin <- F#
		#
# This need to be changed to reflect new structure#
		mm <- match(phy$edge[,2], z[,"dec"])#
		if (time) {margin=T}#
#		plot(phy, edge.color=z[mm,10], no.margin=!margin, cex=cex, ...)#
		plot(phy, edge.color=z[mm,"partition"], no.margin=!margin, cex=cex, ...)#
		if (time)#
		{#
			axisPhylo(cex.axis=0.75)#
			mtext("Divergence Time (MYA)", at=(max(get("last_plot.phylo", envir = .PlotPhyloEnv)$xx)*0.5), side = 1, line = 2, cex=0.75)#
		}#
		if (node.labels)#
		{#
			for (i in  1:length(break.pts))#
			{#
				nodelabels(i, node= break.pts[i], frame = "c", font = 1, cex=0.5)#
			}#
		}#
	}#
	#
	if (plotSurface)#
	{#
		n.pieces <- length(opt.model[,1])#
		dev.new()#
		#
		if ((sqrt(n.pieces)) == round(sqrt(n.pieces)))  #make square plotting surface#
		{#
			op <- par(mfrow=c(sqrt(n.pieces),sqrt(n.pieces)))#
		} else {#
			layout(matrix(1:n.pieces))#
		}#
		#
#	min.r <- 0.000001#
#	max.r <- max(opt.model["r"]) * 2#
		#
		if (n.pieces > 1) {cat("Computing surfaces...\n")} else {cat("Computing surface...")}#
		for (k in 1: n.pieces)#
		{#
			partition <- k#
			#
			lik <- make.lik.medusa.part(z[z[,"partition"] == partition,,drop=FALSE], est.extinction, epsilon.value, fossil.minimum)#
			#
			lik.vals <- matrix(nrow=n.points, ncol=n.points)#
			r.vals <- seq(from=r.interval[1], to=r.interval[2], length.out=n.points)#
			eps.vals <- seq(from=e.interval[1], to=e.interval[2], length.out=n.points)#
			#
			for (i in 1:length(r.vals))#
			{#
				for (j in 1:(length(eps.vals))) {lik.vals[i,j] <- lik(pars=c(r.vals[i], eps.vals[j]))}#
			}#
			if (n.pieces > 1) {cat("Completed computing surface for piecewise model #", k, "\n", sep="")}#
			else {cat (" done.\n")}#
		#
# Perspective plot#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood", theta=-45, phi=45)#
#	persp(lik.vals, x=r.vals, y=eps.vals, xlab="r", ylab="epsilon", zlab="Likelihood")#
#	points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
#	points(x=best.r, y=best.eps, pch=16, col="blue")#
#	points(modelSummary$Ln.Lik[model.id], x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red")#
	#
	#
	#
	#
## *** Can check on distance between MLE and best point evaluated above; if large, advize evaluating further points#
# Perhaps determine the correct number of points this way automatically?#
	#
	#
	#
	#
# Contour plot#
			#
	# This shit is only good for determining the best number of points to evaluate#
			max.lik <- max(lik.vals,na.rm=T)#
			best.r <- numeric()#
			best.eps <- numeric()#
			#
# Need to figure out which parameter values lead to this likelihood...#
			i.best <- which(lik.vals==max.lik)#
			if (length(i.best) > 1) {i.best <- i.best[1]} # if more than one combination gives best value, just grab first#
			#
	# the following determines, from the r/eps sequences, where in the the likelihood matrix the MLE lies#
			if (i.best > n.points)#
			{#
				best.r <- r.vals[i.best%%n.points]#
				best.eps <- eps.vals[ceiling(i.best/n.points)]#
			} else {#
				best.r <- r.vals[i.best]#
				best.eps <- eps.vals[1]#
			}#
#			cat("Best likelihood found: ", max.lik, " for parameter combination #", i.best, "\n", sep="")#
			#
			#
			max.lik <- as.numeric(opt.model[partition,"LnLik.part"])  # MLE#
			lines <- c(max.lik-0.5, max.lik-1, max.lik-2, max.lik-3, max.lik-4, max.lik-5, max.lik-10, max.lik-50, max.lik-100)#
			contour(lik.vals, levels=lines, labels=c(0.5, 1, 2, 3, 4, 5, 10, 50, 100), axes=FALSE, xlab="r (b-d)", ylab="epsilon (d/b)")#
			tics<-floor(c(1, n.points/4, n.points/2, n.points*3/4, n.points))#
			axis(1, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(r.vals[tics], 3))#
			axis(2, at=c(0, 0.25, 0.5, 0.75, 1), labels=round(eps.vals[tics], 3))#
			points(x=opt.model[partition,"r"], y=opt.model[partition,"epsilon"], pch=16, col="red") # inferred ML values#
#			points(x=best.r, y=best.eps, pch=16, col="blue") # best from surface samples#
#			legend("topright", c("ML","Best from sampled surface"), pch=16, col=c("red", "blue"), inset = .05, cex=0.75, bty="n")#
			legend("topright", "ML", pch=16, col="red", inset = .05, cex=0.75, bty="n")#
			if (n.pieces > 1) {title(main=paste("Piecewise model #", k, sep=""))}#
		}#
	}#
}#
#
#
#
#
#
#
#
#
# *** NOT used ***#
#
#
## Get b and d values from r (b-d) and epsilson (d/b)#
## Used in previous version of program; now in terms of r and epsilon#
## Possibly of use to users wishing to translate results#
get.b.d <- function(r, epsilon)#
{#
	b <- r/(1-epsilon)#
	d <- b-r   # Alternatively: d <- eps*r/(1-eps)#
	return(list(b=b, d=d))#
}#
#
## Print out tree with ape-style node-numbering#
## Possibly of interest for users to identify numbers of node(s) off interest#
 ## If this is the case, make sure to pass in pruned tree#
plotNN <- function (phy, time=TRUE, margin=TRUE, label.offset=0.5, cex=0.5, ...) #
{#
	phy$node.label <- (length(phy$tip.label) + 1):max(phy$edge)#
	plot.phylo(phy, show.node.label=TRUE, no.margin=!margin, label.offset=label.offset, cex=cex, ...)#
	if (time && !margin) cat("Cannot plot time axis without a margin.\n")#
	else if (time && margin) axisPhylo(cex.axis=0.75)#
}
summarizeFossilMEDUSA(results=carny.res)
threshold <- 1
summarizeFossilMEDUSA(results=carny.res)
threshold <- -1
summarizeFossilMEDUSA(results=carny.res)
require(fossilMEDUSA)
carnivore.extant.richness <- read.csv("carnivore.extant.richness.csv")#
carnivora.tree <- read.tree("carnivora.phy")#
#
plot(carnivora.tree, label.offset=0.5, cex=0.75); axisPhylo()
carny.res <- runFossilMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
carny.res
summarizeFossilMEDUSA(results=carny.res)
 carny.res$threshold
runFossilMEDUSA <- function(phy, richness=NULL, fossil.richness=NULL, est.extinction=TRUE, fossil.minimum=FALSE,#
	model.limit=20, stop="model.limit", criterion="aicc", epsilon.value=NULL, initial.r=0.05, initial.e=0.5, #
	plotFig=FALSE, nexus=FALSE, verbose=TRUE, mc=FALSE, num.cores=NULL, ...)#
{#
	#
	if (fossil.minimum==T)#
	{#
		cat("\n\n*** Whoops! Fossils as minimum counts currently broken! Setting to exact. ***\n\n")#
		fossil.minimum=F#
	}#
	#
	if (nexus) phy <- read.nexus(phy)#
	if (is.null(richness))  # Assume tree represents single species tips and is completely sampled#
	{#
		richness <- data.frame(taxon=phy$tip.label, n.taxa=1, n.fossils=NA, f.time=NA)#
	} else {#
## Before determining model.limit, prune tree as necessary (from 'taxon' information in 'richness')#
		phyData <- pruneTreeMergeData(phy, richness, fossil.richness, fossil.minimum, verbose)#
		phy <- phyData$phy#
		richness <- phyData$richness#
	}#
	#
## Limit on number of piecewise models fitted; based on tree size, aicc correction factor, flavour of model#
## fitted (i.e. # parameters estimated), and the stop criterion enforced#
	model.limit <- getMaxModelLimit(richness, model.limit, est.extinction, stop, verbose)#
	#
## Determine correct AICc threshold based on tree size (based on simulations)#
 ## Should be used for interpreting model-fit#
	threshold <- getThreshold(length(phy$tip.label))#
	cat("Appropriate AICc threshold for tree of ", length(phy$tip.label), " tips is: ", threshold, ".\n\n", sep="")#
	#
## Store pertinent information: branch times, richness, ancestors#
	cat("Preparing data for analysis... ")#
	obj <- make.cache.medusa(phy, richness, mc, num.cores)#
	cat("done.\n")#
	#
## Keep track of all nodes, internal and pendant (for keeping track of breakpoints)#
	pend.nodes <- seq_len(length(phy$tip.label))   # Calculate pendant splits just once, keep track through various models#
	int.nodes <- (length(phy$tip.label)+2):max(phy$edge) # Omit root node#
	root.node <- length(phy$tip.label)+1#
	all.nodes <- c(pend.nodes, root.node, int.nodes)#
	#
	anc <- obj$anc#
	z <- obj$z#
	z.orig <- z # Save for summarizing models#
	#
## Pre-fit pendant edges so these values need not be re(re(re))calculated; amounts to ~25% of all calculations#
 ## Will show particular performance gain for edges with many fossil observations#
	tips <- list()#
	cat("Optimizing parameters for pendant edges... ")#
	if (mc)#
	{#
		tips <- mclapply(pend.nodes, medusa.ml.prefit, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e, mc.cores=num.cores)#
	} else {#
		tips <- lapply(pend.nodes, medusa.ml.prefit, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
	}#
	cat("done.\n")#
	#
## Pre-fit virgin internal nodes; should deliver performance gain for early models, and especially for large trees#
 ## Remain useful until a spilt is accepted within the clade#
	virgin.nodes <- list()#
	cat("Pre-calculating parameters for virgin internal nodes... ")#
	if (mc)#
	{#
		virgin.nodes <- mclapply(int.nodes, medusa.ml.prefit, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e, mc.cores=num.cores)#
	} else {#
		virgin.nodes <- lapply(int.nodes, medusa.ml.prefit, z, anc, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
	}#
	cat("done.\n\n")#
	#
## Needed downstream; don't recalculate#
	num.tips <- list()#
	if (mc)#
	{#
		num.tips <- mclapply(all.nodes, getNumTips, phy, mc.cores=num.cores)#
	} else {#
		num.tips <- lapply(all.nodes, getNumTips, phy)#
	}#
	#
## 'fit' holds current results; useful for initializing subsequent models#
	fit <- medusa.ml.initial(z, est.extinction, epsilon.value, fossil.minimum, initial.r, initial.e)#
	models <- list(fit)#
	#
	if (stop == "model.limit") # Consider 'model.limit' piecewise models#
	{#
		cat("Step 1 (of ", model.limit, "): best likelihood = ", models[[1]]$lnLik, "; AICc = ", models[[1]]$aicc, "\n", sep="")#
		for (i in seq_len(model.limit-1))#
		{#
			node.list <- all.nodes[-fit$split.at]#
			if (mc)  # multicore (i.e. multithreaded) processing. No GUI, and not at all on Windows#
			{#
				res <- mclapply(node.list, medusa.ml.update, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum, mc.cores=num.cores)#
			} else {#
				res <- lapply(node.list, medusa.ml.update, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum)#
			}#
# Select model with best score according to the specific criterion employed (default aicc)#
			best <- which.min(unlist(lapply(res, "[[", criterion)))#
			models <- c(models, res[best])#
			z <- medusa.split(node.list[best], z, anc)$z#
			fit <- res[[best]]   # keep track of '$split.at' i.e. nodes already considered#
			#
			cat("Step ", i+1, " (of ", model.limit, "): best likelihood = ", models[[i+1]]$lnLik, "; AICc = ", models[[i+1]]$aicc,#
				"; break at node ", models[[i+1]]$split.at[i+1],"\n", sep="")#
		}#
	} else if (stop == "threshold") {#
		i <- 1#
		done <- FALSE#
		cat("Step 1: best likelihood = ", models[[1]]$lnLik, "; AICc = ", models[[1]]$aicc, "\n", sep="")#
		while (!done & i < model.limit)#
		{#
			node.list <- all.nodes[-fit$split.at]#
			if (mc)  # multicore (i.e. multithreaded) processing. No GUI, and not at all on Windows#
			{#
				res <- mclapply(node.list, medusa.ml.update, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum, mc.cores=num.cores)#
			} else {#
				res <- lapply(node.list, medusa.ml.update, z, anc, fit, tips, virgin.nodes, num.tips, root.node, est.extinction, epsilon.value, fossil.minimum)#
			}#
# Select model with best score according to the specific criterion employed (default aicc)#
			best <- which.min(unlist(lapply(res, "[[", criterion)))#
			if (as.numeric(res[[best]][criterion]) - as.numeric(models[[length(models)]][criterion]) > threshold)#
			{#
				cat("\nNo significant increase in ", criterion, " score. Disregarding subsequent piecewise models.\n", sep="")#
				done <- TRUE#
				break;#
			}#
			models <- c(models, res[best])#
			z <- medusa.split(node.list[best], z, anc)$z#
			fit <- res[[best]]   # keep track of '$split.at' i.e. nodes already considered#
			#
			cat("Step ", i+1, " (of ", model.limit, "): best likelihood = ", models[[i+1]]$lnLik, "; AICc = ", models[[i+1]]$aicc,#
				"; break at node ", models[[i+1]]$split.at[i+1],"\n", sep="")#
			i <- i+1#
		}#
	}#
	#
	modelSummary <- calculateModelFitSummary(models, phy, plotFig=ifelse(model.limit > 1 & plotFig, T, F), ...)#
	if (verbose)#
	{#
		cat("\n", "Model fit summary:", "\n\n", sep="")#
		print(modelSummary)#
	}#
	results <- list(z=z.orig, anc=anc, models=models, phy=phy, modelSummary=modelSummary, threshold=threshold)#
	#
	return(results)#
}
carny.res <- runFossilMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
 carny.res$threshold
summarizeFossilMEDUSA(results=carny.res)
require(turboMEDUSA)
carnivore.extant.richness <- read.csv("carnivore.extant.richness.csv")
carnivora.tree <- read.tree("carnivora.phy")
carny.res <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
summarizeTurboMEDUSA(results=carny.res)
carny.res <- runFossilMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
summarizeFossilMEDUSA(results=carny.res)
require(fossilMEDUSA)
carny.res <- runFossilMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
summarizeFossilMEDUSA(results=carny.res)
ls()
carny.res
carny.res$threshold
summarizeFossilMEDUSA(results=carny.res)
require(turboMEDUSA)
summarizeTurboMEDUSA(results=carny.res)
require(turboMEDUSA)
carnivore.extant.richness <- read.csv("carnivore.extant.richness.csv")#
carnivora.tree <- read.tree("carnivora.phy")
carny.res <- runTurboMEDUSA(phy=carnivora.tree, richness=carnivore.extant.richness)
summarizeTurboMEDUSA(results=carny.res)
dev.new()
require(fossilMEDUSA)
summarizeFossilMEDUSA(results=carny.res)
summarizeTurboMEDUSA(results=carny.res)
res <- carny.res
results <- carny.res
	fit <- results$models#
	phy <- results$phy#
	z <- results$z#
	anc <- results$anc#
	model.summary <- results$model.summary#
	threshold <- results$threshold
	fit <- results$models#
	phy <- results$phy#
	z <- results$z#
	anc <- results$anc#
	modelSummary <- results$modelSummary#
	threshold <- results$threshold
setwd("/Users/josephwb/Projects/R_working/turboMEDUSA/turboMEDUSA/R")
